#!/bin/bash

#SBATCH --job-name=training_emnist
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=3
#SBATCH --ntasks-per-node=1
#SBATCH --time=24:00:00
#SBATCH --mem=60000M
#SBATCH --partition=gpu_shared_course
#SBATCH --gres=gpu:1

module load 2019
module load Miniconda2
source activate FACT

pip install emnist
pip install ./

# Number of concepts to be trained on
declare -a concepts=(5 10 15 20 25 30 35 40)

for i in `seq 0 7`; do
  srun python scripts/main_emnist.py --lisa 1 --cuda --nconcepts ${concepts[i]} --train |& tee -a "$SLURM_SUBMIT_DIR"/lisa_output/slurm/emnist_output_$i &
done
wait


