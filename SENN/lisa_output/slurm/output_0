
Parameters:
	BATCH_SIZE=128
	CONCEPT_DIM=1
	CUDA=False
	DATASET=pathology
	DATASETS=['heart', 'ionosphere', 'breast-cancer', 'wine', 'heart', 'glass', 'diabetes', 'yeast', 'leukemia', 'abalone']
	DEBUG=False
	DROPOUT=0.1
	EMBEDDING=pathology
	EPOCHS=10
	H_SPARSITY=0.0001
	H_TYPE=cnn
	LIP_CALLS=10
	LIP_EPS=0.01
	LIP_POINTS=100
	LISA=1
	LOAD_MODEL=False
	LOG_PATH=log
	LR=0.001
	MODEL_PATH=models
	NCLASSES=2
	NCONCEPTS=5
	NOBIAS=False
	NUM_GPUS=1
	NUM_WORKERS=4
	OBJECTIVE=cross_entropy
	OPT=adam
	OPTIM=gp
	POSITIVE_THETA=False
	PRINT_FREQ=10
	RESULTS_PATH=out
	SEED=2018
	SUMMARY_PATH=results/summary.csv
	TEST=False
	THETA_ARCH=simple
	THETA_DIM=-1
	THETA_REG_LAMBDA=0.01
	THETA_REG_TYPE=grad3
	TRAIN=True
	WEIGHT_DECAY=0.001
Model path out lisa_output/models/mnist/grad3_Hcnn_Thsimple_Cpts5_Reg1e-02_Sp0.0001_LR0.001
Epoch: [0][0/422]  Time 2.08 (2.08)  Loss 2.3357 (2.3357)  Prec@1 7.812 (7.812)  Prec@5 46.094 (46.094)
Epoch: [0][10/422]  Time 1.69 (1.77)  Loss 2.1657 (2.2451)  Prec@1 27.344 (20.668)  Prec@5 75.781 (69.389)
Epoch: [0][20/422]  Time 1.81 (1.75)  Loss 2.0025 (2.1663)  Prec@1 31.250 (25.149)  Prec@5 85.938 (75.484)
Epoch: [0][30/422]  Time 1.74 (1.74)  Loss 1.8731 (2.1001)  Prec@1 43.750 (27.797)  Prec@5 88.281 (78.805)
Epoch: [0][40/422]  Time 1.69 (1.74)  Loss 1.6635 (2.0170)  Prec@1 47.656 (32.203)  Prec@5 91.406 (81.555)
Epoch: [0][50/422]  Time 1.76 (1.74)  Loss 1.3084 (1.9136)  Prec@1 64.844 (37.286)  Prec@5 95.312 (84.069)
Epoch: [0][60/422]  Time 1.71 (1.73)  Loss 1.1806 (1.8157)  Prec@1 66.406 (41.714)  Prec@5 96.875 (85.925)
Epoch: [0][70/422]  Time 1.71 (1.73)  Loss 1.1611 (1.7312)  Prec@1 71.094 (45.621)  Prec@5 96.094 (87.214)
Epoch: [0][80/422]  Time 1.68 (1.73)  Loss 1.1170 (1.6608)  Prec@1 73.438 (48.756)  Prec@5 96.094 (88.368)
Epoch: [0][90/422]  Time 1.68 (1.73)  Loss 1.0927 (1.5939)  Prec@1 78.125 (51.683)  Prec@5 99.219 (89.363)
Epoch: [0][100/422]  Time 1.68 (1.72)  Loss 1.1528 (1.5349)  Prec@1 74.219 (54.185)  Prec@5 96.094 (90.130)
Epoch: [0][110/422]  Time 1.81 (1.72)  Loss 0.9574 (1.4875)  Prec@1 76.562 (56.201)  Prec@5 96.875 (90.745)
Epoch: [0][120/422]  Time 1.76 (1.72)  Loss 0.8707 (1.4425)  Prec@1 82.812 (58.032)  Prec@5 97.656 (91.284)
Epoch: [0][130/422]  Time 1.71 (1.72)  Loss 0.8537 (1.3968)  Prec@1 79.688 (59.924)  Prec@5 98.438 (91.812)
Epoch: [0][140/422]  Time 1.60 (1.72)  Loss 0.9573 (1.3590)  Prec@1 76.562 (61.541)  Prec@5 97.656 (92.260)
Epoch: [0][150/422]  Time 1.59 (1.71)  Loss 0.8621 (1.3240)  Prec@1 86.719 (63.033)  Prec@5 97.656 (92.638)
Epoch: [0][160/422]  Time 1.59 (1.71)  Loss 0.7795 (1.2921)  Prec@1 83.594 (64.334)  Prec@5 99.219 (92.993)
Epoch: [0][170/422]  Time 1.58 (1.70)  Loss 0.8313 (1.2635)  Prec@1 85.938 (65.570)  Prec@5 96.875 (93.279)
Epoch: [0][180/422]  Time 1.68 (1.70)  Loss 0.8246 (1.2373)  Prec@1 83.594 (66.613)  Prec@5 95.312 (93.530)
Epoch: [0][190/422]  Time 1.58 (1.69)  Loss 0.7386 (1.2145)  Prec@1 82.812 (67.519)  Prec@5 98.438 (93.770)
Epoch: [0][200/422]  Time 1.57 (1.68)  Loss 0.6912 (1.1928)  Prec@1 88.281 (68.424)  Prec@5 98.438 (93.972)
Epoch: [0][210/422]  Time 1.56 (1.68)  Loss 0.7381 (1.1717)  Prec@1 85.156 (69.261)  Prec@5 99.219 (94.194)
Epoch: [0][220/422]  Time 1.65 (1.68)  Loss 0.6790 (1.1517)  Prec@1 89.844 (70.054)  Prec@5 96.875 (94.390)
Epoch: [0][230/422]  Time 1.61 (1.67)  Loss 0.7502 (1.1355)  Prec@1 85.938 (70.681)  Prec@5 98.438 (94.585)
Epoch: [0][240/422]  Time 1.59 (1.67)  Loss 0.7217 (1.1188)  Prec@1 85.156 (71.360)  Prec@5 98.438 (94.752)
Epoch: [0][250/422]  Time 1.67 (1.67)  Loss 0.6081 (1.1027)  Prec@1 89.062 (71.947)  Prec@5 100.000 (94.908)
Epoch: [0][260/422]  Time 1.58 (1.67)  Loss 0.8648 (1.0880)  Prec@1 80.469 (72.501)  Prec@5 100.000 (95.040)
Epoch: [0][270/422]  Time 1.58 (1.66)  Loss 0.7358 (1.0744)  Prec@1 87.500 (73.037)  Prec@5 99.219 (95.183)
Epoch: [0][280/422]  Time 1.56 (1.66)  Loss 0.6469 (1.0603)  Prec@1 86.719 (73.563)  Prec@5 99.219 (95.321)
Epoch: [0][290/422]  Time 1.58 (1.66)  Loss 0.7993 (1.0476)  Prec@1 88.281 (74.036)  Prec@5 98.438 (95.444)
Epoch: [0][300/422]  Time 1.59 (1.66)  Loss 0.7717 (1.0365)  Prec@1 85.938 (74.478)  Prec@5 100.000 (95.538)
Epoch: [0][310/422]  Time 1.59 (1.66)  Loss 0.5701 (1.0251)  Prec@1 92.188 (74.950)  Prec@5 99.219 (95.647)
Epoch: [0][320/422]  Time 1.58 (1.65)  Loss 0.6580 (1.0137)  Prec@1 85.156 (75.363)  Prec@5 99.219 (95.751)
Epoch: [0][330/422]  Time 1.58 (1.65)  Loss 0.7363 (1.0027)  Prec@1 83.594 (75.755)  Prec@5 97.656 (95.846)
Epoch: [0][340/422]  Time 1.58 (1.65)  Loss 0.5706 (0.9926)  Prec@1 91.406 (76.136)  Prec@5 99.219 (95.940)
Epoch: [0][350/422]  Time 1.58 (1.65)  Loss 0.5831 (0.9823)  Prec@1 90.625 (76.489)  Prec@5 100.000 (96.025)
Epoch: [0][360/422]  Time 1.58 (1.65)  Loss 0.5908 (0.9731)  Prec@1 89.844 (76.848)  Prec@5 99.219 (96.092)
Epoch: [0][370/422]  Time 1.57 (1.64)  Loss 0.5843 (0.9644)  Prec@1 91.406 (77.171)  Prec@5 98.438 (96.151)
Epoch: [0][380/422]  Time 1.76 (1.64)  Loss 0.6275 (0.9550)  Prec@1 89.844 (77.512)  Prec@5 98.438 (96.229)
Epoch: [0][390/422]  Time 1.60 (1.64)  Loss 0.5743 (0.9467)  Prec@1 91.406 (77.837)  Prec@5 98.438 (96.292)
Epoch: [0][400/422]  Time 1.69 (1.64)  Loss 0.5478 (0.9380)  Prec@1 94.531 (78.164)  Prec@5 99.219 (96.367)
Epoch: [0][410/422]  Time 1.64 (1.64)  Loss 0.5119 (0.9305)  Prec@1 92.969 (78.416)  Prec@5 100.000 (96.424)
Epoch: [0][420/422]  Time 1.56 (1.64)  Loss 0.6251 (0.9234)  Prec@1 90.625 (78.671)  Prec@5 99.219 (96.476)
Test: [0/47]	Time 0.366 (0.366)	Loss 0.1013 (0.1013)	Prec@1 98.438 (98.438)	Prec@5 99.219 (99.219)
Test: [10/47]	Time 0.092 (0.122)	Loss 0.0794 (0.1222)	Prec@1 97.656 (96.733)	Prec@5 100.000 (99.716)
Test: [20/47]	Time 0.092 (0.109)	Loss 0.0997 (0.1432)	Prec@1 96.094 (96.168)	Prec@5 100.000 (99.665)
Test: [30/47]	Time 0.089 (0.104)	Loss 0.1004 (0.1414)	Prec@1 96.094 (96.346)	Prec@5 100.000 (99.748)
Test: [40/47]	Time 0.071 (0.100)	Loss 0.1585 (0.1420)	Prec@1 96.094 (96.208)	Prec@5 100.000 (99.771)
 * Prec@1 96.350 Prec@5 99.750
Epoch: [1][0/422]  Time 1.92 (1.92)  Loss 0.6570 (0.6570)  Prec@1 89.062 (89.062)  Prec@5 99.219 (99.219)
Epoch: [1][10/422]  Time 1.77 (1.66)  Loss 0.5706 (0.6289)  Prec@1 92.188 (89.631)  Prec@5 100.000 (98.580)
Epoch: [1][20/422]  Time 1.87 (1.72)  Loss 0.7478 (0.6099)  Prec@1 86.719 (90.179)  Prec@5 97.656 (98.921)
Epoch: [1][30/422]  Time 1.78 (1.77)  Loss 0.6064 (0.6262)  Prec@1 90.625 (89.642)  Prec@5 99.219 (98.740)
Epoch: [1][40/422]  Time 1.80 (1.78)  Loss 0.6420 (0.6270)  Prec@1 89.844 (89.405)  Prec@5 99.219 (98.819)
Epoch: [1][50/422]  Time 1.78 (1.78)  Loss 0.6914 (0.6237)  Prec@1 85.938 (89.445)  Prec@5 97.656 (98.943)
Epoch: [1][60/422]  Time 1.55 (1.76)  Loss 0.6259 (0.6218)  Prec@1 87.500 (89.498)  Prec@5 99.219 (98.937)
Epoch: [1][70/422]  Time 1.56 (1.73)  Loss 0.5277 (0.6154)  Prec@1 89.844 (89.646)  Prec@5 97.656 (98.977)
Epoch: [1][80/422]  Time 1.58 (1.72)  Loss 0.5935 (0.6139)  Prec@1 91.406 (89.757)  Prec@5 98.438 (98.978)
Epoch: [1][90/422]  Time 1.58 (1.70)  Loss 0.7460 (0.6126)  Prec@1 89.062 (89.861)  Prec@5 98.438 (98.996)
Epoch: [1][100/422]  Time 1.57 (1.69)  Loss 0.5670 (0.6148)  Prec@1 92.188 (89.813)  Prec@5 98.438 (98.917)
Epoch: [1][110/422]  Time 1.60 (1.68)  Loss 0.6347 (0.6130)  Prec@1 89.062 (89.830)  Prec@5 98.438 (98.937)
Epoch: [1][120/422]  Time 1.66 (1.67)  Loss 0.5536 (0.6113)  Prec@1 92.969 (89.863)  Prec@5 100.000 (98.954)
Epoch: [1][130/422]  Time 1.59 (1.67)  Loss 0.6821 (0.6080)  Prec@1 87.500 (89.927)  Prec@5 98.438 (98.986)
Epoch: [1][140/422]  Time 1.57 (1.66)  Loss 0.5525 (0.6091)  Prec@1 92.969 (89.977)  Prec@5 100.000 (98.969)
Epoch: [1][150/422]  Time 1.57 (1.65)  Loss 0.4827 (0.6090)  Prec@1 92.969 (90.035)  Prec@5 100.000 (98.960)
Epoch: [1][160/422]  Time 1.56 (1.65)  Loss 0.5456 (0.6062)  Prec@1 89.844 (90.111)  Prec@5 100.000 (98.986)
Epoch: [1][170/422]  Time 1.58 (1.65)  Loss 0.6266 (0.6052)  Prec@1 91.406 (90.141)  Prec@5 99.219 (99.009)
Epoch: [1][180/422]  Time 1.57 (1.64)  Loss 0.5797 (0.6044)  Prec@1 89.062 (90.150)  Prec@5 99.219 (99.016)
Epoch: [1][190/422]  Time 1.56 (1.64)  Loss 0.5857 (0.6024)  Prec@1 90.625 (90.228)  Prec@5 97.656 (99.027)
Epoch: [1][200/422]  Time 1.56 (1.64)  Loss 0.5462 (0.6007)  Prec@1 92.188 (90.271)  Prec@5 98.438 (99.021)
Epoch: [1][210/422]  Time 1.56 (1.63)  Loss 0.5797 (0.5995)  Prec@1 93.750 (90.258)  Prec@5 100.000 (99.041)
Epoch: [1][220/422]  Time 1.75 (1.63)  Loss 0.5434 (0.5983)  Prec@1 91.406 (90.282)  Prec@5 100.000 (99.038)
Epoch: [1][230/422]  Time 1.58 (1.63)  Loss 0.7279 (0.5972)  Prec@1 87.500 (90.310)  Prec@5 97.656 (99.046)
Epoch: [1][240/422]  Time 1.58 (1.63)  Loss 0.5530 (0.5958)  Prec@1 92.188 (90.356)  Prec@5 100.000 (99.044)
Epoch: [1][250/422]  Time 1.60 (1.63)  Loss 0.4963 (0.5943)  Prec@1 92.969 (90.423)  Prec@5 99.219 (99.041)
Epoch: [1][260/422]  Time 1.58 (1.62)  Loss 0.5597 (0.5925)  Prec@1 90.625 (90.478)  Prec@5 100.000 (99.048)
Epoch: [1][270/422]  Time 1.58 (1.62)  Loss 0.5777 (0.5915)  Prec@1 89.844 (90.492)  Prec@5 100.000 (99.066)
Epoch: [1][280/422]  Time 1.56 (1.62)  Loss 0.6526 (0.5901)  Prec@1 90.625 (90.530)  Prec@5 96.094 (99.049)
Epoch: [1][290/422]  Time 1.71 (1.62)  Loss 0.6319 (0.5894)  Prec@1 89.062 (90.523)  Prec@5 98.438 (99.052)
Epoch: [1][300/422]  Time 1.57 (1.62)  Loss 0.5614 (0.5878)  Prec@1 90.625 (90.550)  Prec@5 99.219 (99.068)
Epoch: [1][310/422]  Time 1.66 (1.62)  Loss 0.6631 (0.5877)  Prec@1 87.500 (90.512)  Prec@5 98.438 (99.063)
Epoch: [1][320/422]  Time 1.59 (1.62)  Loss 0.5961 (0.5874)  Prec@1 89.844 (90.520)  Prec@5 98.438 (99.061)
Epoch: [1][330/422]  Time 1.59 (1.62)  Loss 0.5819 (0.5865)  Prec@1 92.969 (90.568)  Prec@5 98.438 (99.072)
Epoch: [1][340/422]  Time 1.58 (1.62)  Loss 0.5042 (0.5861)  Prec@1 90.625 (90.577)  Prec@5 100.000 (99.068)
Epoch: [1][350/422]  Time 1.57 (1.62)  Loss 0.5201 (0.5849)  Prec@1 92.969 (90.623)  Prec@5 100.000 (99.085)
Epoch: [1][360/422]  Time 1.59 (1.62)  Loss 0.4698 (0.5834)  Prec@1 96.094 (90.681)  Prec@5 100.000 (99.078)
Epoch: [1][370/422]  Time 1.58 (1.62)  Loss 0.6361 (0.5834)  Prec@1 92.969 (90.701)  Prec@5 96.875 (99.071)
Epoch: [1][380/422]  Time 1.58 (1.62)  Loss 0.5578 (0.5819)  Prec@1 89.062 (90.740)  Prec@5 100.000 (99.075)
Epoch: [1][390/422]  Time 1.58 (1.62)  Loss 0.6617 (0.5817)  Prec@1 88.281 (90.745)  Prec@5 99.219 (99.069)
Epoch: [1][400/422]  Time 1.58 (1.62)  Loss 0.5019 (0.5810)  Prec@1 92.969 (90.748)  Prec@5 100.000 (99.078)
Epoch: [1][410/422]  Time 1.57 (1.62)  Loss 0.5432 (0.5806)  Prec@1 89.062 (90.730)  Prec@5 99.219 (99.080)
Epoch: [1][420/422]  Time 1.55 (1.62)  Loss 0.4536 (0.5794)  Prec@1 91.406 (90.762)  Prec@5 100.000 (99.085)
Test: [0/47]	Time 0.377 (0.377)	Loss 0.0840 (0.0840)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
Test: [10/47]	Time 0.090 (0.133)	Loss 0.0915 (0.0773)	Prec@1 96.094 (97.372)	Prec@5 100.000 (99.929)
Test: [20/47]	Time 0.090 (0.114)	Loss 0.1828 (0.1024)	Prec@1 97.656 (97.247)	Prec@5 100.000 (99.926)
Test: [30/47]	Time 0.089 (0.107)	Loss 0.0704 (0.1121)	Prec@1 98.438 (97.077)	Prec@5 100.000 (99.874)
Test: [40/47]	Time 0.076 (0.102)	Loss 0.1226 (0.1171)	Prec@1 96.875 (97.008)	Prec@5 98.438 (99.790)
 * Prec@1 96.983 Prec@5 99.783
Epoch: [2][0/422]  Time 2.04 (2.04)  Loss 0.4915 (0.4915)  Prec@1 94.531 (94.531)  Prec@5 99.219 (99.219)
Epoch: [2][10/422]  Time 1.57 (1.69)  Loss 0.5139 (0.5502)  Prec@1 93.750 (91.406)  Prec@5 99.219 (99.503)
Epoch: [2][20/422]  Time 1.57 (1.64)  Loss 0.5780 (0.5581)  Prec@1 90.625 (91.220)  Prec@5 98.438 (99.368)
Epoch: [2][30/422]  Time 1.59 (1.63)  Loss 0.5688 (0.5544)  Prec@1 89.844 (91.381)  Prec@5 100.000 (99.420)
Epoch: [2][40/422]  Time 1.58 (1.62)  Loss 0.5314 (0.5502)  Prec@1 92.188 (91.578)  Prec@5 100.000 (99.352)
Epoch: [2][50/422]  Time 1.58 (1.61)  Loss 0.4754 (0.5478)  Prec@1 93.750 (91.498)  Prec@5 100.000 (99.403)
Epoch: [2][60/422]  Time 1.57 (1.61)  Loss 0.4198 (0.5420)  Prec@1 95.312 (91.624)  Prec@5 100.000 (99.411)
Epoch: [2][70/422]  Time 1.59 (1.60)  Loss 0.5246 (0.5368)  Prec@1 92.969 (91.736)  Prec@5 98.438 (99.362)
Epoch: [2][80/422]  Time 1.76 (1.60)  Loss 0.5101 (0.5407)  Prec@1 92.969 (91.782)  Prec@5 98.438 (99.286)
Epoch: [2][90/422]  Time 1.70 (1.61)  Loss 0.4623 (0.5394)  Prec@1 92.188 (91.775)  Prec@5 100.000 (99.296)
Epoch: [2][100/422]  Time 1.56 (1.60)  Loss 0.6714 (0.5374)  Prec@1 91.406 (91.832)  Prec@5 96.875 (99.296)
Epoch: [2][110/422]  Time 1.57 (1.60)  Loss 0.5171 (0.5339)  Prec@1 92.969 (91.899)  Prec@5 100.000 (99.296)
Epoch: [2][120/422]  Time 1.58 (1.60)  Loss 0.5248 (0.5342)  Prec@1 93.750 (91.968)  Prec@5 98.438 (99.238)
Epoch: [2][130/422]  Time 1.58 (1.60)  Loss 0.6158 (0.5374)  Prec@1 88.281 (91.836)  Prec@5 98.438 (99.195)
Epoch: [2][140/422]  Time 1.58 (1.60)  Loss 0.4203 (0.5352)  Prec@1 96.875 (91.933)  Prec@5 100.000 (99.202)
Epoch: [2][150/422]  Time 1.58 (1.60)  Loss 0.4532 (0.5333)  Prec@1 94.531 (91.960)  Prec@5 99.219 (99.214)
Epoch: [2][160/422]  Time 1.57 (1.60)  Loss 0.6407 (0.5342)  Prec@1 87.500 (91.896)  Prec@5 98.438 (99.190)
Epoch: [2][170/422]  Time 1.56 (1.60)  Loss 0.5583 (0.5332)  Prec@1 92.188 (91.954)  Prec@5 99.219 (99.196)
Epoch: [2][180/422]  Time 1.58 (1.60)  Loss 0.4616 (0.5304)  Prec@1 95.312 (92.071)  Prec@5 100.000 (99.210)
Epoch: [2][190/422]  Time 1.57 (1.60)  Loss 0.4967 (0.5294)  Prec@1 91.406 (92.110)  Prec@5 100.000 (99.211)
Epoch: [2][200/422]  Time 1.58 (1.60)  Loss 0.4325 (0.5287)  Prec@1 93.750 (92.106)  Prec@5 100.000 (99.215)
Epoch: [2][210/422]  Time 1.58 (1.60)  Loss 0.5359 (0.5288)  Prec@1 91.406 (92.091)  Prec@5 100.000 (99.234)
Epoch: [2][220/422]  Time 1.58 (1.60)  Loss 0.5171 (0.5281)  Prec@1 92.969 (92.113)  Prec@5 100.000 (99.240)
Epoch: [2][230/422]  Time 1.56 (1.60)  Loss 0.5119 (0.5283)  Prec@1 91.406 (92.093)  Prec@5 99.219 (99.256)
Epoch: [2][240/422]  Time 1.58 (1.60)  Loss 0.3762 (0.5281)  Prec@1 95.312 (92.081)  Prec@5 100.000 (99.251)
Epoch: [2][250/422]  Time 1.80 (1.60)  Loss 0.4703 (0.5268)  Prec@1 95.312 (92.110)  Prec@5 99.219 (99.253)
Epoch: [2][260/422]  Time 1.57 (1.61)  Loss 0.6234 (0.5264)  Prec@1 89.844 (92.134)  Prec@5 97.656 (99.237)
Epoch: [2][270/422]  Time 1.57 (1.60)  Loss 0.4960 (0.5265)  Prec@1 90.625 (92.107)  Prec@5 98.438 (99.245)
Epoch: [2][280/422]  Time 1.57 (1.60)  Loss 0.5420 (0.5265)  Prec@1 89.844 (92.065)  Prec@5 98.438 (99.252)
Epoch: [2][290/422]  Time 1.56 (1.60)  Loss 0.4967 (0.5251)  Prec@1 92.188 (92.107)  Prec@5 99.219 (99.248)
Epoch: [2][300/422]  Time 1.56 (1.60)  Loss 0.5316 (0.5245)  Prec@1 90.625 (92.123)  Prec@5 99.219 (99.255)
Epoch: [2][310/422]  Time 1.58 (1.60)  Loss 0.5260 (0.5240)  Prec@1 93.750 (92.145)  Prec@5 100.000 (99.259)
Epoch: [2][320/422]  Time 1.57 (1.60)  Loss 0.5286 (0.5238)  Prec@1 91.406 (92.175)  Prec@5 99.219 (99.246)
Epoch: [2][330/422]  Time 1.55 (1.60)  Loss 0.4763 (0.5239)  Prec@1 92.969 (92.169)  Prec@5 100.000 (99.245)
Epoch: [2][340/422]  Time 1.56 (1.60)  Loss 0.5050 (0.5237)  Prec@1 92.969 (92.167)  Prec@5 100.000 (99.251)
Epoch: [2][350/422]  Time 1.57 (1.60)  Loss 0.5239 (0.5241)  Prec@1 90.625 (92.181)  Prec@5 99.219 (99.239)
Epoch: [2][360/422]  Time 1.57 (1.60)  Loss 0.4362 (0.5239)  Prec@1 92.969 (92.166)  Prec@5 100.000 (99.240)
Epoch: [2][370/422]  Time 1.55 (1.60)  Loss 0.4685 (0.5235)  Prec@1 95.312 (92.179)  Prec@5 99.219 (99.244)
Epoch: [2][380/422]  Time 1.56 (1.60)  Loss 0.4985 (0.5235)  Prec@1 94.531 (92.188)  Prec@5 99.219 (99.241)
Epoch: [2][390/422]  Time 1.57 (1.59)  Loss 0.4806 (0.5229)  Prec@1 92.969 (92.182)  Prec@5 100.000 (99.245)
Epoch: [2][400/422]  Time 1.59 (1.59)  Loss 0.4968 (0.5221)  Prec@1 92.969 (92.215)  Prec@5 100.000 (99.252)
Epoch: [2][410/422]  Time 1.59 (1.59)  Loss 0.6018 (0.5218)  Prec@1 92.188 (92.226)  Prec@5 96.875 (99.245)
Epoch: [2][420/422]  Time 1.55 (1.59)  Loss 0.6919 (0.5207)  Prec@1 84.375 (92.252)  Prec@5 99.219 (99.254)
Test: [0/47]	Time 0.387 (0.387)	Loss 0.0736 (0.0736)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
Test: [10/47]	Time 0.101 (0.126)	Loss 0.1979 (0.1103)	Prec@1 96.875 (97.656)	Prec@5 100.000 (99.716)
Test: [20/47]	Time 0.094 (0.110)	Loss 0.0235 (0.0942)	Prec@1 99.219 (97.879)	Prec@5 100.000 (99.814)
Test: [30/47]	Time 0.090 (0.105)	Loss 0.0460 (0.0982)	Prec@1 98.438 (97.555)	Prec@5 100.000 (99.798)
Test: [40/47]	Time 0.073 (0.100)	Loss 0.0435 (0.0999)	Prec@1 99.219 (97.542)	Prec@5 99.219 (99.790)
 * Prec@1 97.417 Prec@5 99.817
Epoch: [3][0/422]  Time 2.15 (2.15)  Loss 0.6412 (0.6412)  Prec@1 88.281 (88.281)  Prec@5 98.438 (98.438)
Epoch: [3][10/422]  Time 1.56 (1.84)  Loss 0.4574 (0.5244)  Prec@1 94.531 (91.832)  Prec@5 100.000 (99.219)
Epoch: [3][20/422]  Time 1.56 (1.71)  Loss 0.4881 (0.4994)  Prec@1 95.312 (92.969)  Prec@5 100.000 (99.368)
Epoch: [3][30/422]  Time 1.58 (1.68)  Loss 0.5582 (0.5036)  Prec@1 89.844 (92.868)  Prec@5 99.219 (99.345)
Epoch: [3][40/422]  Time 1.58 (1.66)  Loss 0.6373 (0.4976)  Prec@1 89.844 (93.083)  Prec@5 97.656 (99.333)
Epoch: [3][50/422]  Time 1.57 (1.65)  Loss 0.5243 (0.4983)  Prec@1 91.406 (92.862)  Prec@5 99.219 (99.357)
Epoch: [3][60/422]  Time 1.56 (1.65)  Loss 0.4616 (0.4999)  Prec@1 94.531 (92.853)  Prec@5 99.219 (99.347)
Epoch: [3][70/422]  Time 1.59 (1.64)  Loss 0.4510 (0.4992)  Prec@1 92.969 (92.782)  Prec@5 99.219 (99.340)
Epoch: [3][80/422]  Time 1.57 (1.64)  Loss 0.5333 (0.4972)  Prec@1 93.750 (92.747)  Prec@5 98.438 (99.344)
Epoch: [3][90/422]  Time 1.57 (1.63)  Loss 0.5256 (0.4964)  Prec@1 93.750 (92.728)  Prec@5 98.438 (99.322)
Epoch: [3][100/422]  Time 1.59 (1.63)  Loss 0.4258 (0.4958)  Prec@1 96.875 (92.799)  Prec@5 100.000 (99.343)
Epoch: [3][110/422]  Time 1.58 (1.63)  Loss 0.4408 (0.4918)  Prec@1 96.094 (92.948)  Prec@5 100.000 (99.367)
Epoch: [3][120/422]  Time 1.57 (1.63)  Loss 0.6496 (0.4927)  Prec@1 89.062 (92.846)  Prec@5 99.219 (99.367)
Epoch: [3][130/422]  Time 1.59 (1.62)  Loss 0.5033 (0.4928)  Prec@1 91.406 (92.897)  Prec@5 99.219 (99.362)
Epoch: [3][140/422]  Time 1.57 (1.62)  Loss 0.5000 (0.4932)  Prec@1 93.750 (92.908)  Prec@5 98.438 (99.330)
Epoch: [3][150/422]  Time 1.58 (1.62)  Loss 0.5162 (0.4928)  Prec@1 94.531 (92.917)  Prec@5 99.219 (99.343)
Epoch: [3][160/422]  Time 1.58 (1.62)  Loss 0.5189 (0.4953)  Prec@1 90.625 (92.823)  Prec@5 100.000 (99.340)
Epoch: [3][170/422]  Time 1.59 (1.61)  Loss 0.4633 (0.4941)  Prec@1 92.188 (92.832)  Prec@5 99.219 (99.347)
Epoch: [3][180/422]  Time 1.62 (1.61)  Loss 0.5904 (0.4944)  Prec@1 89.062 (92.831)  Prec@5 99.219 (99.340)
Epoch: [3][190/422]  Time 1.59 (1.61)  Loss 0.4557 (0.4948)  Prec@1 96.875 (92.850)  Prec@5 99.219 (99.321)
Epoch: [3][200/422]  Time 1.57 (1.61)  Loss 0.4442 (0.4941)  Prec@1 92.969 (92.872)  Prec@5 100.000 (99.331)
Epoch: [3][210/422]  Time 1.83 (1.62)  Loss 0.4473 (0.4936)  Prec@1 94.531 (92.895)  Prec@5 99.219 (99.319)
Epoch: [3][220/422]  Time 1.82 (1.63)  Loss 0.4795 (0.4925)  Prec@1 94.531 (92.955)  Prec@5 99.219 (99.321)
Epoch: [3][230/422]  Time 1.82 (1.63)  Loss 0.4908 (0.4913)  Prec@1 91.406 (92.989)  Prec@5 99.219 (99.334)
Epoch: [3][240/422]  Time 1.82 (1.64)  Loss 0.4854 (0.4904)  Prec@1 92.188 (93.034)  Prec@5 99.219 (99.329)
Epoch: [3][250/422]  Time 1.83 (1.65)  Loss 0.4352 (0.4902)  Prec@1 94.531 (93.043)  Prec@5 99.219 (99.334)
Epoch: [3][260/422]  Time 1.82 (1.66)  Loss 0.5490 (0.4897)  Prec@1 92.188 (93.053)  Prec@5 100.000 (99.338)
Epoch: [3][270/422]  Time 1.82 (1.67)  Loss 0.5792 (0.4907)  Prec@1 88.281 (93.018)  Prec@5 96.875 (99.340)
Epoch: [3][280/422]  Time 1.83 (1.67)  Loss 0.4016 (0.4916)  Prec@1 95.312 (92.985)  Prec@5 100.000 (99.352)
Epoch: [3][290/422]  Time 1.83 (1.68)  Loss 0.3728 (0.4902)  Prec@1 97.656 (93.022)  Prec@5 100.000 (99.366)
Epoch: [3][300/422]  Time 1.73 (1.68)  Loss 0.5358 (0.4900)  Prec@1 94.531 (93.039)  Prec@5 98.438 (99.367)
Epoch: [3][310/422]  Time 1.77 (1.68)  Loss 0.4931 (0.4904)  Prec@1 92.188 (93.021)  Prec@5 98.438 (99.357)
Epoch: [3][320/422]  Time 1.57 (1.68)  Loss 0.4892 (0.4902)  Prec@1 94.531 (93.034)  Prec@5 98.438 (99.353)
Epoch: [3][330/422]  Time 1.58 (1.67)  Loss 0.4782 (0.4908)  Prec@1 93.750 (93.021)  Prec@5 99.219 (99.346)
Epoch: [3][340/422]  Time 1.58 (1.67)  Loss 0.5185 (0.4895)  Prec@1 91.406 (93.051)  Prec@5 97.656 (99.345)
Epoch: [3][350/422]  Time 1.58 (1.67)  Loss 0.5030 (0.4888)  Prec@1 92.188 (93.060)  Prec@5 100.000 (99.348)
Epoch: [3][360/422]  Time 1.57 (1.67)  Loss 0.4804 (0.4891)  Prec@1 92.969 (93.060)  Prec@5 100.000 (99.353)
Epoch: [3][370/422]  Time 1.63 (1.67)  Loss 0.5770 (0.4894)  Prec@1 92.188 (93.047)  Prec@5 99.219 (99.360)
Epoch: [3][380/422]  Time 1.58 (1.66)  Loss 0.4185 (0.4893)  Prec@1 95.312 (93.036)  Prec@5 100.000 (99.346)
Epoch: [3][390/422]  Time 1.57 (1.66)  Loss 0.5946 (0.4891)  Prec@1 88.281 (93.055)  Prec@5 98.438 (99.347)
Epoch: [3][400/422]  Time 1.71 (1.66)  Loss 0.4809 (0.4893)  Prec@1 96.094 (93.074)  Prec@5 99.219 (99.349)
Epoch: [3][410/422]  Time 1.62 (1.66)  Loss 0.4062 (0.4889)  Prec@1 94.531 (93.077)  Prec@5 99.219 (99.350)
Epoch: [3][420/422]  Time 1.56 (1.66)  Loss 0.4316 (0.4881)  Prec@1 95.312 (93.112)  Prec@5 98.438 (99.356)
Test: [0/47]	Time 0.360 (0.360)	Loss 0.0127 (0.0127)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test: [10/47]	Time 0.096 (0.124)	Loss 0.0998 (0.0768)	Prec@1 98.438 (97.869)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.096 (0.109)	Loss 0.1730 (0.0882)	Prec@1 96.094 (97.582)	Prec@5 99.219 (99.888)
Test: [30/47]	Time 0.089 (0.104)	Loss 0.0460 (0.0931)	Prec@1 98.438 (97.606)	Prec@5 100.000 (99.824)
Test: [40/47]	Time 0.073 (0.100)	Loss 0.0536 (0.0938)	Prec@1 98.438 (97.599)	Prec@5 99.219 (99.809)
 * Prec@1 97.550 Prec@5 99.833
Epoch: [4][0/422]  Time 2.03 (2.03)  Loss 0.5623 (0.5623)  Prec@1 91.406 (91.406)  Prec@5 99.219 (99.219)
Epoch: [4][10/422]  Time 1.57 (1.65)  Loss 0.4185 (0.4970)  Prec@1 94.531 (92.472)  Prec@5 100.000 (99.290)
Epoch: [4][20/422]  Time 1.58 (1.62)  Loss 0.4827 (0.4686)  Prec@1 92.969 (93.192)  Prec@5 100.000 (99.479)
Epoch: [4][30/422]  Time 1.60 (1.61)  Loss 0.4646 (0.4709)  Prec@1 93.750 (93.347)  Prec@5 100.000 (99.471)
Epoch: [4][40/422]  Time 1.56 (1.60)  Loss 0.4723 (0.4746)  Prec@1 94.531 (93.274)  Prec@5 99.219 (99.390)
Epoch: [4][50/422]  Time 1.58 (1.59)  Loss 0.4177 (0.4751)  Prec@1 94.531 (93.168)  Prec@5 100.000 (99.387)
Epoch: [4][60/422]  Time 1.58 (1.59)  Loss 0.5841 (0.4729)  Prec@1 89.844 (93.238)  Prec@5 99.219 (99.449)
Epoch: [4][70/422]  Time 1.57 (1.59)  Loss 0.5372 (0.4739)  Prec@1 89.844 (93.277)  Prec@5 100.000 (99.483)
Epoch: [4][80/422]  Time 1.56 (1.59)  Loss 0.4971 (0.4741)  Prec@1 93.750 (93.248)  Prec@5 99.219 (99.498)
Epoch: [4][90/422]  Time 1.58 (1.59)  Loss 0.4197 (0.4724)  Prec@1 95.312 (93.269)  Prec@5 100.000 (99.519)
Epoch: [4][100/422]  Time 1.57 (1.59)  Loss 0.5860 (0.4707)  Prec@1 93.750 (93.433)  Prec@5 98.438 (99.489)
Epoch: [4][110/422]  Time 1.66 (1.59)  Loss 0.5209 (0.4681)  Prec@1 91.406 (93.433)  Prec@5 98.438 (99.486)
Epoch: [4][120/422]  Time 1.77 (1.59)  Loss 0.4801 (0.4664)  Prec@1 94.531 (93.498)  Prec@5 99.219 (99.496)
Epoch: [4][130/422]  Time 1.80 (1.59)  Loss 0.3723 (0.4650)  Prec@1 96.094 (93.589)  Prec@5 99.219 (99.499)
Epoch: [4][140/422]  Time 1.61 (1.60)  Loss 0.5445 (0.4675)  Prec@1 92.969 (93.512)  Prec@5 98.438 (99.474)
Epoch: [4][150/422]  Time 1.59 (1.60)  Loss 0.5529 (0.4679)  Prec@1 88.281 (93.528)  Prec@5 100.000 (99.457)
Epoch: [4][160/422]  Time 1.59 (1.60)  Loss 0.4773 (0.4675)  Prec@1 91.406 (93.488)  Prec@5 98.438 (99.447)
Epoch: [4][170/422]  Time 1.72 (1.60)  Loss 0.4053 (0.4661)  Prec@1 96.094 (93.544)  Prec@5 100.000 (99.447)
Epoch: [4][180/422]  Time 1.62 (1.60)  Loss 0.5664 (0.4675)  Prec@1 91.406 (93.521)  Prec@5 96.875 (99.426)
Epoch: [4][190/422]  Time 1.61 (1.60)  Loss 0.3897 (0.4669)  Prec@1 96.094 (93.562)  Prec@5 99.219 (99.419)
Epoch: [4][200/422]  Time 1.56 (1.60)  Loss 0.4027 (0.4651)  Prec@1 95.312 (93.637)  Prec@5 100.000 (99.413)
Epoch: [4][210/422]  Time 1.67 (1.60)  Loss 0.5191 (0.4652)  Prec@1 92.969 (93.639)  Prec@5 98.438 (99.415)
Epoch: [4][220/422]  Time 1.55 (1.60)  Loss 0.4352 (0.4635)  Prec@1 94.531 (93.693)  Prec@5 99.219 (99.413)
Epoch: [4][230/422]  Time 1.61 (1.60)  Loss 0.4584 (0.4642)  Prec@1 92.969 (93.615)  Prec@5 97.656 (99.398)
Epoch: [4][240/422]  Time 1.73 (1.60)  Loss 0.4373 (0.4633)  Prec@1 92.969 (93.630)  Prec@5 100.000 (99.397)
Epoch: [4][250/422]  Time 1.58 (1.60)  Loss 0.4955 (0.4630)  Prec@1 94.531 (93.647)  Prec@5 99.219 (99.409)
Epoch: [4][260/422]  Time 1.57 (1.60)  Loss 0.3994 (0.4620)  Prec@1 96.094 (93.681)  Prec@5 100.000 (99.410)
Epoch: [4][270/422]  Time 1.56 (1.60)  Loss 0.3858 (0.4611)  Prec@1 93.750 (93.689)  Prec@5 100.000 (99.412)
Epoch: [4][280/422]  Time 1.56 (1.60)  Loss 0.4818 (0.4615)  Prec@1 93.750 (93.658)  Prec@5 100.000 (99.411)
Epoch: [4][290/422]  Time 1.57 (1.60)  Loss 0.4310 (0.4607)  Prec@1 92.969 (93.664)  Prec@5 99.219 (99.412)
Epoch: [4][300/422]  Time 1.81 (1.61)  Loss 0.4001 (0.4604)  Prec@1 96.094 (93.675)  Prec@5 99.219 (99.411)
Epoch: [4][310/422]  Time 1.83 (1.61)  Loss 0.4916 (0.4607)  Prec@1 92.188 (93.660)  Prec@5 100.000 (99.407)
Epoch: [4][320/422]  Time 1.57 (1.62)  Loss 0.4928 (0.4619)  Prec@1 93.750 (93.628)  Prec@5 99.219 (99.416)
Epoch: [4][330/422]  Time 1.71 (1.62)  Loss 0.3928 (0.4613)  Prec@1 94.531 (93.649)  Prec@5 100.000 (99.417)
Epoch: [4][340/422]  Time 1.74 (1.62)  Loss 0.4027 (0.4606)  Prec@1 96.875 (93.668)  Prec@5 99.219 (99.420)
Epoch: [4][350/422]  Time 1.82 (1.62)  Loss 0.4201 (0.4596)  Prec@1 96.094 (93.705)  Prec@5 99.219 (99.426)
Epoch: [4][360/422]  Time 1.82 (1.62)  Loss 0.4849 (0.4594)  Prec@1 92.188 (93.707)  Prec@5 98.438 (99.431)
Epoch: [4][370/422]  Time 1.83 (1.63)  Loss 0.3895 (0.4586)  Prec@1 95.312 (93.702)  Prec@5 100.000 (99.436)
Epoch: [4][380/422]  Time 1.85 (1.64)  Loss 0.4839 (0.4580)  Prec@1 92.188 (93.719)  Prec@5 100.000 (99.438)
Epoch: [4][390/422]  Time 1.81 (1.64)  Loss 0.4964 (0.4579)  Prec@1 89.844 (93.706)  Prec@5 100.000 (99.437)
Epoch: [4][400/422]  Time 1.81 (1.65)  Loss 0.5124 (0.4578)  Prec@1 91.406 (93.695)  Prec@5 98.438 (99.433)
Epoch: [4][410/422]  Time 1.83 (1.65)  Loss 0.4163 (0.4579)  Prec@1 94.531 (93.708)  Prec@5 100.000 (99.428)
Epoch: [4][420/422]  Time 1.84 (1.65)  Loss 0.3753 (0.4575)  Prec@1 91.406 (93.709)  Prec@5 100.000 (99.432)
Test: [0/47]	Time 0.390 (0.390)	Loss 0.1230 (0.1230)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
Test: [10/47]	Time 0.094 (0.127)	Loss 0.0095 (0.1060)	Prec@1 100.000 (97.230)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.095 (0.111)	Loss 0.1765 (0.0912)	Prec@1 95.312 (97.507)	Prec@5 99.219 (99.963)
Test: [30/47]	Time 0.093 (0.105)	Loss 0.1603 (0.0893)	Prec@1 95.312 (97.606)	Prec@5 100.000 (99.950)
Test: [40/47]	Time 0.071 (0.101)	Loss 0.0545 (0.0924)	Prec@1 98.438 (97.580)	Prec@5 99.219 (99.924)
 * Prec@1 97.633 Prec@5 99.933
Epoch: [5][0/422]  Time 2.02 (2.02)  Loss 0.5574 (0.5574)  Prec@1 89.062 (89.062)  Prec@5 97.656 (97.656)
Epoch: [5][10/422]  Time 1.69 (1.78)  Loss 0.4396 (0.4293)  Prec@1 96.094 (94.389)  Prec@5 98.438 (99.432)
Epoch: [5][20/422]  Time 1.70 (1.75)  Loss 0.4440 (0.4316)  Prec@1 93.750 (94.159)  Prec@5 98.438 (99.442)
Epoch: [5][30/422]  Time 1.66 (1.74)  Loss 0.4666 (0.4326)  Prec@1 94.531 (94.204)  Prec@5 98.438 (99.370)
Epoch: [5][40/422]  Time 1.67 (1.72)  Loss 0.4023 (0.4279)  Prec@1 97.656 (94.474)  Prec@5 100.000 (99.390)
Epoch: [5][50/422]  Time 1.71 (1.72)  Loss 0.4213 (0.4288)  Prec@1 96.094 (94.516)  Prec@5 100.000 (99.418)
Epoch: [5][60/422]  Time 1.82 (1.73)  Loss 0.4880 (0.4275)  Prec@1 90.625 (94.493)  Prec@5 100.000 (99.475)
Epoch: [5][70/422]  Time 1.83 (1.74)  Loss 0.4449 (0.4281)  Prec@1 96.094 (94.421)  Prec@5 100.000 (99.472)
Epoch: [5][80/422]  Time 1.88 (1.76)  Loss 0.4552 (0.4293)  Prec@1 95.312 (94.444)  Prec@5 97.656 (99.460)
Epoch: [5][90/422]  Time 1.81 (1.77)  Loss 0.4763 (0.4316)  Prec@1 94.531 (94.368)  Prec@5 99.219 (99.451)
Epoch: [5][100/422]  Time 1.81 (1.77)  Loss 0.3726 (0.4323)  Prec@1 96.875 (94.377)  Prec@5 100.000 (99.451)
Epoch: [5][110/422]  Time 1.81 (1.78)  Loss 0.3398 (0.4291)  Prec@1 97.656 (94.524)  Prec@5 100.000 (99.458)
Epoch: [5][120/422]  Time 1.83 (1.78)  Loss 0.4310 (0.4293)  Prec@1 94.531 (94.525)  Prec@5 100.000 (99.458)
Epoch: [5][130/422]  Time 1.82 (1.78)  Loss 0.4546 (0.4282)  Prec@1 93.750 (94.555)  Prec@5 100.000 (99.475)
Epoch: [5][140/422]  Time 1.88 (1.79)  Loss 0.3808 (0.4303)  Prec@1 96.094 (94.504)  Prec@5 100.000 (99.457)
Epoch: [5][150/422]  Time 1.66 (1.78)  Loss 0.4519 (0.4283)  Prec@1 96.094 (94.547)  Prec@5 99.219 (99.457)
Epoch: [5][160/422]  Time 1.56 (1.77)  Loss 0.4363 (0.4279)  Prec@1 94.531 (94.478)  Prec@5 100.000 (99.481)
Epoch: [5][170/422]  Time 1.60 (1.75)  Loss 0.4620 (0.4309)  Prec@1 92.188 (94.339)  Prec@5 99.219 (99.465)
Epoch: [5][180/422]  Time 1.57 (1.74)  Loss 0.3572 (0.4316)  Prec@1 95.312 (94.320)  Prec@5 100.000 (99.473)
Epoch: [5][190/422]  Time 1.56 (1.74)  Loss 0.4407 (0.4300)  Prec@1 93.750 (94.368)  Prec@5 99.219 (99.489)
Epoch: [5][200/422]  Time 1.56 (1.73)  Loss 0.3635 (0.4298)  Prec@1 96.094 (94.391)  Prec@5 100.000 (99.495)
Epoch: [5][210/422]  Time 1.58 (1.72)  Loss 0.4249 (0.4301)  Prec@1 94.531 (94.398)  Prec@5 100.000 (99.485)
Epoch: [5][220/422]  Time 1.56 (1.72)  Loss 0.5240 (0.4300)  Prec@1 92.188 (94.404)  Prec@5 99.219 (99.487)
Epoch: [5][230/422]  Time 1.57 (1.71)  Loss 0.3935 (0.4327)  Prec@1 95.312 (94.335)  Prec@5 100.000 (99.479)
Epoch: [5][240/422]  Time 1.57 (1.71)  Loss 0.4337 (0.4315)  Prec@1 96.094 (94.389)  Prec@5 99.219 (99.478)
Epoch: [5][250/422]  Time 1.58 (1.70)  Loss 0.4419 (0.4326)  Prec@1 94.531 (94.366)  Prec@5 99.219 (99.465)
Epoch: [5][260/422]  Time 1.58 (1.70)  Loss 0.4139 (0.4322)  Prec@1 91.406 (94.382)  Prec@5 100.000 (99.473)
Epoch: [5][270/422]  Time 1.57 (1.69)  Loss 0.4346 (0.4318)  Prec@1 93.750 (94.367)  Prec@5 98.438 (99.470)
Epoch: [5][280/422]  Time 1.57 (1.69)  Loss 0.4194 (0.4306)  Prec@1 93.750 (94.406)  Prec@5 100.000 (99.486)
Epoch: [5][290/422]  Time 1.58 (1.68)  Loss 0.3878 (0.4296)  Prec@1 95.312 (94.429)  Prec@5 100.000 (99.490)
Epoch: [5][300/422]  Time 1.56 (1.68)  Loss 0.3923 (0.4300)  Prec@1 95.312 (94.420)  Prec@5 99.219 (99.491)
Epoch: [5][310/422]  Time 1.59 (1.68)  Loss 0.4793 (0.4302)  Prec@1 93.750 (94.401)  Prec@5 98.438 (99.483)
Epoch: [5][320/422]  Time 1.60 (1.67)  Loss 0.4408 (0.4308)  Prec@1 93.750 (94.395)  Prec@5 99.219 (99.474)
Epoch: [5][330/422]  Time 1.66 (1.67)  Loss 0.5209 (0.4310)  Prec@1 93.750 (94.392)  Prec@5 98.438 (99.478)
Epoch: [5][340/422]  Time 1.57 (1.67)  Loss 0.4559 (0.4310)  Prec@1 95.312 (94.391)  Prec@5 99.219 (99.473)
Epoch: [5][350/422]  Time 1.57 (1.67)  Loss 0.3824 (0.4314)  Prec@1 96.094 (94.393)  Prec@5 100.000 (99.484)
Epoch: [5][360/422]  Time 1.58 (1.67)  Loss 0.3622 (0.4310)  Prec@1 97.656 (94.406)  Prec@5 99.219 (99.483)
Epoch: [5][370/422]  Time 1.57 (1.66)  Loss 0.4130 (0.4317)  Prec@1 94.531 (94.375)  Prec@5 99.219 (99.478)
Epoch: [5][380/422]  Time 1.56 (1.66)  Loss 0.4207 (0.4319)  Prec@1 94.531 (94.365)  Prec@5 99.219 (99.475)
Epoch: [5][390/422]  Time 1.60 (1.66)  Loss 0.3374 (0.4310)  Prec@1 96.094 (94.403)  Prec@5 100.000 (99.477)
Epoch: [5][400/422]  Time 1.71 (1.66)  Loss 0.3636 (0.4310)  Prec@1 96.094 (94.397)  Prec@5 100.000 (99.478)
Epoch: [5][410/422]  Time 1.57 (1.66)  Loss 0.4714 (0.4308)  Prec@1 94.531 (94.402)  Prec@5 100.000 (99.479)
Epoch: [5][420/422]  Time 1.60 (1.66)  Loss 0.3748 (0.4307)  Prec@1 96.875 (94.396)  Prec@5 100.000 (99.480)
Test: [0/47]	Time 0.405 (0.405)	Loss 0.0776 (0.0776)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
Test: [10/47]	Time 0.093 (0.127)	Loss 0.0568 (0.0825)	Prec@1 98.438 (97.656)	Prec@5 100.000 (99.929)
Test: [20/47]	Time 0.090 (0.110)	Loss 0.0634 (0.0811)	Prec@1 97.656 (97.731)	Prec@5 100.000 (99.926)
Test: [30/47]	Time 0.096 (0.105)	Loss 0.0605 (0.0768)	Prec@1 98.438 (97.782)	Prec@5 100.000 (99.924)
Test: [40/47]	Time 0.069 (0.103)	Loss 0.0370 (0.0782)	Prec@1 99.219 (97.828)	Prec@5 100.000 (99.867)
 * Prec@1 97.850 Prec@5 99.883
Epoch: [6][0/422]  Time 2.08 (2.08)  Loss 0.4575 (0.4575)  Prec@1 96.094 (96.094)  Prec@5 98.438 (98.438)
Epoch: [6][10/422]  Time 1.57 (1.71)  Loss 0.3576 (0.4186)  Prec@1 96.094 (95.455)  Prec@5 99.219 (99.077)
Epoch: [6][20/422]  Time 1.56 (1.66)  Loss 0.4256 (0.4231)  Prec@1 96.875 (95.275)  Prec@5 99.219 (99.293)
Epoch: [6][30/422]  Time 1.56 (1.63)  Loss 0.4797 (0.4277)  Prec@1 92.969 (94.960)  Prec@5 100.000 (99.294)
Epoch: [6][40/422]  Time 1.54 (1.62)  Loss 0.4166 (0.4323)  Prec@1 95.312 (94.703)  Prec@5 99.219 (99.295)
Epoch: [6][50/422]  Time 1.56 (1.61)  Loss 0.3584 (0.4338)  Prec@1 96.875 (94.669)  Prec@5 98.438 (99.311)
Epoch: [6][60/422]  Time 1.55 (1.61)  Loss 0.3811 (0.4322)  Prec@1 96.094 (94.621)  Prec@5 100.000 (99.385)
Epoch: [6][70/422]  Time 1.58 (1.60)  Loss 0.4199 (0.4342)  Prec@1 95.312 (94.575)  Prec@5 99.219 (99.373)
Epoch: [6][80/422]  Time 1.57 (1.60)  Loss 0.4784 (0.4299)  Prec@1 92.188 (94.666)  Prec@5 100.000 (99.383)
Epoch: [6][90/422]  Time 1.56 (1.60)  Loss 0.4594 (0.4320)  Prec@1 94.531 (94.566)  Prec@5 99.219 (99.399)
Epoch: [6][100/422]  Time 1.59 (1.59)  Loss 0.3867 (0.4339)  Prec@1 96.875 (94.485)  Prec@5 100.000 (99.412)
Epoch: [6][110/422]  Time 1.56 (1.59)  Loss 0.3682 (0.4328)  Prec@1 97.656 (94.383)  Prec@5 100.000 (99.451)
Epoch: [6][120/422]  Time 1.59 (1.59)  Loss 0.5570 (0.4355)  Prec@1 91.406 (94.292)  Prec@5 97.656 (99.400)
Epoch: [6][130/422]  Time 1.56 (1.59)  Loss 0.4654 (0.4350)  Prec@1 96.094 (94.370)  Prec@5 100.000 (99.422)
Epoch: [6][140/422]  Time 1.55 (1.59)  Loss 0.3688 (0.4339)  Prec@1 96.875 (94.448)  Prec@5 100.000 (99.440)
Epoch: [6][150/422]  Time 1.66 (1.59)  Loss 0.3817 (0.4341)  Prec@1 96.094 (94.469)  Prec@5 99.219 (99.431)
Epoch: [6][160/422]  Time 1.59 (1.59)  Loss 0.4158 (0.4331)  Prec@1 94.531 (94.483)  Prec@5 98.438 (99.423)
Epoch: [6][170/422]  Time 1.58 (1.59)  Loss 0.3556 (0.4300)  Prec@1 96.875 (94.600)  Prec@5 100.000 (99.447)
Epoch: [6][180/422]  Time 1.66 (1.59)  Loss 0.4647 (0.4285)  Prec@1 92.188 (94.631)  Prec@5 99.219 (99.465)
Epoch: [6][190/422]  Time 1.57 (1.59)  Loss 0.3525 (0.4280)  Prec@1 95.312 (94.646)  Prec@5 100.000 (99.456)
Epoch: [6][200/422]  Time 1.57 (1.59)  Loss 0.3761 (0.4284)  Prec@1 97.656 (94.632)  Prec@5 100.000 (99.444)
Epoch: [6][210/422]  Time 1.69 (1.59)  Loss 0.4243 (0.4278)  Prec@1 96.094 (94.602)  Prec@5 98.438 (99.437)
Epoch: [6][220/422]  Time 1.75 (1.59)  Loss 0.4361 (0.4279)  Prec@1 92.188 (94.584)  Prec@5 99.219 (99.434)
Epoch: [6][230/422]  Time 1.57 (1.59)  Loss 0.5009 (0.4282)  Prec@1 92.969 (94.552)  Prec@5 98.438 (99.422)
Epoch: [6][240/422]  Time 1.57 (1.59)  Loss 0.3917 (0.4266)  Prec@1 96.875 (94.586)  Prec@5 100.000 (99.439)
Epoch: [6][250/422]  Time 1.58 (1.59)  Loss 0.5075 (0.4263)  Prec@1 88.281 (94.597)  Prec@5 98.438 (99.437)
Epoch: [6][260/422]  Time 1.81 (1.60)  Loss 0.3622 (0.4253)  Prec@1 96.094 (94.639)  Prec@5 100.000 (99.434)
Epoch: [6][270/422]  Time 1.83 (1.61)  Loss 0.4138 (0.4252)  Prec@1 93.750 (94.612)  Prec@5 100.000 (99.429)
Epoch: [6][280/422]  Time 1.85 (1.62)  Loss 0.4015 (0.4242)  Prec@1 97.656 (94.629)  Prec@5 99.219 (99.433)
Epoch: [6][290/422]  Time 1.84 (1.62)  Loss 0.4829 (0.4242)  Prec@1 95.312 (94.657)  Prec@5 99.219 (99.436)
Epoch: [6][300/422]  Time 1.81 (1.63)  Loss 0.3305 (0.4227)  Prec@1 95.312 (94.677)  Prec@5 100.000 (99.450)
Epoch: [6][310/422]  Time 2.01 (1.64)  Loss 0.3220 (0.4228)  Prec@1 96.875 (94.679)  Prec@5 100.000 (99.455)
Epoch: [6][320/422]  Time 1.80 (1.64)  Loss 0.5319 (0.4232)  Prec@1 90.625 (94.629)  Prec@5 98.438 (99.462)
Epoch: [6][330/422]  Time 1.83 (1.65)  Loss 0.5427 (0.4226)  Prec@1 91.406 (94.635)  Prec@5 100.000 (99.462)
Epoch: [6][340/422]  Time 1.58 (1.65)  Loss 0.3533 (0.4213)  Prec@1 96.875 (94.660)  Prec@5 100.000 (99.468)
Epoch: [6][350/422]  Time 1.59 (1.65)  Loss 0.3829 (0.4213)  Prec@1 95.312 (94.651)  Prec@5 100.000 (99.475)
Epoch: [6][360/422]  Time 1.58 (1.65)  Loss 0.3725 (0.4209)  Prec@1 94.531 (94.676)  Prec@5 99.219 (99.474)
Epoch: [6][370/422]  Time 1.59 (1.64)  Loss 0.4288 (0.4214)  Prec@1 94.531 (94.666)  Prec@5 100.000 (99.480)
Epoch: [6][380/422]  Time 1.62 (1.64)  Loss 0.3715 (0.4206)  Prec@1 96.094 (94.697)  Prec@5 100.000 (99.487)
Epoch: [6][390/422]  Time 1.57 (1.64)  Loss 0.3342 (0.4198)  Prec@1 96.875 (94.715)  Prec@5 100.000 (99.494)
Epoch: [6][400/422]  Time 1.58 (1.64)  Loss 0.3918 (0.4207)  Prec@1 96.094 (94.693)  Prec@5 100.000 (99.480)
Epoch: [6][410/422]  Time 1.57 (1.64)  Loss 0.3128 (0.4205)  Prec@1 96.875 (94.700)  Prec@5 100.000 (99.481)
Epoch: [6][420/422]  Time 1.67 (1.64)  Loss 0.4276 (0.4201)  Prec@1 92.969 (94.709)  Prec@5 98.438 (99.480)
Test: [0/47]	Time 0.380 (0.380)	Loss 0.1113 (0.1113)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
Test: [10/47]	Time 0.091 (0.123)	Loss 0.0674 (0.0848)	Prec@1 96.875 (97.727)	Prec@5 100.000 (99.929)
Test: [20/47]	Time 0.095 (0.109)	Loss 0.0174 (0.0831)	Prec@1 99.219 (97.805)	Prec@5 100.000 (99.888)
Test: [30/47]	Time 0.091 (0.104)	Loss 0.1452 (0.0883)	Prec@1 96.875 (97.707)	Prec@5 99.219 (99.874)
Test: [40/47]	Time 0.072 (0.100)	Loss 0.0100 (0.0815)	Prec@1 100.000 (97.885)	Prec@5 100.000 (99.905)
 * Prec@1 97.933 Prec@5 99.917
Epoch: [7][0/422]  Time 1.87 (1.87)  Loss 0.3338 (0.3338)  Prec@1 97.656 (97.656)  Prec@5 100.000 (100.000)
Epoch: [7][10/422]  Time 1.58 (1.64)  Loss 0.3394 (0.4032)  Prec@1 96.875 (95.526)  Prec@5 100.000 (99.574)
Epoch: [7][20/422]  Time 1.56 (1.63)  Loss 0.4577 (0.4110)  Prec@1 93.750 (95.089)  Prec@5 99.219 (99.479)
Epoch: [7][30/422]  Time 1.56 (1.61)  Loss 0.3843 (0.4168)  Prec@1 93.750 (94.859)  Prec@5 99.219 (99.420)
Epoch: [7][40/422]  Time 1.57 (1.60)  Loss 0.3353 (0.4160)  Prec@1 96.875 (94.912)  Prec@5 100.000 (99.466)
Epoch: [7][50/422]  Time 1.56 (1.60)  Loss 0.3985 (0.4154)  Prec@1 95.312 (94.945)  Prec@5 100.000 (99.494)
Epoch: [7][60/422]  Time 1.56 (1.60)  Loss 0.4347 (0.4170)  Prec@1 93.750 (94.826)  Prec@5 100.000 (99.488)
Epoch: [7][70/422]  Time 1.68 (1.60)  Loss 0.4679 (0.4163)  Prec@1 93.750 (94.795)  Prec@5 98.438 (99.472)
Epoch: [7][80/422]  Time 1.58 (1.59)  Loss 0.4152 (0.4151)  Prec@1 93.750 (94.830)  Prec@5 100.000 (99.508)
Epoch: [7][90/422]  Time 1.56 (1.59)  Loss 0.3463 (0.4110)  Prec@1 96.094 (94.978)  Prec@5 99.219 (99.536)
Epoch: [7][100/422]  Time 1.57 (1.59)  Loss 0.4918 (0.4158)  Prec@1 92.969 (94.779)  Prec@5 99.219 (99.497)
Epoch: [7][110/422]  Time 1.56 (1.59)  Loss 0.3986 (0.4163)  Prec@1 96.094 (94.813)  Prec@5 100.000 (99.521)
Epoch: [7][120/422]  Time 1.59 (1.59)  Loss 0.4022 (0.4167)  Prec@1 96.094 (94.809)  Prec@5 99.219 (99.522)
Epoch: [7][130/422]  Time 1.57 (1.59)  Loss 0.4057 (0.4168)  Prec@1 96.094 (94.812)  Prec@5 100.000 (99.529)
Epoch: [7][140/422]  Time 1.58 (1.59)  Loss 0.4355 (0.4161)  Prec@1 93.750 (94.842)  Prec@5 99.219 (99.529)
Epoch: [7][150/422]  Time 1.57 (1.59)  Loss 0.4009 (0.4164)  Prec@1 96.094 (94.800)  Prec@5 100.000 (99.545)
Epoch: [7][160/422]  Time 1.58 (1.59)  Loss 0.4123 (0.4173)  Prec@1 94.531 (94.784)  Prec@5 100.000 (99.544)
Epoch: [7][170/422]  Time 1.58 (1.59)  Loss 0.4932 (0.4181)  Prec@1 90.625 (94.732)  Prec@5 99.219 (99.548)
Epoch: [7][180/422]  Time 1.68 (1.59)  Loss 0.3941 (0.4186)  Prec@1 95.312 (94.708)  Prec@5 100.000 (99.542)
Epoch: [7][190/422]  Time 1.58 (1.59)  Loss 0.3550 (0.4170)  Prec@1 95.312 (94.785)  Prec@5 100.000 (99.550)
Epoch: [7][200/422]  Time 1.57 (1.59)  Loss 0.4454 (0.4182)  Prec@1 96.094 (94.768)  Prec@5 99.219 (99.534)
Epoch: [7][210/422]  Time 1.69 (1.59)  Loss 0.4963 (0.4191)  Prec@1 94.531 (94.768)  Prec@5 99.219 (99.511)
Epoch: [7][220/422]  Time 1.76 (1.59)  Loss 0.4972 (0.4188)  Prec@1 94.531 (94.775)  Prec@5 99.219 (99.505)
Epoch: [7][230/422]  Time 1.57 (1.59)  Loss 0.3983 (0.4166)  Prec@1 96.875 (94.853)  Prec@5 100.000 (99.516)
Epoch: [7][240/422]  Time 1.66 (1.59)  Loss 0.4046 (0.4167)  Prec@1 94.531 (94.846)  Prec@5 100.000 (99.527)
Epoch: [7][250/422]  Time 1.57 (1.59)  Loss 0.3066 (0.4157)  Prec@1 97.656 (94.864)  Prec@5 100.000 (99.527)
Epoch: [7][260/422]  Time 1.56 (1.59)  Loss 0.3389 (0.4155)  Prec@1 97.656 (94.881)  Prec@5 99.219 (99.524)
Epoch: [7][270/422]  Time 1.60 (1.59)  Loss 0.4398 (0.4149)  Prec@1 94.531 (94.874)  Prec@5 99.219 (99.524)
Epoch: [7][280/422]  Time 1.61 (1.59)  Loss 0.4061 (0.4147)  Prec@1 94.531 (94.882)  Prec@5 99.219 (99.536)
Epoch: [7][290/422]  Time 1.58 (1.59)  Loss 0.3458 (0.4147)  Prec@1 96.875 (94.910)  Prec@5 100.000 (99.544)
Epoch: [7][300/422]  Time 1.56 (1.59)  Loss 0.3761 (0.4158)  Prec@1 96.094 (94.861)  Prec@5 100.000 (99.551)
Epoch: [7][310/422]  Time 1.70 (1.59)  Loss 0.4175 (0.4156)  Prec@1 92.969 (94.883)  Prec@5 99.219 (99.550)
Epoch: [7][320/422]  Time 1.57 (1.59)  Loss 0.4481 (0.4150)  Prec@1 94.531 (94.891)  Prec@5 99.219 (99.555)
Epoch: [7][330/422]  Time 1.60 (1.59)  Loss 0.3824 (0.4144)  Prec@1 96.094 (94.914)  Prec@5 100.000 (99.559)
Epoch: [7][340/422]  Time 1.59 (1.59)  Loss 0.4680 (0.4140)  Prec@1 94.531 (94.921)  Prec@5 99.219 (99.562)
Epoch: [7][350/422]  Time 1.59 (1.59)  Loss 0.3171 (0.4136)  Prec@1 96.094 (94.914)  Prec@5 100.000 (99.559)
Epoch: [7][360/422]  Time 1.56 (1.59)  Loss 0.3858 (0.4134)  Prec@1 95.312 (94.923)  Prec@5 100.000 (99.559)
Epoch: [7][370/422]  Time 1.58 (1.59)  Loss 0.3052 (0.4126)  Prec@1 99.219 (94.957)  Prec@5 100.000 (99.564)
Epoch: [7][380/422]  Time 1.63 (1.59)  Loss 0.4737 (0.4134)  Prec@1 92.969 (94.937)  Prec@5 99.219 (99.553)
Epoch: [7][390/422]  Time 1.58 (1.59)  Loss 0.4654 (0.4134)  Prec@1 93.750 (94.947)  Prec@5 99.219 (99.552)
Epoch: [7][400/422]  Time 1.58 (1.59)  Loss 0.4512 (0.4134)  Prec@1 92.969 (94.936)  Prec@5 99.219 (99.554)
Epoch: [7][410/422]  Time 1.68 (1.59)  Loss 0.3980 (0.4138)  Prec@1 92.969 (94.913)  Prec@5 100.000 (99.551)
Epoch: [7][420/422]  Time 1.55 (1.59)  Loss 0.4277 (0.4137)  Prec@1 94.531 (94.904)  Prec@5 100.000 (99.547)
Test: [0/47]	Time 0.384 (0.384)	Loss 0.0442 (0.0442)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
Test: [10/47]	Time 0.097 (0.125)	Loss 0.0929 (0.0551)	Prec@1 96.875 (98.295)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.095 (0.109)	Loss 0.0821 (0.0721)	Prec@1 96.875 (97.917)	Prec@5 100.000 (99.963)
Test: [30/47]	Time 0.090 (0.104)	Loss 0.1277 (0.0749)	Prec@1 97.656 (97.908)	Prec@5 100.000 (99.950)
Test: [40/47]	Time 0.072 (0.100)	Loss 0.1170 (0.0780)	Prec@1 95.312 (97.713)	Prec@5 100.000 (99.943)
 * Prec@1 97.750 Prec@5 99.950
Epoch: [8][0/422]  Time 1.90 (1.90)  Loss 0.3882 (0.3882)  Prec@1 93.750 (93.750)  Prec@5 99.219 (99.219)
Epoch: [8][10/422]  Time 1.59 (1.65)  Loss 0.3901 (0.3899)  Prec@1 95.312 (95.526)  Prec@5 99.219 (99.645)
Epoch: [8][20/422]  Time 1.56 (1.63)  Loss 0.5128 (0.3993)  Prec@1 89.062 (95.312)  Prec@5 100.000 (99.554)
Epoch: [8][30/422]  Time 1.56 (1.61)  Loss 0.3820 (0.4033)  Prec@1 96.875 (95.338)  Prec@5 99.219 (99.572)
Epoch: [8][40/422]  Time 1.57 (1.60)  Loss 0.3005 (0.3919)  Prec@1 98.438 (95.713)  Prec@5 100.000 (99.619)
Epoch: [8][50/422]  Time 1.57 (1.60)  Loss 0.4939 (0.3999)  Prec@1 92.188 (95.466)  Prec@5 99.219 (99.586)
Epoch: [8][60/422]  Time 1.65 (1.60)  Loss 0.5069 (0.3987)  Prec@1 92.188 (95.530)  Prec@5 98.438 (99.565)
Epoch: [8][70/422]  Time 1.57 (1.60)  Loss 0.3507 (0.3996)  Prec@1 95.312 (95.445)  Prec@5 99.219 (99.571)
Epoch: [8][80/422]  Time 1.58 (1.60)  Loss 0.3786 (0.4005)  Prec@1 97.656 (95.409)  Prec@5 100.000 (99.585)
Epoch: [8][90/422]  Time 1.57 (1.60)  Loss 0.3728 (0.4013)  Prec@1 96.094 (95.407)  Prec@5 100.000 (99.596)
Epoch: [8][100/422]  Time 1.57 (1.59)  Loss 0.4149 (0.3998)  Prec@1 92.969 (95.336)  Prec@5 99.219 (99.613)
Epoch: [8][110/422]  Time 1.57 (1.59)  Loss 0.2657 (0.4001)  Prec@1 99.219 (95.298)  Prec@5 100.000 (99.613)
Epoch: [8][120/422]  Time 1.61 (1.59)  Loss 0.4838 (0.4040)  Prec@1 92.969 (95.151)  Prec@5 98.438 (99.587)
Epoch: [8][130/422]  Time 1.58 (1.59)  Loss 0.3928 (0.4025)  Prec@1 96.094 (95.217)  Prec@5 100.000 (99.594)
Epoch: [8][140/422]  Time 1.58 (1.59)  Loss 0.3561 (0.4037)  Prec@1 97.656 (95.157)  Prec@5 100.000 (99.601)
Epoch: [8][150/422]  Time 1.57 (1.59)  Loss 0.4134 (0.4068)  Prec@1 96.875 (95.038)  Prec@5 99.219 (99.565)
Epoch: [8][160/422]  Time 1.58 (1.59)  Loss 0.4117 (0.4067)  Prec@1 90.625 (95.036)  Prec@5 99.219 (99.573)
Epoch: [8][170/422]  Time 1.57 (1.59)  Loss 0.4320 (0.4063)  Prec@1 95.312 (95.070)  Prec@5 99.219 (99.580)
Epoch: [8][180/422]  Time 1.68 (1.59)  Loss 0.3880 (0.4054)  Prec@1 94.531 (95.084)  Prec@5 100.000 (99.586)
Epoch: [8][190/422]  Time 1.56 (1.59)  Loss 0.4014 (0.4056)  Prec@1 92.969 (95.088)  Prec@5 100.000 (99.579)
Epoch: [8][200/422]  Time 1.57 (1.59)  Loss 0.3281 (0.4053)  Prec@1 95.312 (95.114)  Prec@5 100.000 (99.580)
Epoch: [8][210/422]  Time 1.68 (1.59)  Loss 0.4110 (0.4042)  Prec@1 93.750 (95.113)  Prec@5 100.000 (99.593)
Epoch: [8][220/422]  Time 1.75 (1.59)  Loss 0.3477 (0.4047)  Prec@1 96.094 (95.097)  Prec@5 100.000 (99.593)
Epoch: [8][230/422]  Time 1.67 (1.59)  Loss 0.3760 (0.4049)  Prec@1 95.312 (95.062)  Prec@5 100.000 (99.594)
Epoch: [8][240/422]  Time 1.57 (1.59)  Loss 0.3590 (0.4054)  Prec@1 96.094 (95.047)  Prec@5 100.000 (99.601)
Epoch: [8][250/422]  Time 1.58 (1.59)  Loss 0.4886 (0.4055)  Prec@1 93.750 (95.048)  Prec@5 99.219 (99.592)
Epoch: [8][260/422]  Time 1.58 (1.59)  Loss 0.3595 (0.4064)  Prec@1 96.875 (95.052)  Prec@5 100.000 (99.575)
Epoch: [8][270/422]  Time 1.59 (1.59)  Loss 0.4296 (0.4065)  Prec@1 94.531 (95.024)  Prec@5 100.000 (99.582)
Epoch: [8][280/422]  Time 1.62 (1.59)  Loss 0.3431 (0.4065)  Prec@1 94.531 (95.018)  Prec@5 100.000 (99.583)
Epoch: [8][290/422]  Time 1.58 (1.59)  Loss 0.3950 (0.4067)  Prec@1 96.875 (95.012)  Prec@5 99.219 (99.573)
Epoch: [8][300/422]  Time 1.57 (1.59)  Loss 0.4111 (0.4063)  Prec@1 95.312 (95.027)  Prec@5 99.219 (99.569)
Epoch: [8][310/422]  Time 1.68 (1.59)  Loss 0.3922 (0.4060)  Prec@1 96.875 (95.031)  Prec@5 100.000 (99.578)
Epoch: [8][320/422]  Time 1.58 (1.59)  Loss 0.3835 (0.4056)  Prec@1 96.875 (95.052)  Prec@5 98.438 (99.581)
Epoch: [8][330/422]  Time 1.59 (1.59)  Loss 0.3792 (0.4051)  Prec@1 93.750 (95.041)  Prec@5 100.000 (99.573)
Epoch: [8][340/422]  Time 1.58 (1.59)  Loss 0.5213 (0.4051)  Prec@1 88.281 (95.024)  Prec@5 99.219 (99.572)
Epoch: [8][350/422]  Time 1.59 (1.59)  Loss 0.3307 (0.4047)  Prec@1 96.875 (95.039)  Prec@5 99.219 (99.564)
Epoch: [8][360/422]  Time 1.57 (1.59)  Loss 0.4935 (0.4054)  Prec@1 94.531 (95.025)  Prec@5 97.656 (99.556)
Epoch: [8][370/422]  Time 1.60 (1.59)  Loss 0.3936 (0.4054)  Prec@1 94.531 (95.016)  Prec@5 99.219 (99.551)
Epoch: [8][380/422]  Time 1.70 (1.59)  Loss 0.4048 (0.4053)  Prec@1 92.969 (94.995)  Prec@5 100.000 (99.553)
Epoch: [8][390/422]  Time 1.56 (1.59)  Loss 0.4127 (0.4052)  Prec@1 94.531 (94.987)  Prec@5 99.219 (99.548)
Epoch: [8][400/422]  Time 1.58 (1.59)  Loss 0.3464 (0.4050)  Prec@1 94.531 (94.974)  Prec@5 100.000 (99.542)
Epoch: [8][410/422]  Time 1.57 (1.59)  Loss 0.3955 (0.4045)  Prec@1 94.531 (94.993)  Prec@5 100.000 (99.546)
Epoch: [8][420/422]  Time 1.54 (1.59)  Loss 0.4659 (0.4046)  Prec@1 92.969 (94.990)  Prec@5 100.000 (99.543)
Test: [0/47]	Time 0.385 (0.385)	Loss 0.0883 (0.0883)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
Test: [10/47]	Time 0.093 (0.127)	Loss 0.0904 (0.0884)	Prec@1 97.656 (97.727)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.093 (0.111)	Loss 0.0544 (0.0780)	Prec@1 97.656 (97.768)	Prec@5 100.000 (99.926)
Test: [30/47]	Time 0.090 (0.106)	Loss 0.1363 (0.0827)	Prec@1 97.656 (97.833)	Prec@5 100.000 (99.950)
Test: [40/47]	Time 0.071 (0.101)	Loss 0.0149 (0.0753)	Prec@1 100.000 (97.999)	Prec@5 100.000 (99.962)
 * Prec@1 97.967 Prec@5 99.933
Epoch: [9][0/422]  Time 2.06 (2.06)  Loss 0.4411 (0.4411)  Prec@1 91.406 (91.406)  Prec@5 99.219 (99.219)
Epoch: [9][10/422]  Time 1.58 (1.71)  Loss 0.4217 (0.4212)  Prec@1 95.312 (93.679)  Prec@5 98.438 (99.432)
Epoch: [9][20/422]  Time 1.57 (1.67)  Loss 0.2843 (0.3980)  Prec@1 99.219 (94.978)  Prec@5 100.000 (99.628)
Epoch: [9][30/422]  Time 1.67 (1.64)  Loss 0.4316 (0.3998)  Prec@1 92.969 (95.035)  Prec@5 98.438 (99.521)
Epoch: [9][40/422]  Time 1.57 (1.62)  Loss 0.4952 (0.4057)  Prec@1 91.406 (94.912)  Prec@5 97.656 (99.486)
Epoch: [9][50/422]  Time 1.58 (1.62)  Loss 0.3930 (0.4041)  Prec@1 95.312 (94.945)  Prec@5 100.000 (99.540)
Epoch: [9][60/422]  Time 1.55 (1.61)  Loss 0.3435 (0.3992)  Prec@1 96.094 (95.069)  Prec@5 100.000 (99.590)
Epoch: [9][70/422]  Time 1.57 (1.61)  Loss 0.3541 (0.4032)  Prec@1 94.531 (94.916)  Prec@5 100.000 (99.549)
Epoch: [9][80/422]  Time 1.57 (1.60)  Loss 0.3851 (0.4015)  Prec@1 93.750 (94.965)  Prec@5 100.000 (99.566)
Epoch: [9][90/422]  Time 1.57 (1.60)  Loss 0.3883 (0.3985)  Prec@1 97.656 (95.038)  Prec@5 100.000 (99.596)
Epoch: [9][100/422]  Time 1.58 (1.60)  Loss 0.3382 (0.3972)  Prec@1 96.094 (95.142)  Prec@5 100.000 (99.606)
Epoch: [9][110/422]  Time 1.56 (1.60)  Loss 0.3636 (0.3990)  Prec@1 96.875 (95.108)  Prec@5 99.219 (99.592)
Epoch: [9][120/422]  Time 1.60 (1.60)  Loss 0.4248 (0.3992)  Prec@1 94.531 (95.138)  Prec@5 100.000 (99.561)
Epoch: [9][130/422]  Time 1.57 (1.60)  Loss 0.3242 (0.3996)  Prec@1 97.656 (95.104)  Prec@5 100.000 (99.559)
Epoch: [9][140/422]  Time 1.58 (1.59)  Loss 0.3347 (0.3983)  Prec@1 96.875 (95.113)  Prec@5 100.000 (99.573)
Epoch: [9][150/422]  Time 1.59 (1.59)  Loss 0.4118 (0.3985)  Prec@1 94.531 (95.116)  Prec@5 99.219 (99.571)
Epoch: [9][160/422]  Time 1.58 (1.59)  Loss 0.5407 (0.3989)  Prec@1 93.750 (95.094)  Prec@5 99.219 (99.578)
Epoch: [9][170/422]  Time 1.57 (1.59)  Loss 0.4351 (0.3991)  Prec@1 94.531 (95.084)  Prec@5 98.438 (99.566)
Epoch: [9][180/422]  Time 1.66 (1.59)  Loss 0.3977 (0.3991)  Prec@1 93.750 (95.062)  Prec@5 100.000 (99.581)
Epoch: [9][190/422]  Time 1.56 (1.59)  Loss 0.3178 (0.3982)  Prec@1 97.656 (95.059)  Prec@5 100.000 (99.591)
Epoch: [9][200/422]  Time 1.67 (1.60)  Loss 0.3672 (0.3986)  Prec@1 96.875 (95.064)  Prec@5 100.000 (99.580)
Epoch: [9][210/422]  Time 1.69 (1.59)  Loss 0.3316 (0.3981)  Prec@1 95.312 (95.053)  Prec@5 100.000 (99.574)
Epoch: [9][220/422]  Time 1.76 (1.60)  Loss 0.3330 (0.3980)  Prec@1 96.875 (95.054)  Prec@5 100.000 (99.569)
Epoch: [9][230/422]  Time 1.57 (1.59)  Loss 0.3394 (0.3987)  Prec@1 96.094 (95.015)  Prec@5 100.000 (99.570)
Epoch: [9][240/422]  Time 1.55 (1.59)  Loss 0.4442 (0.3976)  Prec@1 91.406 (95.043)  Prec@5 99.219 (99.579)
Epoch: [9][250/422]  Time 1.57 (1.59)  Loss 0.3981 (0.3970)  Prec@1 92.969 (95.057)  Prec@5 98.438 (99.574)
Epoch: [9][260/422]  Time 1.57 (1.59)  Loss 0.3361 (0.3980)  Prec@1 96.094 (95.031)  Prec@5 100.000 (99.572)
Epoch: [9][270/422]  Time 1.59 (1.59)  Loss 0.4764 (0.3987)  Prec@1 92.188 (95.010)  Prec@5 99.219 (99.565)
Epoch: [9][280/422]  Time 1.61 (1.59)  Loss 0.3992 (0.3991)  Prec@1 96.094 (95.032)  Prec@5 99.219 (99.552)
Epoch: [9][290/422]  Time 1.57 (1.59)  Loss 0.4226 (0.3993)  Prec@1 95.312 (95.060)  Prec@5 98.438 (99.546)
Epoch: [9][300/422]  Time 1.56 (1.59)  Loss 0.3747 (0.3992)  Prec@1 93.750 (95.058)  Prec@5 99.219 (99.546)
Epoch: [9][310/422]  Time 1.70 (1.59)  Loss 0.2909 (0.3983)  Prec@1 96.875 (95.081)  Prec@5 100.000 (99.545)
Epoch: [9][320/422]  Time 1.56 (1.59)  Loss 0.4215 (0.3979)  Prec@1 92.969 (95.072)  Prec@5 99.219 (99.552)
Epoch: [9][330/422]  Time 1.59 (1.59)  Loss 0.4259 (0.3974)  Prec@1 93.750 (95.093)  Prec@5 100.000 (99.559)
Epoch: [9][340/422]  Time 1.57 (1.59)  Loss 0.3447 (0.3974)  Prec@1 98.438 (95.093)  Prec@5 100.000 (99.558)
Epoch: [9][350/422]  Time 1.58 (1.59)  Loss 0.3303 (0.3976)  Prec@1 95.312 (95.099)  Prec@5 100.000 (99.553)
Epoch: [9][360/422]  Time 1.81 (1.60)  Loss 0.3761 (0.3977)  Prec@1 95.312 (95.083)  Prec@5 99.219 (99.552)
Epoch: [9][370/422]  Time 1.83 (1.61)  Loss 0.3685 (0.3983)  Prec@1 96.875 (95.075)  Prec@5 100.000 (99.547)
Epoch: [9][380/422]  Time 1.62 (1.61)  Loss 0.3883 (0.3986)  Prec@1 96.875 (95.068)  Prec@5 100.000 (99.543)
Epoch: [9][390/422]  Time 1.56 (1.61)  Loss 0.3881 (0.3986)  Prec@1 95.312 (95.087)  Prec@5 99.219 (99.534)
Epoch: [9][400/422]  Time 1.56 (1.60)  Loss 0.3221 (0.3983)  Prec@1 96.094 (95.100)  Prec@5 100.000 (99.532)
Epoch: [9][410/422]  Time 1.58 (1.60)  Loss 0.3158 (0.3989)  Prec@1 97.656 (95.084)  Prec@5 99.219 (99.523)
Epoch: [9][420/422]  Time 1.57 (1.60)  Loss 0.4262 (0.3990)  Prec@1 94.531 (95.082)  Prec@5 99.219 (99.523)
Test: [0/47]	Time 0.399 (0.399)	Loss 0.0319 (0.0319)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
Test: [10/47]	Time 0.097 (0.126)	Loss 0.0372 (0.0720)	Prec@1 99.219 (98.224)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.095 (0.111)	Loss 0.0616 (0.0690)	Prec@1 96.875 (98.214)	Prec@5 100.000 (100.000)
Test: [30/47]	Time 0.095 (0.105)	Loss 0.0673 (0.0731)	Prec@1 98.438 (98.110)	Prec@5 100.000 (99.950)
Test: [40/47]	Time 0.069 (0.103)	Loss 0.0272 (0.0712)	Prec@1 99.219 (98.056)	Prec@5 100.000 (99.943)
 * Prec@1 97.917 Prec@5 99.917
Training done
Test: [0/79]	Time 0.272 (0.272)	Loss 0.0116 (0.0116)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test: [10/79]	Time 0.093 (0.114)	Loss 0.1068 (0.0851)	Prec@1 95.312 (97.443)	Prec@5 100.000 (100.000)
Test: [20/79]	Time 0.091 (0.104)	Loss 0.0978 (0.1002)	Prec@1 97.656 (97.210)	Prec@5 100.000 (100.000)
Test: [30/79]	Time 0.093 (0.100)	Loss 0.1556 (0.0979)	Prec@1 95.312 (97.203)	Prec@5 100.000 (100.000)
Test: [40/79]	Time 0.092 (0.098)	Loss 0.0040 (0.0922)	Prec@1 100.000 (97.294)	Prec@5 100.000 (100.000)
Test: [50/79]	Time 0.094 (0.097)	Loss 0.0713 (0.0813)	Prec@1 99.219 (97.656)	Prec@5 100.000 (100.000)
Test: [60/79]	Time 0.092 (0.096)	Loss 0.0024 (0.0717)	Prec@1 100.000 (97.925)	Prec@5 100.000 (100.000)
Test: [70/79]	Time 0.073 (0.095)	Loss 0.1263 (0.0646)	Prec@1 96.094 (98.118)	Prec@5 100.000 (100.000)
 * Prec@1 98.160 Prec@5 100.000
Initializing GSENN wrapper.
Computing train data stats...
**** Performing black-box lipschitz estimation over subset of dataset ****
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1358
Function value obtained: -0.0059
Current minimum: -0.0059
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1329
Function value obtained: -0.0069
Current minimum: -0.0069
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1319
Function value obtained: -0.0066
Current minimum: -0.0069
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1324
Function value obtained: -0.0047
Current minimum: -0.0069
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1298
Function value obtained: -0.0092
Current minimum: -0.0092
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1295
Function value obtained: -0.0112
Current minimum: -0.0112
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1310
Function value obtained: -0.0146
Current minimum: -0.0146
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0086
Current minimum: -0.0146
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1303
Function value obtained: -0.0090
Current minimum: -0.0146
Iteration No: 10 started. Evaluating function at random point.
Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x2b05026cd7b8>>
Traceback (most recent call last):
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 399, in __del__
    self._shutdown_workers()
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 378, in _shutdown_workers
    self.worker_result_queue.get()
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/multiprocessing/queues.py", line 337, in get
    return _ForkingPickler.loads(res)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/multiprocessing/reductions.py", line 151, in rebuild_storage_fd
    fd = df.detach()
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/multiprocessing/connection.py", line 493, in Client
    answer_challenge(c, authkey)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/multiprocessing/connection.py", line 732, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError: 
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 10.2343
Function value obtained: -0.0072
Current minimum: -0.0146
0.014617717229878908 0.13889567455049048
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1328
Function value obtained: -0.0020
Current minimum: -0.0020
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1308
Function value obtained: -0.0036
Current minimum: -0.0036
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1301
Function value obtained: -0.0037
Current minimum: -0.0037
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1303
Function value obtained: -0.0031
Current minimum: -0.0037
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1301
Function value obtained: -0.0026
Current minimum: -0.0037
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1299
Function value obtained: -0.0031
Current minimum: -0.0037
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1305
Function value obtained: -0.0028
Current minimum: -0.0037
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1296
Function value obtained: -0.0021
Current minimum: -0.0037
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1309
Function value obtained: -0.0047
Current minimum: -0.0047
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.2327
Function value obtained: -0.0038
Current minimum: -0.0047
0.004656843065191348 0.1438231403360421
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1321
Function value obtained: -0.0039
Current minimum: -0.0039
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1316
Function value obtained: -0.0121
Current minimum: -0.0121
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1323
Function value obtained: -0.0025
Current minimum: -0.0121
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1322
Function value obtained: -0.0113
Current minimum: -0.0121
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1315
Function value obtained: -0.0105
Current minimum: -0.0121
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1313
Function value obtained: -0.0050
Current minimum: -0.0121
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1322
Function value obtained: -0.0099
Current minimum: -0.0121
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1315
Function value obtained: -0.0059
Current minimum: -0.0121
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1308
Function value obtained: -0.0100
Current minimum: -0.0121
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.1301
Function value obtained: -0.0082
Current minimum: -0.0121
0.012078284748718802 0.1370604076161647
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1323
Function value obtained: -0.0030
Current minimum: -0.0030
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1323
Function value obtained: -0.0081
Current minimum: -0.0081
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1322
Function value obtained: -0.0096
Current minimum: -0.0096
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1314
Function value obtained: -0.0100
Current minimum: -0.0100
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1303
Function value obtained: -0.0069
Current minimum: -0.0100
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1311
Function value obtained: -0.0074
Current minimum: -0.0100
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1306
Function value obtained: -0.0130
Current minimum: -0.0130
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1308
Function value obtained: -0.0106
Current minimum: -0.0130
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1309
Function value obtained: -0.0086
Current minimum: -0.0130
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.0690
Function value obtained: -0.0161
Current minimum: -0.0161
0.016085278665969156 0.130460428462684
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1326
Function value obtained: -0.0144
Current minimum: -0.0144
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1324
Function value obtained: -0.0186
Current minimum: -0.0186
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1302
Function value obtained: -0.0152
Current minimum: -0.0186
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1309
Function value obtained: -0.0137
Current minimum: -0.0186
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1308
Function value obtained: -0.0189
Current minimum: -0.0189
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1311
Function value obtained: -0.0130
Current minimum: -0.0189
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1303
Function value obtained: -0.0144
Current minimum: -0.0189
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1306
Function value obtained: -0.0151
Current minimum: -0.0189
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1312
Function value obtained: -0.0098
Current minimum: -0.0189
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.1107
Function value obtained: -0.0145
Current minimum: -0.0189
0.01894852564408068 0.13387411513922515
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1315
Function value obtained: -0.0070
Current minimum: -0.0070
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1306
Function value obtained: -0.0117
Current minimum: -0.0117
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1313
Function value obtained: -0.0096
Current minimum: -0.0117
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1320
Function value obtained: -0.0157
Current minimum: -0.0157
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1320
Function value obtained: -0.0137
Current minimum: -0.0157
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1315
Function value obtained: -0.0127
Current minimum: -0.0157
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1320
Function value obtained: -0.0139
Current minimum: -0.0157
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1321
Function value obtained: -0.0027
Current minimum: -0.0157
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1302
Function value obtained: -0.0099
Current minimum: -0.0157
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.3275
Function value obtained: -0.0156
Current minimum: -0.0157
0.015724053009023964 0.13818395848140136
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1322
Function value obtained: -0.0097
Current minimum: -0.0097
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1316
Function value obtained: -0.0137
Current minimum: -0.0137
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1315
Function value obtained: -0.0116
Current minimum: -0.0137
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1303
Function value obtained: -0.0067
Current minimum: -0.0137
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1303
Function value obtained: -0.0123
Current minimum: -0.0137
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1306
Function value obtained: -0.0108
Current minimum: -0.0137
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1310
Function value obtained: -0.0097
Current minimum: -0.0137
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1297
Function value obtained: -0.0071
Current minimum: -0.0137
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1311
Function value obtained: -0.0135
Current minimum: -0.0137
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.0844
Function value obtained: -0.0126
Current minimum: -0.0137
0.013698500185991155 0.13537563959326135
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1333
Function value obtained: -0.0061
Current minimum: -0.0061
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1323
Function value obtained: -0.0079
Current minimum: -0.0079
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1308
Function value obtained: -0.0059
Current minimum: -0.0079
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1305
Function value obtained: -0.0060
Current minimum: -0.0079
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1309
Function value obtained: -0.0055
Current minimum: -0.0079
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1302
Function value obtained: -0.0020
Current minimum: -0.0079
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1308
Function value obtained: -0.0051
Current minimum: -0.0079
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0032
Current minimum: -0.0079
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1313
Function value obtained: -0.0037
Current minimum: -0.0079
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.0189
Function value obtained: -0.0059
Current minimum: -0.0079
0.007929410681060012 0.1352107071475854
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1331
Function value obtained: -0.0069
Current minimum: -0.0069
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1319
Function value obtained: -0.0123
Current minimum: -0.0123
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1319
Function value obtained: -0.0062
Current minimum: -0.0123
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0009
Current minimum: -0.0123
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1309
Function value obtained: -0.0104
Current minimum: -0.0123
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1305
Function value obtained: -0.0075
Current minimum: -0.0123
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0050
Current minimum: -0.0123
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1304
Function value obtained: -0.0044
Current minimum: -0.0123
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0011
Current minimum: -0.0123
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.0454
Function value obtained: -0.0091
Current minimum: -0.0123
0.012305077941184269 0.13461485287556058
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1330
Function value obtained: -0.0113
Current minimum: -0.0113
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1320
Function value obtained: -0.0087
Current minimum: -0.0113
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1328
Function value obtained: -0.0082
Current minimum: -0.0113
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1320
Function value obtained: -0.0113
Current minimum: -0.0113
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1314
Function value obtained: -0.0101
Current minimum: -0.0113
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1315
Function value obtained: -0.0155
Current minimum: -0.0155
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1319
Function value obtained: -0.0077
Current minimum: -0.0155
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1304
Function value obtained: -0.0072
Current minimum: -0.0155
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1306
Function value obtained: -0.0121
Current minimum: -0.0155
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.0313
Function value obtained: -0.0097
Current minimum: -0.0155
0.015500796609216017 0.13666077888558734
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1314
Function value obtained: -0.0050
Current minimum: -0.0050
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1303
Function value obtained: -0.0043
Current minimum: -0.0050
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1306
Function value obtained: -0.0096
Current minimum: -0.0096
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1300
Function value obtained: -0.0134
Current minimum: -0.0134
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1311
Function value obtained: -0.0120
Current minimum: -0.0134
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1299
Function value obtained: -0.0059
Current minimum: -0.0134
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1308
Function value obtained: -0.0141
Current minimum: -0.0141
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0142
Current minimum: -0.0142
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1309
Function value obtained: -0.0043
Current minimum: -0.0142
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.0409
Function value obtained: -0.0112
Current minimum: -0.0142
0.014163535685564823 0.13401337909809322
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1328
Function value obtained: -0.0074
Current minimum: -0.0074
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0059
Current minimum: -0.0074
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1309
Function value obtained: -0.0086
Current minimum: -0.0086
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1310
Function value obtained: -0.0045
Current minimum: -0.0086
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1303
Function value obtained: -0.0073
Current minimum: -0.0086
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1313
Function value obtained: -0.0054
Current minimum: -0.0086
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1309
Function value obtained: -0.0066
Current minimum: -0.0086
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0049
Current minimum: -0.0086
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1306
Function value obtained: -0.0063
Current minimum: -0.0086
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.1323
Function value obtained: -0.0065
Current minimum: -0.0086
0.00861521428040103 0.1350216316687405
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1320
Function value obtained: -0.0093
Current minimum: -0.0093
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1330
Function value obtained: -0.0075
Current minimum: -0.0093
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1314
Function value obtained: -0.0057
Current minimum: -0.0093
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1317
Function value obtained: -0.0076
Current minimum: -0.0093
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1319
Function value obtained: -0.0096
Current minimum: -0.0096
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1306
Function value obtained: -0.0069
Current minimum: -0.0096
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1305
Function value obtained: -0.0077
Current minimum: -0.0096
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0075
Current minimum: -0.0096
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1302
Function value obtained: -0.0099
Current minimum: -0.0099
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.1639
Function value obtained: -0.0074
Current minimum: -0.0099
0.009935229200441733 0.13638413495542398
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1319
Function value obtained: -0.0118
Current minimum: -0.0118
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1326
Function value obtained: -0.0126
Current minimum: -0.0126
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1316
Function value obtained: -0.0096
Current minimum: -0.0126
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1311
Function value obtained: -0.0077
Current minimum: -0.0126
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1303
Function value obtained: -0.0072
Current minimum: -0.0126
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1310
Function value obtained: -0.0095
Current minimum: -0.0126
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1310
Function value obtained: -0.0163
Current minimum: -0.0163
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0083
Current minimum: -0.0163
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1306
Function value obtained: -0.0125
Current minimum: -0.0163
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.1422
Function value obtained: -0.0085
Current minimum: -0.0163
0.016287511483884385 0.13397718358547214
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1322
Function value obtained: -0.0350
Current minimum: -0.0350
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1306
Function value obtained: -0.0320
Current minimum: -0.0350
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1309
Function value obtained: -0.0430
Current minimum: -0.0430
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1310
Function value obtained: -0.0331
Current minimum: -0.0430
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1306
Function value obtained: -0.0478
Current minimum: -0.0478
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1309
Function value obtained: -0.0245
Current minimum: -0.0478
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0321
Current minimum: -0.0478
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0268
Current minimum: -0.0478
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1305
Function value obtained: -0.0343
Current minimum: -0.0478
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.2462
Function value obtained: -0.0420
Current minimum: -0.0478
0.0477576139318225 0.13377124193966508
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1323
Function value obtained: -0.0174
Current minimum: -0.0174
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1320
Function value obtained: -0.0158
Current minimum: -0.0174
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1308
Function value obtained: -0.0141
Current minimum: -0.0174
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1322
Function value obtained: -0.0163
Current minimum: -0.0174
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1321
Function value obtained: -0.0108
Current minimum: -0.0174
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1311
Function value obtained: -0.0058
Current minimum: -0.0174
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1304
Function value obtained: -0.0129
Current minimum: -0.0174
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1308
Function value obtained: -0.0145
Current minimum: -0.0174
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0133
Current minimum: -0.0174
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.1636
Function value obtained: -0.0088
Current minimum: -0.0174
0.01740241716550217 0.1351132724216068
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1320
Function value obtained: -0.0064
Current minimum: -0.0064
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1325
Function value obtained: -0.0037
Current minimum: -0.0064
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1321
Function value obtained: -0.0081
Current minimum: -0.0081
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1314
Function value obtained: -0.0047
Current minimum: -0.0081
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1306
Function value obtained: -0.0064
Current minimum: -0.0081
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1301
Function value obtained: -0.0061
Current minimum: -0.0081
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1308
Function value obtained: -0.0063
Current minimum: -0.0081
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1315
Function value obtained: -0.0062
Current minimum: -0.0081
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0078
Current minimum: -0.0081
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.0648
Function value obtained: -0.0078
Current minimum: -0.0081
0.008105781274210026 0.1369457555184467
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1336
Function value obtained: -0.0055
Current minimum: -0.0055
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1321
Function value obtained: -0.0213
Current minimum: -0.0213
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1320
Function value obtained: -0.0134
Current minimum: -0.0213
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1308
Function value obtained: -0.0105
Current minimum: -0.0213
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1309
Function value obtained: -0.0058
Current minimum: -0.0213
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0172
Current minimum: -0.0213
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1301
Function value obtained: -0.0090
Current minimum: -0.0213
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1305
Function value obtained: -0.0101
Current minimum: -0.0213
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1313
Function value obtained: -0.0094
Current minimum: -0.0213
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.0500
Function value obtained: -0.0173
Current minimum: -0.0213
0.02129067694194375 0.13739048163592327
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1328
Function value obtained: -0.0070
Current minimum: -0.0070
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0065
Current minimum: -0.0070
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1303
Function value obtained: -0.0071
Current minimum: -0.0071
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1306
Function value obtained: -0.0046
Current minimum: -0.0071
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0069
Current minimum: -0.0071
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1308
Function value obtained: -0.0023
Current minimum: -0.0071
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1301
Function value obtained: -0.0064
Current minimum: -0.0071
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1318
Function value obtained: -0.0045
Current minimum: -0.0071
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1309
Function value obtained: -0.0059
Current minimum: -0.0071
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.0287
Function value obtained: -0.0062
Current minimum: -0.0071
0.007117008057822198 0.14101685864770785
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1330
Function value obtained: -0.0199
Current minimum: -0.0199
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1303
Function value obtained: -0.0148
Current minimum: -0.0199
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1302
Function value obtained: -0.0216
Current minimum: -0.0216
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1308
Function value obtained: -0.0204
Current minimum: -0.0216
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1311
Function value obtained: -0.0189
Current minimum: -0.0216
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1300
Function value obtained: -0.0110
Current minimum: -0.0216
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1314
Function value obtained: -0.0213
Current minimum: -0.0216
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1304
Function value obtained: -0.0340
Current minimum: -0.0340
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1306
Function value obtained: -0.0107
Current minimum: -0.0340
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.0742
Function value obtained: -0.0140
Current minimum: -0.0340
0.03396451047118176 0.13512073003769287
Missed points: 0/20
> /home/lgpu0014/FACT/SENN/scripts/main_mnist.py(384)main()
-> Stability_dict = {'lips': lips}
(Pdb) 
/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.
  warnings.warn(message, FutureWarning)
/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.
  warnings.warn(message, FutureWarning)
/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "scripts/main_mnist.py", line 404, in <module>
    main()
  File "scripts/main_mnist.py", line 384, in main
    Stability_dict = {'lips': lips}
  File "scripts/main_mnist.py", line 384, in main
    Stability_dict = {'lips': lips}
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/bdb.py", line 51, in trace_dispatch
    return self.dispatch_line(frame)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/bdb.py", line 70, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
srun: error: r30n6: task 0: Exited with exit code 1

Parameters:
	BATCH_SIZE=128
	CONCEPT_DIM=1
	CUDA=True
	DATASET=pathology
	DATASETS=['heart', 'ionosphere', 'breast-cancer', 'wine', 'heart', 'glass', 'diabetes', 'yeast', 'leukemia', 'abalone']
	DEBUG=False
	DROPOUT=0.1
	EMBEDDING=pathology
	EPOCHS=10
	H_SPARSITY=0.0001
	H_TYPE=cnn
	LIP_CALLS=10
	LIP_EPS=0.01
	LIP_POINTS=100
	LISA=1
	LOAD_MODEL=False
	LOG_PATH=log
	LR=0.001
	MODEL_PATH=models
	NCLASSES=2
	NCONCEPTS=5
	NOBIAS=False
	NUM_GPUS=1
	NUM_WORKERS=4
	OBJECTIVE=cross_entropy
	OPT=adam
	OPTIM=gp
	POSITIVE_THETA=False
	PRINT_FREQ=10
	RESULTS_PATH=out
	SEED=2018
	SUMMARY_PATH=results/summary.csv
	TEST=False
	THETA_ARCH=simple
	THETA_DIM=-1
	THETA_REG_LAMBDA=0.01
	THETA_REG_TYPE=grad3
	TRAIN=True
	WEIGHT_DECAY=0.001
Model path out lisa_output/models/mnist/grad3_Hcnn_Thsimple_Cpts5_Reg1e-02_Sp0.0001_LR0.001
Traceback (most recent call last):
  File "scripts/main_mnist.py", line 404, in <module>
    main()
  File "scripts/main_mnist.py", line 257, in main
    trainer.train(train_loader, valid_loader, epochs = args.epochs, save_path = model_path)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/trainers.py", line 180, in train
    self.train_epoch(epoch, train_loader)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/trainers.py", line 248, in train_epoch
    outputs, loss, loss_dict = self.train_batch(inputs, targets)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/trainers.py", line 575, in train_batch
    pred = self.model(inputs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/models.py", line 221, in forward
    h_x, x_tilde = self.conceptizer(x)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/conceptizers.py", line 102, in forward
    encoded = self.encode(x)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/conceptizers.py", line 202, in encode
    p       = F.relu(F.max_pool2d(self.conv1(x), 2))
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 301, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #2 'weight'
srun: error: r31n3: task 0: Exited with exit code 1
srun: Job 4386967 step creation temporarily disabled, retrying
srun: Step created for job 4386967

Parameters:
	BATCH_SIZE=128
	CONCEPT_DIM=1
	CUDA=True
	DATASET=pathology
	DATASETS=['heart', 'ionosphere', 'breast-cancer', 'wine', 'heart', 'glass', 'diabetes', 'yeast', 'leukemia', 'abalone']
	DEBUG=False
	DROPOUT=0.1
	EMBEDDING=pathology
	EPOCHS=10
	H_SPARSITY=0.0001
	H_TYPE=cnn
	LIP_CALLS=10
	LIP_EPS=0.01
	LIP_POINTS=100
	LISA=1
	LOAD_MODEL=False
	LOG_PATH=log
	LR=0.001
	MODEL_PATH=models
	NCLASSES=2
	NCONCEPTS=5
	NOBIAS=False
	NUM_GPUS=1
	NUM_WORKERS=4
	OBJECTIVE=cross_entropy
	OPT=adam
	OPTIM=gp
	POSITIVE_THETA=False
	PRINT_FREQ=10
	RESULTS_PATH=out
	SEED=2018
	SUMMARY_PATH=results/summary.csv
	TEST=False
	THETA_ARCH=simple
	THETA_DIM=-1
	THETA_REG_LAMBDA=0.01
	THETA_REG_TYPE=grad3
	TRAIN=True
	WEIGHT_DECAY=0.001
Model path out lisa_output/models/mnist/grad3_Hcnn_Thsimple_Cpts5_Reg1e-02_Sp0.0001_LR0.001
Traceback (most recent call last):
  File "scripts/main_mnist.py", line 404, in <module>
    main()
  File "scripts/main_mnist.py", line 257, in main
    trainer.train(train_loader, valid_loader, epochs = args.epochs, save_path = model_path)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/trainers.py", line 180, in train
    self.train_epoch(epoch, train_loader)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/trainers.py", line 248, in train_epoch
    outputs, loss, loss_dict = self.train_batch(inputs, targets)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/trainers.py", line 575, in train_batch
    pred = self.model(inputs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/models.py", line 221, in forward
    h_x, x_tilde = self.conceptizer(x)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/conceptizers.py", line 102, in forward
    encoded = self.encode(x)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/conceptizers.py", line 202, in encode
    p       = F.relu(F.max_pool2d(self.conv1(x), 2))
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 301, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #2 'weight'
srun: error: r31n3: task 0: Exited with exit code 1

Parameters:
	BATCH_SIZE=128
	CONCEPT_DIM=1
	CUDA=True
	DATASET=pathology
	DATASETS=['heart', 'ionosphere', 'breast-cancer', 'wine', 'heart', 'glass', 'diabetes', 'yeast', 'leukemia', 'abalone']
	DEBUG=False
	DROPOUT=0.1
	EMBEDDING=pathology
	EPOCHS=10
	H_SPARSITY=0.0001
	H_TYPE=cnn
	LIP_CALLS=10
	LIP_EPS=0.01
	LIP_POINTS=100
	LISA=1
	LOAD_MODEL=False
	LOG_PATH=log
	LR=0.001
	MODEL_PATH=models
	NCLASSES=2
	NCONCEPTS=5
	NOBIAS=False
	NUM_GPUS=1
	NUM_WORKERS=4
	OBJECTIVE=cross_entropy
	OPT=adam
	OPTIM=gp
	POSITIVE_THETA=False
	PRINT_FREQ=10
	RESULTS_PATH=out
	SEED=2018
	SUMMARY_PATH=results/summary.csv
	TEST=False
	THETA_ARCH=simple
	THETA_DIM=-1
	THETA_REG_LAMBDA=0.01
	THETA_REG_TYPE=grad3
	TRAIN=True
	WEIGHT_DECAY=0.001
Model path out lisa_output/models/mnist/grad3_Hcnn_Thsimple_Cpts5_Reg1e-02_Sp0.0001_LR0.001
Traceback (most recent call last):
  File "scripts/main_mnist.py", line 404, in <module>
    main()
  File "scripts/main_mnist.py", line 257, in main
    trainer.train(train_loader, valid_loader, epochs = args.epochs, save_path = model_path)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/trainers.py", line 180, in train
    self.train_epoch(epoch, train_loader)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/trainers.py", line 248, in train_epoch
    outputs, loss, loss_dict = self.train_batch(inputs, targets)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/trainers.py", line 575, in train_batch
    pred = self.model(inputs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/models.py", line 221, in forward
    h_x, x_tilde = self.conceptizer(x)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/conceptizers.py", line 102, in forward
    encoded = self.encode(x)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/conceptizers.py", line 202, in encode
    p       = F.relu(F.max_pool2d(self.conv1(x), 2))
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 301, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #2 'weight'
srun: error: r31n3: task 0: Exited with exit code 1

Parameters:
	BATCH_SIZE=128
	CONCEPT_DIM=1
	CUDA=True
	DATASET=pathology
	DATASETS=['heart', 'ionosphere', 'breast-cancer', 'wine', 'heart', 'glass', 'diabetes', 'yeast', 'leukemia', 'abalone']
	DEBUG=False
	DROPOUT=0.1
	EMBEDDING=pathology
	EPOCHS=10
	H_SPARSITY=0.0001
	H_TYPE=cnn
	LIP_CALLS=10
	LIP_EPS=0.01
	LIP_POINTS=100
	LISA=1
	LOAD_MODEL=False
	LOG_PATH=log
	LR=0.001
	MODEL_PATH=models
	NCLASSES=2
	NCONCEPTS=5
	NOBIAS=False
	NUM_GPUS=1
	NUM_WORKERS=4
	OBJECTIVE=cross_entropy
	OPT=adam
	OPTIM=gp
	POSITIVE_THETA=False
	PRINT_FREQ=10
	RESULTS_PATH=out
	SEED=2018
	SUMMARY_PATH=results/summary.csv
	TEST=False
	THETA_ARCH=simple
	THETA_DIM=-1
	THETA_REG_LAMBDA=0.01
	THETA_REG_TYPE=grad3
	TRAIN=True
	WEIGHT_DECAY=0.001
Model path out lisa_output/models/mnist/grad3_Hcnn_Thsimple_Cpts5_Reg1e-02_Sp0.0001_LR0.001
Traceback (most recent call last):
  File "scripts/main_mnist.py", line 404, in <module>
    main()
  File "scripts/main_mnist.py", line 257, in main
    trainer.train(train_loader, valid_loader, epochs = args.epochs, save_path = model_path)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/trainers.py", line 180, in train
    self.train_epoch(epoch, train_loader)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/trainers.py", line 248, in train_epoch
    outputs, loss, loss_dict = self.train_batch(inputs, targets)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/trainers.py", line 575, in train_batch
    pred = self.model(inputs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/models.py", line 221, in forward
    h_x, x_tilde = self.conceptizer(x)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/conceptizers.py", line 102, in forward
    encoded = self.encode(x)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/conceptizers.py", line 202, in encode
    p       = F.relu(F.max_pool2d(self.conv1(x), 2))
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 301, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #2 'weight'
srun: error: r31n3: task 0: Exited with exit code 1
