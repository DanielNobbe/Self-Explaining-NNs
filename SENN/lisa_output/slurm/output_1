srun: Job 4385042 step creation temporarily disabled, retrying
srun: Step created for job 4385042

Parameters:
	BATCH_SIZE=128
	CONCEPT_DIM=1
	CUDA=False
	DATASET=pathology
	DATASETS=['heart', 'ionosphere', 'breast-cancer', 'wine', 'heart', 'glass', 'diabetes', 'yeast', 'leukemia', 'abalone']
	DEBUG=False
	DROPOUT=0.1
	EMBEDDING=pathology
	EPOCHS=10
	H_SPARSITY=0.0001
	H_TYPE=cnn
	LIP_CALLS=10
	LIP_EPS=0.01
	LIP_POINTS=100
	LISA=1
	LOAD_MODEL=False
	LOG_PATH=log
	LR=0.001
	MODEL_PATH=models
	NCLASSES=2
	NCONCEPTS=10
	NOBIAS=False
	NUM_GPUS=1
	NUM_WORKERS=4
	OBJECTIVE=cross_entropy
	OPT=adam
	OPTIM=gp
	POSITIVE_THETA=False
	PRINT_FREQ=10
	RESULTS_PATH=out
	SEED=2018
	SUMMARY_PATH=results/summary.csv
	TEST=False
	THETA_ARCH=simple
	THETA_DIM=-1
	THETA_REG_LAMBDA=0.01
	THETA_REG_TYPE=grad3
	TRAIN=True
	WEIGHT_DECAY=0.001
Model path out lisa_output/models/mnist/grad3_Hcnn_Thsimple_Cpts10_Reg1e-02_Sp0.0001_LR0.001
Epoch: [0][0/422]  Time 2.39 (2.39)  Loss 2.3715 (2.3715)  Prec@1 10.938 (10.938)  Prec@5 49.219 (49.219)
Epoch: [0][10/422]  Time 1.90 (2.10)  Loss 2.0839 (2.2400)  Prec@1 37.500 (23.580)  Prec@5 82.812 (67.969)
Epoch: [0][20/422]  Time 1.91 (2.01)  Loss 1.8426 (2.0923)  Prec@1 44.531 (32.068)  Prec@5 87.500 (77.158)
Epoch: [0][30/422]  Time 1.90 (1.98)  Loss 1.6011 (1.9640)  Prec@1 50.781 (36.845)  Prec@5 93.750 (81.477)
Epoch: [0][40/422]  Time 1.90 (1.96)  Loss 1.3832 (1.8554)  Prec@1 61.719 (41.311)  Prec@5 95.312 (84.223)
Epoch: [0][50/422]  Time 1.90 (1.95)  Loss 1.2387 (1.7522)  Prec@1 67.188 (45.113)  Prec@5 96.875 (86.550)
Epoch: [0][60/422]  Time 1.99 (1.94)  Loss 1.2048 (1.6640)  Prec@1 64.062 (48.770)  Prec@5 96.875 (88.102)
Epoch: [0][70/422]  Time 2.07 (1.96)  Loss 1.0821 (1.5831)  Prec@1 73.438 (52.234)  Prec@5 96.875 (89.360)
Epoch: [0][80/422]  Time 2.09 (1.97)  Loss 0.9840 (1.5170)  Prec@1 78.125 (54.958)  Prec@5 97.656 (90.316)
Epoch: [0][90/422]  Time 2.10 (1.99)  Loss 0.9276 (1.4578)  Prec@1 82.812 (57.357)  Prec@5 97.656 (91.080)
Epoch: [0][100/422]  Time 2.09 (2.00)  Loss 0.8999 (1.4043)  Prec@1 81.250 (59.646)  Prec@5 99.219 (91.778)
Epoch: [0][110/422]  Time 2.12 (2.01)  Loss 0.7652 (1.3523)  Prec@1 85.156 (61.782)  Prec@5 100.000 (92.349)
Epoch: [0][120/422]  Time 2.07 (2.02)  Loss 0.7824 (1.3075)  Prec@1 86.719 (63.630)  Prec@5 99.219 (92.840)
Epoch: [0][130/422]  Time 2.09 (2.02)  Loss 0.8552 (1.2663)  Prec@1 83.594 (65.303)  Prec@5 96.094 (93.291)
Epoch: [0][140/422]  Time 2.09 (2.03)  Loss 0.7889 (1.2301)  Prec@1 84.375 (66.678)  Prec@5 99.219 (93.656)
Epoch: [0][150/422]  Time 2.09 (2.03)  Loss 0.7430 (1.1982)  Prec@1 85.156 (67.969)  Prec@5 99.219 (93.993)
Epoch: [0][160/422]  Time 2.07 (2.03)  Loss 0.7089 (1.1697)  Prec@1 85.938 (69.095)  Prec@5 99.219 (94.245)
Epoch: [0][170/422]  Time 2.11 (2.04)  Loss 0.7257 (1.1422)  Prec@1 89.844 (70.189)  Prec@5 99.219 (94.527)
Epoch: [0][180/422]  Time 2.11 (2.04)  Loss 0.7063 (1.1174)  Prec@1 89.062 (71.193)  Prec@5 96.875 (94.751)
Epoch: [0][190/422]  Time 2.09 (2.04)  Loss 0.5944 (1.0937)  Prec@1 88.281 (72.141)  Prec@5 98.438 (94.965)
Epoch: [0][200/422]  Time 2.08 (2.05)  Loss 0.7283 (1.0700)  Prec@1 90.625 (73.033)  Prec@5 99.219 (95.173)
Epoch: [0][210/422]  Time 2.10 (2.05)  Loss 0.6500 (1.0498)  Prec@1 92.188 (73.782)  Prec@5 99.219 (95.324)
Epoch: [0][220/422]  Time 2.11 (2.05)  Loss 0.6653 (1.0295)  Prec@1 86.719 (74.540)  Prec@5 100.000 (95.510)
Epoch: [0][230/422]  Time 2.08 (2.05)  Loss 0.5442 (1.0115)  Prec@1 95.312 (75.230)  Prec@5 99.219 (95.661)
Epoch: [0][240/422]  Time 2.07 (2.06)  Loss 0.5513 (0.9951)  Prec@1 92.969 (75.810)  Prec@5 100.000 (95.796)
Epoch: [0][250/422]  Time 2.08 (2.06)  Loss 0.6018 (0.9791)  Prec@1 91.406 (76.394)  Prec@5 99.219 (95.935)
Epoch: [0][260/422]  Time 2.11 (2.06)  Loss 0.5571 (0.9660)  Prec@1 91.406 (76.883)  Prec@5 99.219 (96.031)
Epoch: [0][270/422]  Time 2.10 (2.06)  Loss 0.6326 (0.9512)  Prec@1 90.625 (77.442)  Prec@5 98.438 (96.151)
Epoch: [0][280/422]  Time 2.12 (2.06)  Loss 0.5469 (0.9377)  Prec@1 93.750 (77.964)  Prec@5 99.219 (96.255)
Epoch: [0][290/422]  Time 2.09 (2.06)  Loss 0.6644 (0.9268)  Prec@1 89.844 (78.369)  Prec@5 98.438 (96.351)
Epoch: [0][300/422]  Time 2.07 (2.06)  Loss 0.6282 (0.9159)  Prec@1 92.188 (78.795)  Prec@5 99.219 (96.439)
Epoch: [0][310/422]  Time 2.08 (2.06)  Loss 0.5680 (0.9036)  Prec@1 92.188 (79.225)  Prec@5 99.219 (96.536)
Epoch: [0][320/422]  Time 2.08 (2.07)  Loss 0.5337 (0.8924)  Prec@1 92.969 (79.627)  Prec@5 99.219 (96.624)
Epoch: [0][330/422]  Time 2.08 (2.07)  Loss 0.5085 (0.8823)  Prec@1 92.969 (79.980)  Prec@5 99.219 (96.712)
Epoch: [0][340/422]  Time 2.08 (2.07)  Loss 0.5432 (0.8728)  Prec@1 92.969 (80.327)  Prec@5 99.219 (96.793)
Epoch: [0][350/422]  Time 2.08 (2.07)  Loss 0.4808 (0.8629)  Prec@1 94.531 (80.687)  Prec@5 100.000 (96.871)
Epoch: [0][360/422]  Time 2.08 (2.07)  Loss 0.4817 (0.8539)  Prec@1 95.312 (81.012)  Prec@5 99.219 (96.933)
Epoch: [0][370/422]  Time 2.09 (2.07)  Loss 0.5275 (0.8453)  Prec@1 92.188 (81.324)  Prec@5 99.219 (96.987)
Epoch: [0][380/422]  Time 2.09 (2.07)  Loss 0.4598 (0.8371)  Prec@1 95.312 (81.617)  Prec@5 99.219 (97.045)
Epoch: [0][390/422]  Time 2.16 (2.07)  Loss 0.5174 (0.8282)  Prec@1 90.625 (81.933)  Prec@5 100.000 (97.111)
Epoch: [0][400/422]  Time 2.08 (2.07)  Loss 0.5367 (0.8203)  Prec@1 92.188 (82.193)  Prec@5 99.219 (97.159)
Epoch: [0][410/422]  Time 2.09 (2.07)  Loss 0.6658 (0.8130)  Prec@1 88.281 (82.449)  Prec@5 98.438 (97.215)
Epoch: [0][420/422]  Time 2.06 (2.07)  Loss 0.4313 (0.8055)  Prec@1 95.312 (82.684)  Prec@5 100.000 (97.268)
Test: [0/47]	Time 0.343 (0.343)	Loss 0.0686 (0.0686)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
Test: [10/47]	Time 0.095 (0.121)	Loss 0.0539 (0.1116)	Prec@1 98.438 (96.520)	Prec@5 100.000 (99.787)
Test: [20/47]	Time 0.092 (0.108)	Loss 0.1211 (0.1122)	Prec@1 95.312 (96.726)	Prec@5 100.000 (99.851)
Test: [30/47]	Time 0.093 (0.103)	Loss 0.0735 (0.1110)	Prec@1 98.438 (96.825)	Prec@5 100.000 (99.874)
Test: [40/47]	Time 0.075 (0.100)	Loss 0.2742 (0.1184)	Prec@1 93.750 (96.723)	Prec@5 100.000 (99.848)
 * Prec@1 96.700 Prec@5 99.850
Epoch: [1][0/422]  Time 2.22 (2.22)  Loss 0.5034 (0.5034)  Prec@1 92.188 (92.188)  Prec@5 98.438 (98.438)
Epoch: [1][10/422]  Time 1.91 (1.95)  Loss 0.4887 (0.5047)  Prec@1 94.531 (92.543)  Prec@5 100.000 (99.077)
Epoch: [1][20/422]  Time 1.89 (1.93)  Loss 0.4319 (0.5096)  Prec@1 94.531 (92.485)  Prec@5 100.000 (98.996)
Epoch: [1][30/422]  Time 1.91 (1.92)  Loss 0.3992 (0.5079)  Prec@1 96.875 (92.692)  Prec@5 100.000 (99.042)
Epoch: [1][40/422]  Time 1.91 (1.92)  Loss 0.4403 (0.5017)  Prec@1 96.875 (92.931)  Prec@5 98.438 (99.047)
Epoch: [1][50/422]  Time 1.89 (1.92)  Loss 0.6003 (0.4997)  Prec@1 89.844 (93.030)  Prec@5 98.438 (99.081)
Epoch: [1][60/422]  Time 1.87 (1.92)  Loss 0.4260 (0.4990)  Prec@1 95.312 (92.982)  Prec@5 99.219 (99.142)
Epoch: [1][70/422]  Time 1.90 (1.91)  Loss 0.4566 (0.4903)  Prec@1 94.531 (93.244)  Prec@5 100.000 (99.175)
Epoch: [1][80/422]  Time 1.89 (1.91)  Loss 0.4738 (0.4882)  Prec@1 95.312 (93.326)  Prec@5 99.219 (99.219)
Epoch: [1][90/422]  Time 1.89 (1.91)  Loss 0.4320 (0.4875)  Prec@1 95.312 (93.295)  Prec@5 99.219 (99.210)
Epoch: [1][100/422]  Time 1.93 (1.91)  Loss 0.3271 (0.4870)  Prec@1 98.438 (93.193)  Prec@5 99.219 (99.226)
Epoch: [1][110/422]  Time 1.89 (1.91)  Loss 0.4220 (0.4829)  Prec@1 96.094 (93.356)  Prec@5 100.000 (99.261)
Epoch: [1][120/422]  Time 1.88 (1.91)  Loss 0.4833 (0.4815)  Prec@1 93.750 (93.440)  Prec@5 100.000 (99.296)
Epoch: [1][130/422]  Time 1.92 (1.91)  Loss 0.3892 (0.4787)  Prec@1 96.094 (93.500)  Prec@5 100.000 (99.284)
Epoch: [1][140/422]  Time 1.92 (1.91)  Loss 0.4065 (0.4778)  Prec@1 95.312 (93.501)  Prec@5 100.000 (99.307)
Epoch: [1][150/422]  Time 1.89 (1.91)  Loss 0.4436 (0.4766)  Prec@1 92.969 (93.491)  Prec@5 100.000 (99.312)
Epoch: [1][160/422]  Time 1.89 (1.91)  Loss 0.4953 (0.4762)  Prec@1 89.844 (93.464)  Prec@5 100.000 (99.326)
Epoch: [1][170/422]  Time 1.89 (1.91)  Loss 0.4461 (0.4762)  Prec@1 94.531 (93.458)  Prec@5 99.219 (99.301)
Epoch: [1][180/422]  Time 1.90 (1.91)  Loss 0.4219 (0.4748)  Prec@1 94.531 (93.461)  Prec@5 99.219 (99.322)
Epoch: [1][190/422]  Time 1.90 (1.91)  Loss 0.4561 (0.4728)  Prec@1 92.969 (93.492)  Prec@5 97.656 (99.325)
Epoch: [1][200/422]  Time 1.90 (1.91)  Loss 0.3831 (0.4714)  Prec@1 97.656 (93.556)  Prec@5 100.000 (99.328)
Epoch: [1][210/422]  Time 1.90 (1.91)  Loss 0.4986 (0.4699)  Prec@1 90.625 (93.576)  Prec@5 98.438 (99.341)
Epoch: [1][220/422]  Time 1.91 (1.91)  Loss 0.4715 (0.4685)  Prec@1 93.750 (93.616)  Prec@5 99.219 (99.332)
Epoch: [1][230/422]  Time 1.90 (1.91)  Loss 0.5126 (0.4686)  Prec@1 90.625 (93.594)  Prec@5 99.219 (99.334)
Epoch: [1][240/422]  Time 1.91 (1.91)  Loss 0.4867 (0.4665)  Prec@1 91.406 (93.633)  Prec@5 99.219 (99.342)
Epoch: [1][250/422]  Time 1.90 (1.91)  Loss 0.3298 (0.4651)  Prec@1 97.656 (93.678)  Prec@5 100.000 (99.356)
Epoch: [1][260/422]  Time 1.93 (1.91)  Loss 0.4477 (0.4644)  Prec@1 92.969 (93.675)  Prec@5 98.438 (99.347)
Epoch: [1][270/422]  Time 1.93 (1.91)  Loss 0.4712 (0.4619)  Prec@1 91.406 (93.710)  Prec@5 99.219 (99.363)
Epoch: [1][280/422]  Time 1.90 (1.91)  Loss 0.4274 (0.4605)  Prec@1 94.531 (93.736)  Prec@5 100.000 (99.366)
Epoch: [1][290/422]  Time 1.89 (1.91)  Loss 0.3912 (0.4589)  Prec@1 94.531 (93.750)  Prec@5 99.219 (99.377)
Epoch: [1][300/422]  Time 1.90 (1.91)  Loss 0.4244 (0.4575)  Prec@1 94.531 (93.799)  Prec@5 99.219 (99.382)
Epoch: [1][310/422]  Time 1.90 (1.91)  Loss 0.4150 (0.4576)  Prec@1 93.750 (93.810)  Prec@5 100.000 (99.374)
Epoch: [1][320/422]  Time 1.93 (1.91)  Loss 0.4988 (0.4564)  Prec@1 92.188 (93.857)  Prec@5 99.219 (99.389)
Epoch: [1][330/422]  Time 1.89 (1.91)  Loss 0.4601 (0.4559)  Prec@1 93.750 (93.863)  Prec@5 100.000 (99.396)
Epoch: [1][340/422]  Time 1.91 (1.91)  Loss 0.4807 (0.4548)  Prec@1 96.094 (93.887)  Prec@5 99.219 (99.404)
Epoch: [1][350/422]  Time 1.89 (1.91)  Loss 0.4928 (0.4533)  Prec@1 95.312 (93.935)  Prec@5 99.219 (99.415)
Epoch: [1][360/422]  Time 1.90 (1.91)  Loss 0.4084 (0.4519)  Prec@1 92.969 (93.958)  Prec@5 99.219 (99.414)
Epoch: [1][370/422]  Time 2.06 (1.92)  Loss 0.4686 (0.4517)  Prec@1 90.625 (93.952)  Prec@5 99.219 (99.417)
Epoch: [1][380/422]  Time 1.93 (1.92)  Loss 0.3872 (0.4506)  Prec@1 96.094 (93.967)  Prec@5 99.219 (99.414)
Epoch: [1][390/422]  Time 1.91 (1.92)  Loss 0.4114 (0.4492)  Prec@1 94.531 (93.998)  Prec@5 100.000 (99.427)
Epoch: [1][400/422]  Time 1.90 (1.91)  Loss 0.4146 (0.4483)  Prec@1 93.750 (94.019)  Prec@5 99.219 (99.427)
Epoch: [1][410/422]  Time 1.90 (1.91)  Loss 0.4310 (0.4472)  Prec@1 92.969 (94.058)  Prec@5 100.000 (99.434)
Epoch: [1][420/422]  Time 1.88 (1.91)  Loss 0.3874 (0.4465)  Prec@1 96.094 (94.073)  Prec@5 98.438 (99.434)
Test: [0/47]	Time 0.458 (0.458)	Loss 0.0979 (0.0979)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
Test: [10/47]	Time 0.092 (0.133)	Loss 0.1930 (0.1091)	Prec@1 95.312 (96.946)	Prec@5 99.219 (99.858)
Test: [20/47]	Time 0.092 (0.114)	Loss 0.0765 (0.1036)	Prec@1 96.875 (97.024)	Prec@5 100.000 (99.888)
Test: [30/47]	Time 0.091 (0.107)	Loss 0.0918 (0.0976)	Prec@1 96.094 (97.203)	Prec@5 100.000 (99.874)
Test: [40/47]	Time 0.076 (0.102)	Loss 0.0252 (0.0929)	Prec@1 100.000 (97.370)	Prec@5 100.000 (99.867)
 * Prec@1 97.400 Prec@5 99.867
Epoch: [2][0/422]  Time 2.27 (2.27)  Loss 0.4347 (0.4347)  Prec@1 93.750 (93.750)  Prec@5 100.000 (100.000)
Epoch: [2][10/422]  Time 1.89 (1.96)  Loss 0.3132 (0.4078)  Prec@1 97.656 (94.105)  Prec@5 100.000 (99.574)
Epoch: [2][20/422]  Time 1.89 (1.94)  Loss 0.3510 (0.3851)  Prec@1 96.875 (94.829)  Prec@5 100.000 (99.702)
Epoch: [2][30/422]  Time 1.91 (1.93)  Loss 0.4090 (0.3915)  Prec@1 94.531 (94.758)  Prec@5 100.000 (99.698)
Epoch: [2][40/422]  Time 1.90 (1.92)  Loss 0.4028 (0.3969)  Prec@1 94.531 (94.722)  Prec@5 99.219 (99.638)
Epoch: [2][50/422]  Time 1.94 (1.92)  Loss 0.3520 (0.3943)  Prec@1 96.875 (94.899)  Prec@5 100.000 (99.632)
Epoch: [2][60/422]  Time 1.92 (1.92)  Loss 0.3664 (0.3983)  Prec@1 96.094 (94.813)  Prec@5 99.219 (99.577)
Epoch: [2][70/422]  Time 1.89 (1.92)  Loss 0.4079 (0.3973)  Prec@1 93.750 (94.949)  Prec@5 98.438 (99.582)
Epoch: [2][80/422]  Time 1.89 (1.92)  Loss 0.3922 (0.3975)  Prec@1 97.656 (95.014)  Prec@5 99.219 (99.585)
Epoch: [2][90/422]  Time 1.89 (1.92)  Loss 0.3720 (0.3977)  Prec@1 95.312 (95.046)  Prec@5 100.000 (99.605)
Epoch: [2][100/422]  Time 1.90 (1.92)  Loss 0.3557 (0.3972)  Prec@1 96.094 (95.088)  Prec@5 100.000 (99.590)
Epoch: [2][110/422]  Time 1.92 (1.92)  Loss 0.3437 (0.3985)  Prec@1 96.875 (95.073)  Prec@5 100.000 (99.557)
Epoch: [2][120/422]  Time 1.90 (1.92)  Loss 0.3986 (0.3978)  Prec@1 96.094 (95.074)  Prec@5 100.000 (99.561)
Epoch: [2][130/422]  Time 1.87 (1.92)  Loss 0.3441 (0.3976)  Prec@1 96.094 (95.062)  Prec@5 100.000 (99.577)
Epoch: [2][140/422]  Time 1.90 (1.92)  Loss 0.3993 (0.3992)  Prec@1 95.312 (95.047)  Prec@5 100.000 (99.573)
Epoch: [2][150/422]  Time 1.87 (1.92)  Loss 0.3670 (0.3982)  Prec@1 96.094 (95.095)  Prec@5 99.219 (99.571)
Epoch: [2][160/422]  Time 1.91 (1.92)  Loss 0.4088 (0.3974)  Prec@1 94.531 (95.099)  Prec@5 100.000 (99.578)
Epoch: [2][170/422]  Time 1.91 (1.92)  Loss 0.4401 (0.3968)  Prec@1 93.750 (95.084)  Prec@5 99.219 (99.571)
Epoch: [2][180/422]  Time 2.02 (1.92)  Loss 0.3130 (0.3968)  Prec@1 96.875 (95.054)  Prec@5 100.000 (99.586)
Epoch: [2][190/422]  Time 1.90 (1.92)  Loss 0.3761 (0.3972)  Prec@1 96.094 (95.026)  Prec@5 100.000 (99.587)
Epoch: [2][200/422]  Time 1.90 (1.92)  Loss 0.3414 (0.3954)  Prec@1 96.094 (95.075)  Prec@5 100.000 (99.584)
Epoch: [2][210/422]  Time 1.90 (1.92)  Loss 0.4052 (0.3948)  Prec@1 93.750 (95.057)  Prec@5 99.219 (99.593)
Epoch: [2][220/422]  Time 1.89 (1.92)  Loss 0.3310 (0.3946)  Prec@1 96.875 (95.051)  Prec@5 100.000 (99.586)
Epoch: [2][230/422]  Time 1.90 (1.92)  Loss 0.3655 (0.3931)  Prec@1 96.875 (95.103)  Prec@5 99.219 (99.584)
Epoch: [2][240/422]  Time 1.90 (1.92)  Loss 0.4193 (0.3925)  Prec@1 93.750 (95.099)  Prec@5 98.438 (99.575)
Epoch: [2][250/422]  Time 1.89 (1.92)  Loss 0.3256 (0.3925)  Prec@1 96.094 (95.110)  Prec@5 100.000 (99.583)
Epoch: [2][260/422]  Time 1.89 (1.92)  Loss 0.5315 (0.3925)  Prec@1 90.625 (95.085)  Prec@5 97.656 (99.581)
Epoch: [2][270/422]  Time 1.92 (1.92)  Loss 0.3529 (0.3916)  Prec@1 97.656 (95.114)  Prec@5 100.000 (99.582)
Epoch: [2][280/422]  Time 1.90 (1.92)  Loss 0.3727 (0.3908)  Prec@1 93.750 (95.135)  Prec@5 100.000 (99.577)
Epoch: [2][290/422]  Time 2.03 (1.92)  Loss 0.3649 (0.3908)  Prec@1 96.875 (95.108)  Prec@5 100.000 (99.578)
Epoch: [2][300/422]  Time 1.88 (1.91)  Loss 0.3747 (0.3905)  Prec@1 95.312 (95.126)  Prec@5 100.000 (99.574)
Epoch: [2][310/422]  Time 1.89 (1.91)  Loss 0.3758 (0.3900)  Prec@1 96.094 (95.142)  Prec@5 99.219 (99.568)
Epoch: [2][320/422]  Time 1.92 (1.91)  Loss 0.3517 (0.3898)  Prec@1 94.531 (95.120)  Prec@5 100.000 (99.567)
Epoch: [2][330/422]  Time 1.92 (1.91)  Loss 0.2771 (0.3889)  Prec@1 99.219 (95.133)  Prec@5 100.000 (99.570)
Epoch: [2][340/422]  Time 1.88 (1.91)  Loss 0.4363 (0.3884)  Prec@1 91.406 (95.132)  Prec@5 99.219 (99.576)
Epoch: [2][350/422]  Time 1.87 (1.91)  Loss 0.3613 (0.3875)  Prec@1 96.094 (95.150)  Prec@5 100.000 (99.577)
Epoch: [2][360/422]  Time 1.89 (1.91)  Loss 0.3884 (0.3869)  Prec@1 96.875 (95.185)  Prec@5 98.438 (99.574)
Epoch: [2][370/422]  Time 1.89 (1.91)  Loss 0.3576 (0.3865)  Prec@1 96.094 (95.207)  Prec@5 100.000 (99.577)
Epoch: [2][380/422]  Time 1.95 (1.91)  Loss 0.3333 (0.3863)  Prec@1 98.438 (95.214)  Prec@5 100.000 (99.573)
Epoch: [2][390/422]  Time 1.91 (1.91)  Loss 0.4066 (0.3860)  Prec@1 93.750 (95.215)  Prec@5 99.219 (99.574)
Epoch: [2][400/422]  Time 2.03 (1.91)  Loss 0.3365 (0.3855)  Prec@1 96.875 (95.211)  Prec@5 99.219 (99.573)
Epoch: [2][410/422]  Time 1.89 (1.91)  Loss 0.3950 (0.3849)  Prec@1 95.312 (95.225)  Prec@5 100.000 (99.578)
Epoch: [2][420/422]  Time 1.86 (1.91)  Loss 0.3486 (0.3841)  Prec@1 96.094 (95.244)  Prec@5 100.000 (99.582)
Test: [0/47]	Time 0.400 (0.400)	Loss 0.0638 (0.0638)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
Test: [10/47]	Time 0.091 (0.127)	Loss 0.0305 (0.0813)	Prec@1 99.219 (97.514)	Prec@5 100.000 (99.929)
Test: [20/47]	Time 0.098 (0.111)	Loss 0.0585 (0.0811)	Prec@1 98.438 (97.470)	Prec@5 100.000 (99.888)
Test: [30/47]	Time 0.093 (0.106)	Loss 0.1146 (0.0783)	Prec@1 98.438 (97.631)	Prec@5 100.000 (99.924)
Test: [40/47]	Time 0.074 (0.101)	Loss 0.1247 (0.0801)	Prec@1 96.094 (97.713)	Prec@5 100.000 (99.943)
 * Prec@1 97.683 Prec@5 99.933
Epoch: [3][0/422]  Time 2.24 (2.24)  Loss 0.3758 (0.3758)  Prec@1 96.875 (96.875)  Prec@5 100.000 (100.000)
Epoch: [3][10/422]  Time 1.91 (1.96)  Loss 0.3356 (0.3680)  Prec@1 97.656 (95.739)  Prec@5 100.000 (99.716)
Epoch: [3][20/422]  Time 1.89 (1.94)  Loss 0.4219 (0.3666)  Prec@1 95.312 (95.685)  Prec@5 100.000 (99.740)
Epoch: [3][30/422]  Time 1.91 (1.93)  Loss 0.3779 (0.3605)  Prec@1 95.312 (95.968)  Prec@5 100.000 (99.723)
Epoch: [3][40/422]  Time 1.90 (1.93)  Loss 0.3376 (0.3556)  Prec@1 96.875 (95.998)  Prec@5 100.000 (99.714)
Epoch: [3][50/422]  Time 1.92 (1.92)  Loss 0.3250 (0.3582)  Prec@1 97.656 (95.879)  Prec@5 100.000 (99.663)
Epoch: [3][60/422]  Time 1.91 (1.92)  Loss 0.3809 (0.3589)  Prec@1 94.531 (95.876)  Prec@5 100.000 (99.693)
Epoch: [3][70/422]  Time 2.03 (1.92)  Loss 0.3791 (0.3565)  Prec@1 96.094 (95.863)  Prec@5 98.438 (99.681)
Epoch: [3][80/422]  Time 1.87 (1.91)  Loss 0.3101 (0.3545)  Prec@1 95.312 (95.795)  Prec@5 100.000 (99.720)
Epoch: [3][90/422]  Time 1.89 (1.91)  Loss 0.3543 (0.3578)  Prec@1 96.094 (95.639)  Prec@5 99.219 (99.708)
Epoch: [3][100/422]  Time 1.88 (1.91)  Loss 0.3706 (0.3593)  Prec@1 94.531 (95.591)  Prec@5 99.219 (99.706)
Epoch: [3][110/422]  Time 1.93 (1.91)  Loss 0.3992 (0.3590)  Prec@1 94.531 (95.636)  Prec@5 100.000 (99.711)
Epoch: [3][120/422]  Time 1.92 (1.91)  Loss 0.3037 (0.3615)  Prec@1 96.094 (95.474)  Prec@5 100.000 (99.697)
Epoch: [3][130/422]  Time 1.87 (1.91)  Loss 0.3926 (0.3593)  Prec@1 95.312 (95.551)  Prec@5 98.438 (99.684)
Epoch: [3][140/422]  Time 1.91 (1.91)  Loss 0.3766 (0.3601)  Prec@1 96.094 (95.512)  Prec@5 98.438 (99.684)
Epoch: [3][150/422]  Time 1.88 (1.91)  Loss 0.3963 (0.3618)  Prec@1 94.531 (95.478)  Prec@5 99.219 (99.679)
Epoch: [3][160/422]  Time 1.87 (1.91)  Loss 0.4325 (0.3622)  Prec@1 94.531 (95.487)  Prec@5 99.219 (99.670)
Epoch: [3][170/422]  Time 1.91 (1.91)  Loss 0.3356 (0.3617)  Prec@1 95.312 (95.468)  Prec@5 100.000 (99.680)
Epoch: [3][180/422]  Time 1.98 (1.91)  Loss 0.3378 (0.3614)  Prec@1 96.875 (95.528)  Prec@5 100.000 (99.681)
Epoch: [3][190/422]  Time 1.89 (1.91)  Loss 0.3433 (0.3611)  Prec@1 96.875 (95.509)  Prec@5 100.000 (99.689)
Epoch: [3][200/422]  Time 1.91 (1.91)  Loss 0.3173 (0.3610)  Prec@1 96.875 (95.534)  Prec@5 100.000 (99.689)
Epoch: [3][210/422]  Time 1.88 (1.91)  Loss 0.3299 (0.3610)  Prec@1 95.312 (95.531)  Prec@5 100.000 (99.678)
Epoch: [3][220/422]  Time 1.88 (1.91)  Loss 0.3469 (0.3614)  Prec@1 96.094 (95.521)  Prec@5 99.219 (99.678)
Epoch: [3][230/422]  Time 1.93 (1.91)  Loss 0.3462 (0.3613)  Prec@1 97.656 (95.526)  Prec@5 99.219 (99.675)
Epoch: [3][240/422]  Time 1.89 (1.91)  Loss 0.3202 (0.3610)  Prec@1 95.312 (95.533)  Prec@5 100.000 (99.679)
Epoch: [3][250/422]  Time 1.89 (1.91)  Loss 0.3620 (0.3614)  Prec@1 92.969 (95.524)  Prec@5 100.000 (99.683)
Epoch: [3][260/422]  Time 1.89 (1.91)  Loss 0.3559 (0.3627)  Prec@1 95.312 (95.462)  Prec@5 100.000 (99.674)
Epoch: [3][270/422]  Time 1.90 (1.91)  Loss 0.3696 (0.3631)  Prec@1 96.875 (95.468)  Prec@5 99.219 (99.671)
Epoch: [3][280/422]  Time 1.90 (1.91)  Loss 0.4067 (0.3631)  Prec@1 97.656 (95.474)  Prec@5 99.219 (99.675)
Epoch: [3][290/422]  Time 2.04 (1.91)  Loss 0.3440 (0.3625)  Prec@1 96.875 (95.514)  Prec@5 100.000 (99.672)
Epoch: [3][300/422]  Time 1.88 (1.91)  Loss 0.3663 (0.3616)  Prec@1 96.094 (95.556)  Prec@5 100.000 (99.673)
Epoch: [3][310/422]  Time 1.88 (1.91)  Loss 0.3915 (0.3616)  Prec@1 92.188 (95.564)  Prec@5 100.000 (99.666)
Epoch: [3][320/422]  Time 1.89 (1.91)  Loss 0.3920 (0.3609)  Prec@1 96.875 (95.612)  Prec@5 98.438 (99.669)
Epoch: [3][330/422]  Time 1.89 (1.91)  Loss 0.3677 (0.3601)  Prec@1 96.094 (95.641)  Prec@5 99.219 (99.672)
Epoch: [3][340/422]  Time 1.91 (1.91)  Loss 0.3146 (0.3591)  Prec@1 98.438 (95.674)  Prec@5 100.000 (99.672)
Epoch: [3][350/422]  Time 1.90 (1.91)  Loss 0.3500 (0.3588)  Prec@1 94.531 (95.669)  Prec@5 100.000 (99.673)
Epoch: [3][360/422]  Time 1.89 (1.91)  Loss 0.3430 (0.3581)  Prec@1 96.875 (95.685)  Prec@5 99.219 (99.675)
Epoch: [3][370/422]  Time 1.89 (1.91)  Loss 0.3033 (0.3587)  Prec@1 97.656 (95.670)  Prec@5 100.000 (99.665)
Epoch: [3][380/422]  Time 1.92 (1.91)  Loss 0.3142 (0.3580)  Prec@1 96.875 (95.692)  Prec@5 100.000 (99.664)
Epoch: [3][390/422]  Time 1.92 (1.91)  Loss 0.3877 (0.3577)  Prec@1 93.750 (95.706)  Prec@5 98.438 (99.658)
Epoch: [3][400/422]  Time 2.05 (1.91)  Loss 0.3223 (0.3578)  Prec@1 97.656 (95.704)  Prec@5 99.219 (99.655)
Epoch: [3][410/422]  Time 1.88 (1.91)  Loss 0.3688 (0.3577)  Prec@1 93.750 (95.689)  Prec@5 99.219 (99.656)
Epoch: [3][420/422]  Time 1.87 (1.91)  Loss 0.3185 (0.3570)  Prec@1 98.438 (95.717)  Prec@5 100.000 (99.660)
Test: [0/47]	Time 0.417 (0.417)	Loss 0.1480 (0.1480)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
Test: [10/47]	Time 0.096 (0.130)	Loss 0.0180 (0.0885)	Prec@1 99.219 (97.727)	Prec@5 100.000 (99.858)
Test: [20/47]	Time 0.092 (0.112)	Loss 0.0230 (0.0671)	Prec@1 99.219 (98.028)	Prec@5 100.000 (99.926)
Test: [30/47]	Time 0.091 (0.106)	Loss 0.0635 (0.0676)	Prec@1 96.094 (97.908)	Prec@5 100.000 (99.924)
Test: [40/47]	Time 0.074 (0.102)	Loss 0.0557 (0.0755)	Prec@1 98.438 (97.809)	Prec@5 100.000 (99.943)
 * Prec@1 97.867 Prec@5 99.950
Epoch: [4][0/422]  Time 2.24 (2.24)  Loss 0.3602 (0.3602)  Prec@1 96.875 (96.875)  Prec@5 99.219 (99.219)
Epoch: [4][10/422]  Time 1.87 (2.06)  Loss 0.2892 (0.3355)  Prec@1 97.656 (96.378)  Prec@5 100.000 (99.645)
Epoch: [4][20/422]  Time 1.92 (2.00)  Loss 0.4025 (0.3472)  Prec@1 93.750 (95.871)  Prec@5 99.219 (99.628)
Epoch: [4][30/422]  Time 1.91 (1.97)  Loss 0.3206 (0.3498)  Prec@1 96.094 (95.741)  Prec@5 99.219 (99.572)
Epoch: [4][40/422]  Time 1.88 (1.96)  Loss 0.3326 (0.3457)  Prec@1 96.094 (95.808)  Prec@5 100.000 (99.619)
Epoch: [4][50/422]  Time 1.90 (1.96)  Loss 0.3167 (0.3443)  Prec@1 96.094 (95.787)  Prec@5 100.000 (99.617)
Epoch: [4][60/422]  Time 1.88 (1.95)  Loss 0.2886 (0.3449)  Prec@1 96.875 (95.825)  Prec@5 100.000 (99.616)
Epoch: [4][70/422]  Time 1.90 (1.95)  Loss 0.3446 (0.3469)  Prec@1 96.094 (95.819)  Prec@5 99.219 (99.604)
Epoch: [4][80/422]  Time 1.89 (1.94)  Loss 0.3984 (0.3509)  Prec@1 93.750 (95.698)  Prec@5 99.219 (99.614)
Epoch: [4][90/422]  Time 1.88 (1.94)  Loss 0.4041 (0.3496)  Prec@1 95.312 (95.836)  Prec@5 98.438 (99.622)
Epoch: [4][100/422]  Time 2.02 (1.94)  Loss 0.2889 (0.3498)  Prec@1 98.438 (95.823)  Prec@5 100.000 (99.606)
Epoch: [4][110/422]  Time 1.89 (1.93)  Loss 0.3209 (0.3488)  Prec@1 96.875 (95.861)  Prec@5 100.000 (99.613)
Epoch: [4][120/422]  Time 1.93 (1.93)  Loss 0.3230 (0.3482)  Prec@1 96.875 (95.894)  Prec@5 99.219 (99.626)
Epoch: [4][130/422]  Time 1.87 (1.93)  Loss 0.2527 (0.3470)  Prec@1 97.656 (95.897)  Prec@5 100.000 (99.630)
Epoch: [4][140/422]  Time 1.89 (1.93)  Loss 0.2663 (0.3465)  Prec@1 99.219 (95.939)  Prec@5 100.000 (99.629)
Epoch: [4][150/422]  Time 1.87 (1.93)  Loss 0.2615 (0.3449)  Prec@1 98.438 (95.980)  Prec@5 100.000 (99.627)
Epoch: [4][160/422]  Time 1.88 (1.93)  Loss 0.3437 (0.3439)  Prec@1 96.094 (95.992)  Prec@5 100.000 (99.646)
Epoch: [4][170/422]  Time 1.90 (1.93)  Loss 0.3116 (0.3442)  Prec@1 96.094 (96.012)  Prec@5 100.000 (99.644)
Epoch: [4][180/422]  Time 1.91 (1.92)  Loss 0.4017 (0.3439)  Prec@1 90.625 (96.012)  Prec@5 99.219 (99.642)
Epoch: [4][190/422]  Time 1.90 (1.92)  Loss 0.4391 (0.3439)  Prec@1 94.531 (96.004)  Prec@5 100.000 (99.656)
Epoch: [4][200/422]  Time 1.90 (1.92)  Loss 0.3532 (0.3446)  Prec@1 95.312 (95.977)  Prec@5 100.000 (99.658)
Epoch: [4][210/422]  Time 2.03 (1.92)  Loss 0.3328 (0.3441)  Prec@1 98.438 (95.986)  Prec@5 99.219 (99.656)
Epoch: [4][220/422]  Time 1.91 (1.92)  Loss 0.3783 (0.3447)  Prec@1 92.969 (95.974)  Prec@5 100.000 (99.657)
Epoch: [4][230/422]  Time 1.92 (1.92)  Loss 0.3906 (0.3456)  Prec@1 90.625 (95.962)  Prec@5 100.000 (99.655)
Epoch: [4][240/422]  Time 1.88 (1.92)  Loss 0.2908 (0.3451)  Prec@1 95.312 (95.980)  Prec@5 100.000 (99.663)
Epoch: [4][250/422]  Time 2.07 (1.93)  Loss 0.3739 (0.3446)  Prec@1 94.531 (96.000)  Prec@5 97.656 (99.658)
Epoch: [4][260/422]  Time 1.89 (1.93)  Loss 0.3186 (0.3436)  Prec@1 96.094 (96.025)  Prec@5 100.000 (99.671)
Epoch: [4][270/422]  Time 1.90 (1.93)  Loss 0.2902 (0.3428)  Prec@1 96.875 (96.036)  Prec@5 99.219 (99.671)
Epoch: [4][280/422]  Time 1.90 (1.93)  Loss 0.3703 (0.3425)  Prec@1 95.312 (96.058)  Prec@5 99.219 (99.664)
Epoch: [4][290/422]  Time 1.92 (1.93)  Loss 0.3434 (0.3427)  Prec@1 94.531 (96.032)  Prec@5 100.000 (99.659)
Epoch: [4][300/422]  Time 1.89 (1.92)  Loss 0.3957 (0.3425)  Prec@1 94.531 (96.050)  Prec@5 100.000 (99.655)
Epoch: [4][310/422]  Time 2.07 (1.92)  Loss 0.3015 (0.3420)  Prec@1 96.875 (96.059)  Prec@5 99.219 (99.656)
Epoch: [4][320/422]  Time 1.92 (1.93)  Loss 0.3772 (0.3420)  Prec@1 92.969 (96.062)  Prec@5 99.219 (99.657)
Epoch: [4][330/422]  Time 1.91 (1.93)  Loss 0.3324 (0.3419)  Prec@1 96.094 (96.058)  Prec@5 100.000 (99.658)
Epoch: [4][340/422]  Time 1.88 (1.93)  Loss 0.3344 (0.3413)  Prec@1 95.312 (96.073)  Prec@5 99.219 (99.656)
Epoch: [4][350/422]  Time 2.02 (1.93)  Loss 0.3422 (0.3418)  Prec@1 95.312 (96.054)  Prec@5 100.000 (99.659)
Epoch: [4][360/422]  Time 1.89 (1.92)  Loss 0.3273 (0.3413)  Prec@1 97.656 (96.074)  Prec@5 100.000 (99.662)
Epoch: [4][370/422]  Time 1.89 (1.92)  Loss 0.3400 (0.3416)  Prec@1 95.312 (96.058)  Prec@5 99.219 (99.661)
Epoch: [4][380/422]  Time 1.91 (1.92)  Loss 0.3823 (0.3414)  Prec@1 92.969 (96.063)  Prec@5 100.000 (99.660)
Epoch: [4][390/422]  Time 1.94 (1.92)  Loss 0.3351 (0.3416)  Prec@1 98.438 (96.062)  Prec@5 99.219 (99.658)
Epoch: [4][400/422]  Time 1.91 (1.92)  Loss 0.3863 (0.3415)  Prec@1 96.094 (96.070)  Prec@5 100.000 (99.661)
Epoch: [4][410/422]  Time 1.88 (1.92)  Loss 0.3450 (0.3410)  Prec@1 95.312 (96.077)  Prec@5 99.219 (99.662)
Epoch: [4][420/422]  Time 1.86 (1.92)  Loss 0.4426 (0.3411)  Prec@1 95.312 (96.075)  Prec@5 99.219 (99.660)
Test: [0/47]	Time 0.493 (0.493)	Loss 0.1222 (0.1222)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
Test: [10/47]	Time 0.093 (0.135)	Loss 0.0479 (0.0700)	Prec@1 97.656 (97.940)	Prec@5 100.000 (99.929)
Test: [20/47]	Time 0.093 (0.115)	Loss 0.0377 (0.0706)	Prec@1 99.219 (97.954)	Prec@5 100.000 (99.963)
Test: [30/47]	Time 0.093 (0.108)	Loss 0.1193 (0.0747)	Prec@1 96.875 (97.782)	Prec@5 100.000 (99.975)
Test: [40/47]	Time 0.074 (0.103)	Loss 0.0216 (0.0722)	Prec@1 99.219 (97.847)	Prec@5 100.000 (99.962)
 * Prec@1 97.867 Prec@5 99.967
Epoch: [5][0/422]  Time 2.39 (2.39)  Loss 0.2471 (0.2471)  Prec@1 98.438 (98.438)  Prec@5 100.000 (100.000)
Epoch: [5][10/422]  Time 1.88 (1.99)  Loss 0.3507 (0.3212)  Prec@1 93.750 (96.520)  Prec@5 99.219 (99.716)
Epoch: [5][20/422]  Time 2.06 (1.96)  Loss 0.2943 (0.3279)  Prec@1 97.656 (96.466)  Prec@5 100.000 (99.777)
Epoch: [5][30/422]  Time 1.91 (1.96)  Loss 0.3421 (0.3273)  Prec@1 96.875 (96.346)  Prec@5 98.438 (99.748)
Epoch: [5][40/422]  Time 1.89 (1.95)  Loss 0.3025 (0.3272)  Prec@1 97.656 (96.303)  Prec@5 99.219 (99.695)
Epoch: [5][50/422]  Time 1.90 (1.94)  Loss 0.4235 (0.3344)  Prec@1 95.312 (96.140)  Prec@5 98.438 (99.632)
Epoch: [5][60/422]  Time 1.89 (1.93)  Loss 0.3617 (0.3366)  Prec@1 96.094 (96.043)  Prec@5 100.000 (99.667)
Epoch: [5][70/422]  Time 1.89 (1.93)  Loss 0.2677 (0.3363)  Prec@1 98.438 (96.116)  Prec@5 100.000 (99.670)
Epoch: [5][80/422]  Time 1.90 (1.92)  Loss 0.2951 (0.3372)  Prec@1 95.312 (96.065)  Prec@5 100.000 (99.701)
Epoch: [5][90/422]  Time 1.88 (1.92)  Loss 0.2995 (0.3365)  Prec@1 98.438 (96.111)  Prec@5 100.000 (99.708)
Epoch: [5][100/422]  Time 1.87 (1.92)  Loss 0.4489 (0.3392)  Prec@1 92.969 (96.071)  Prec@5 98.438 (99.667)
Epoch: [5][110/422]  Time 1.89 (1.92)  Loss 0.3432 (0.3387)  Prec@1 94.531 (96.129)  Prec@5 99.219 (99.669)
Epoch: [5][120/422]  Time 1.90 (1.92)  Loss 0.3078 (0.3397)  Prec@1 97.656 (96.126)  Prec@5 99.219 (99.658)
Epoch: [5][130/422]  Time 2.06 (1.92)  Loss 0.2861 (0.3381)  Prec@1 97.656 (96.124)  Prec@5 100.000 (99.672)
Epoch: [5][140/422]  Time 1.89 (1.92)  Loss 0.2603 (0.3363)  Prec@1 98.438 (96.188)  Prec@5 100.000 (99.679)
Epoch: [5][150/422]  Time 1.88 (1.92)  Loss 0.3101 (0.3341)  Prec@1 98.438 (96.270)  Prec@5 100.000 (99.684)
Epoch: [5][160/422]  Time 1.87 (1.92)  Loss 0.3847 (0.3347)  Prec@1 94.531 (96.234)  Prec@5 99.219 (99.685)
Epoch: [5][170/422]  Time 1.87 (1.92)  Loss 0.3379 (0.3346)  Prec@1 97.656 (96.226)  Prec@5 100.000 (99.680)
Epoch: [5][180/422]  Time 1.90 (1.92)  Loss 0.3978 (0.3328)  Prec@1 96.875 (96.288)  Prec@5 98.438 (99.681)
Epoch: [5][190/422]  Time 1.91 (1.92)  Loss 0.3141 (0.3324)  Prec@1 97.656 (96.306)  Prec@5 99.219 (99.665)
Epoch: [5][200/422]  Time 1.89 (1.92)  Loss 0.3054 (0.3322)  Prec@1 97.656 (96.304)  Prec@5 100.000 (99.677)
Epoch: [5][210/422]  Time 1.88 (1.92)  Loss 0.2567 (0.3311)  Prec@1 98.438 (96.327)  Prec@5 100.000 (99.689)
Epoch: [5][220/422]  Time 1.88 (1.91)  Loss 0.2662 (0.3303)  Prec@1 96.875 (96.313)  Prec@5 100.000 (99.700)
Epoch: [5][230/422]  Time 1.92 (1.92)  Loss 0.3221 (0.3301)  Prec@1 96.875 (96.341)  Prec@5 100.000 (99.699)
Epoch: [5][240/422]  Time 2.11 (1.92)  Loss 0.3741 (0.3303)  Prec@1 94.531 (96.314)  Prec@5 99.219 (99.702)
Epoch: [5][250/422]  Time 1.89 (1.92)  Loss 0.4075 (0.3306)  Prec@1 92.969 (96.309)  Prec@5 100.000 (99.698)
Epoch: [5][260/422]  Time 1.89 (1.92)  Loss 0.3363 (0.3305)  Prec@1 96.875 (96.312)  Prec@5 99.219 (99.698)
Epoch: [5][270/422]  Time 1.88 (1.92)  Loss 0.3349 (0.3294)  Prec@1 96.875 (96.350)  Prec@5 99.219 (99.700)
Epoch: [5][280/422]  Time 1.88 (1.92)  Loss 0.3008 (0.3289)  Prec@1 96.875 (96.355)  Prec@5 99.219 (99.703)
Epoch: [5][290/422]  Time 1.90 (1.92)  Loss 0.3846 (0.3293)  Prec@1 92.188 (96.349)  Prec@5 100.000 (99.702)
Epoch: [5][300/422]  Time 1.90 (1.92)  Loss 0.3134 (0.3283)  Prec@1 96.094 (96.364)  Prec@5 100.000 (99.704)
Epoch: [5][310/422]  Time 1.90 (1.92)  Loss 0.2473 (0.3273)  Prec@1 100.000 (96.403)  Prec@5 100.000 (99.711)
Epoch: [5][320/422]  Time 1.89 (1.92)  Loss 0.3350 (0.3269)  Prec@1 96.094 (96.413)  Prec@5 100.000 (99.713)
Epoch: [5][330/422]  Time 1.90 (1.92)  Loss 0.3782 (0.3264)  Prec@1 95.312 (96.441)  Prec@5 99.219 (99.714)
Epoch: [5][340/422]  Time 1.89 (1.92)  Loss 0.3808 (0.3268)  Prec@1 93.750 (96.419)  Prec@5 99.219 (99.711)
Epoch: [5][350/422]  Time 1.91 (1.92)  Loss 0.4243 (0.3271)  Prec@1 93.750 (96.408)  Prec@5 98.438 (99.702)
Epoch: [5][360/422]  Time 1.89 (1.91)  Loss 0.4001 (0.3273)  Prec@1 94.531 (96.388)  Prec@5 98.438 (99.701)
Epoch: [5][370/422]  Time 1.89 (1.91)  Loss 0.3643 (0.3276)  Prec@1 95.312 (96.374)  Prec@5 100.000 (99.699)
Epoch: [5][380/422]  Time 1.92 (1.91)  Loss 0.3138 (0.3274)  Prec@1 96.875 (96.381)  Prec@5 99.219 (99.701)
Epoch: [5][390/422]  Time 1.90 (1.91)  Loss 0.3602 (0.3273)  Prec@1 96.875 (96.389)  Prec@5 100.000 (99.702)
Epoch: [5][400/422]  Time 1.93 (1.91)  Loss 0.3159 (0.3275)  Prec@1 96.875 (96.374)  Prec@5 99.219 (99.700)
Epoch: [5][410/422]  Time 1.91 (1.91)  Loss 0.2767 (0.3272)  Prec@1 98.438 (96.385)  Prec@5 100.000 (99.702)
Epoch: [5][420/422]  Time 1.86 (1.91)  Loss 0.3871 (0.3268)  Prec@1 93.750 (96.383)  Prec@5 99.219 (99.705)
Test: [0/47]	Time 0.490 (0.490)	Loss 0.0592 (0.0592)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
Test: [10/47]	Time 0.092 (0.134)	Loss 0.0360 (0.0716)	Prec@1 97.656 (97.869)	Prec@5 100.000 (99.929)
Test: [20/47]	Time 0.093 (0.116)	Loss 0.0932 (0.0720)	Prec@1 96.875 (97.954)	Prec@5 100.000 (99.963)
Test: [30/47]	Time 0.093 (0.109)	Loss 0.0698 (0.0720)	Prec@1 97.656 (97.908)	Prec@5 100.000 (99.975)
Test: [40/47]	Time 0.070 (0.104)	Loss 0.1247 (0.0691)	Prec@1 96.875 (97.923)	Prec@5 100.000 (99.962)
 * Prec@1 98.017 Prec@5 99.967
Epoch: [6][0/422]  Time 2.33 (2.33)  Loss 0.2640 (0.2640)  Prec@1 96.875 (96.875)  Prec@5 100.000 (100.000)
Epoch: [6][10/422]  Time 1.88 (1.96)  Loss 0.2754 (0.2951)  Prec@1 98.438 (97.372)  Prec@5 100.000 (100.000)
Epoch: [6][20/422]  Time 2.08 (1.97)  Loss 0.2551 (0.3120)  Prec@1 98.438 (96.912)  Prec@5 100.000 (99.851)
Epoch: [6][30/422]  Time 1.91 (1.99)  Loss 0.2827 (0.3139)  Prec@1 96.875 (96.749)  Prec@5 100.000 (99.723)
Epoch: [6][40/422]  Time 1.90 (1.97)  Loss 0.2471 (0.3202)  Prec@1 99.219 (96.627)  Prec@5 100.000 (99.714)
Epoch: [6][50/422]  Time 1.92 (1.96)  Loss 0.3354 (0.3196)  Prec@1 95.312 (96.599)  Prec@5 99.219 (99.663)
Epoch: [6][60/422]  Time 1.90 (1.95)  Loss 0.2967 (0.3186)  Prec@1 97.656 (96.606)  Prec@5 100.000 (99.680)
Epoch: [6][70/422]  Time 1.88 (1.94)  Loss 0.3149 (0.3216)  Prec@1 96.875 (96.479)  Prec@5 99.219 (99.659)
Epoch: [6][80/422]  Time 1.90 (1.94)  Loss 0.3313 (0.3255)  Prec@1 95.312 (96.354)  Prec@5 100.000 (99.643)
Epoch: [6][90/422]  Time 1.89 (1.93)  Loss 0.3640 (0.3257)  Prec@1 95.312 (96.317)  Prec@5 99.219 (99.657)
Epoch: [6][100/422]  Time 1.88 (1.94)  Loss 0.3444 (0.3245)  Prec@1 96.094 (96.357)  Prec@5 99.219 (99.667)
Epoch: [6][110/422]  Time 1.89 (1.94)  Loss 0.4032 (0.3244)  Prec@1 94.531 (96.410)  Prec@5 99.219 (99.669)
Epoch: [6][120/422]  Time 1.90 (1.93)  Loss 0.3419 (0.3227)  Prec@1 95.312 (96.449)  Prec@5 100.000 (99.684)
Epoch: [6][130/422]  Time 1.88 (1.93)  Loss 0.3322 (0.3239)  Prec@1 96.094 (96.440)  Prec@5 100.000 (99.666)
Epoch: [6][140/422]  Time 1.92 (1.93)  Loss 0.5007 (0.3258)  Prec@1 92.188 (96.349)  Prec@5 99.219 (99.668)
Epoch: [6][150/422]  Time 1.87 (1.93)  Loss 0.3178 (0.3251)  Prec@1 96.875 (96.378)  Prec@5 100.000 (99.679)
Epoch: [6][160/422]  Time 1.87 (1.93)  Loss 0.2908 (0.3258)  Prec@1 96.875 (96.332)  Prec@5 100.000 (99.689)
Epoch: [6][170/422]  Time 1.88 (1.93)  Loss 0.2968 (0.3240)  Prec@1 99.219 (96.386)  Prec@5 100.000 (99.698)
Epoch: [6][180/422]  Time 1.88 (1.93)  Loss 0.3321 (0.3228)  Prec@1 96.094 (96.435)  Prec@5 99.219 (99.698)
Epoch: [6][190/422]  Time 2.06 (1.93)  Loss 0.2957 (0.3230)  Prec@1 96.875 (96.421)  Prec@5 100.000 (99.701)
Epoch: [6][200/422]  Time 1.89 (1.93)  Loss 0.2957 (0.3237)  Prec@1 96.875 (96.405)  Prec@5 99.219 (99.697)
Epoch: [6][210/422]  Time 1.89 (1.93)  Loss 0.3804 (0.3237)  Prec@1 93.750 (96.405)  Prec@5 100.000 (99.696)
Epoch: [6][220/422]  Time 1.89 (1.92)  Loss 0.3926 (0.3224)  Prec@1 92.188 (96.433)  Prec@5 99.219 (99.696)
Epoch: [6][230/422]  Time 1.90 (1.92)  Loss 0.2745 (0.3218)  Prec@1 98.438 (96.456)  Prec@5 100.000 (99.702)
Epoch: [6][240/422]  Time 1.89 (1.92)  Loss 0.3843 (0.3210)  Prec@1 93.750 (96.463)  Prec@5 100.000 (99.708)
Epoch: [6][250/422]  Time 1.89 (1.92)  Loss 0.2806 (0.3210)  Prec@1 96.875 (96.452)  Prec@5 100.000 (99.707)
Epoch: [6][260/422]  Time 1.87 (1.92)  Loss 0.2649 (0.3201)  Prec@1 99.219 (96.483)  Prec@5 99.219 (99.710)
Epoch: [6][270/422]  Time 1.88 (1.92)  Loss 0.3301 (0.3203)  Prec@1 96.094 (96.463)  Prec@5 100.000 (99.709)
Epoch: [6][280/422]  Time 1.89 (1.92)  Loss 0.2969 (0.3203)  Prec@1 96.094 (96.441)  Prec@5 100.000 (99.714)
Epoch: [6][290/422]  Time 1.90 (1.92)  Loss 0.2981 (0.3200)  Prec@1 96.875 (96.440)  Prec@5 100.000 (99.710)
Epoch: [6][300/422]  Time 1.89 (1.92)  Loss 0.3024 (0.3207)  Prec@1 96.875 (96.397)  Prec@5 100.000 (99.717)
Epoch: [6][310/422]  Time 1.88 (1.92)  Loss 0.2730 (0.3204)  Prec@1 97.656 (96.413)  Prec@5 100.000 (99.721)
Epoch: [6][320/422]  Time 1.89 (1.92)  Loss 0.2562 (0.3201)  Prec@1 96.094 (96.410)  Prec@5 100.000 (99.725)
Epoch: [6][330/422]  Time 1.90 (1.92)  Loss 0.2640 (0.3202)  Prec@1 96.094 (96.401)  Prec@5 99.219 (99.724)
Epoch: [6][340/422]  Time 1.89 (1.92)  Loss 0.4027 (0.3197)  Prec@1 94.531 (96.414)  Prec@5 99.219 (99.730)
Epoch: [6][350/422]  Time 1.90 (1.92)  Loss 0.3612 (0.3192)  Prec@1 94.531 (96.416)  Prec@5 99.219 (99.733)
Epoch: [6][360/422]  Time 2.10 (1.92)  Loss 0.2887 (0.3193)  Prec@1 96.875 (96.414)  Prec@5 100.000 (99.729)
Epoch: [6][370/422]  Time 2.07 (1.93)  Loss 0.2285 (0.3182)  Prec@1 99.219 (96.462)  Prec@5 100.000 (99.735)
Epoch: [6][380/422]  Time 1.90 (1.93)  Loss 0.2510 (0.3178)  Prec@1 96.875 (96.463)  Prec@5 100.000 (99.738)
Epoch: [6][390/422]  Time 1.88 (1.93)  Loss 0.3191 (0.3180)  Prec@1 96.875 (96.459)  Prec@5 99.219 (99.740)
Epoch: [6][400/422]  Time 1.92 (1.93)  Loss 0.4308 (0.3179)  Prec@1 94.531 (96.470)  Prec@5 98.438 (99.735)
Epoch: [6][410/422]  Time 1.88 (1.93)  Loss 0.2445 (0.3172)  Prec@1 98.438 (96.487)  Prec@5 100.000 (99.736)
Epoch: [6][420/422]  Time 1.87 (1.92)  Loss 0.3341 (0.3165)  Prec@1 96.875 (96.493)  Prec@5 100.000 (99.740)
Test: [0/47]	Time 0.519 (0.519)	Loss 0.0709 (0.0709)	Prec@1 97.656 (97.656)	Prec@5 99.219 (99.219)
Test: [10/47]	Time 0.093 (0.137)	Loss 0.0171 (0.0592)	Prec@1 99.219 (98.295)	Prec@5 100.000 (99.929)
Test: [20/47]	Time 0.091 (0.116)	Loss 0.0834 (0.0679)	Prec@1 97.656 (98.177)	Prec@5 100.000 (99.963)
Test: [30/47]	Time 0.090 (0.109)	Loss 0.0340 (0.0631)	Prec@1 97.656 (98.236)	Prec@5 100.000 (99.950)
Test: [40/47]	Time 0.073 (0.104)	Loss 0.0645 (0.0683)	Prec@1 97.656 (98.133)	Prec@5 100.000 (99.962)
 * Prec@1 98.117 Prec@5 99.967
Epoch: [7][0/422]  Time 2.45 (2.45)  Loss 0.3157 (0.3157)  Prec@1 95.312 (95.312)  Prec@5 100.000 (100.000)
Epoch: [7][10/422]  Time 1.89 (1.95)  Loss 0.2893 (0.2846)  Prec@1 96.875 (97.017)  Prec@5 100.000 (99.858)
Epoch: [7][20/422]  Time 1.89 (1.93)  Loss 0.3959 (0.3116)  Prec@1 94.531 (96.466)  Prec@5 99.219 (99.628)
Epoch: [7][30/422]  Time 1.92 (1.92)  Loss 0.2476 (0.3091)  Prec@1 96.875 (96.547)  Prec@5 100.000 (99.698)
Epoch: [7][40/422]  Time 1.91 (1.92)  Loss 0.2846 (0.3123)  Prec@1 95.312 (96.322)  Prec@5 100.000 (99.695)
Epoch: [7][50/422]  Time 1.90 (1.92)  Loss 0.3689 (0.3161)  Prec@1 95.312 (96.247)  Prec@5 99.219 (99.678)
Epoch: [7][60/422]  Time 1.90 (1.92)  Loss 0.3275 (0.3148)  Prec@1 98.438 (96.311)  Prec@5 100.000 (99.718)
Epoch: [7][70/422]  Time 1.91 (1.92)  Loss 0.3947 (0.3162)  Prec@1 94.531 (96.259)  Prec@5 99.219 (99.747)
Epoch: [7][80/422]  Time 1.90 (1.92)  Loss 0.2965 (0.3181)  Prec@1 97.656 (96.248)  Prec@5 100.000 (99.730)
Epoch: [7][90/422]  Time 1.91 (1.92)  Loss 0.2753 (0.3171)  Prec@1 97.656 (96.300)  Prec@5 100.000 (99.725)
Epoch: [7][100/422]  Time 1.89 (1.91)  Loss 0.3079 (0.3156)  Prec@1 96.875 (96.349)  Prec@5 100.000 (99.745)
Epoch: [7][110/422]  Time 2.04 (1.91)  Loss 0.2981 (0.3147)  Prec@1 96.875 (96.389)  Prec@5 100.000 (99.754)
Epoch: [7][120/422]  Time 1.88 (1.91)  Loss 0.2985 (0.3133)  Prec@1 97.656 (96.429)  Prec@5 100.000 (99.761)
Epoch: [7][130/422]  Time 2.02 (1.91)  Loss 0.4296 (0.3142)  Prec@1 93.750 (96.422)  Prec@5 100.000 (99.773)
Epoch: [7][140/422]  Time 1.90 (1.91)  Loss 0.2355 (0.3124)  Prec@1 97.656 (96.465)  Prec@5 100.000 (99.778)
Epoch: [7][150/422]  Time 1.89 (1.91)  Loss 0.3375 (0.3144)  Prec@1 96.094 (96.409)  Prec@5 99.219 (99.757)
Epoch: [7][160/422]  Time 1.89 (1.91)  Loss 0.2816 (0.3139)  Prec@1 96.875 (96.395)  Prec@5 100.000 (99.772)
Epoch: [7][170/422]  Time 1.92 (1.91)  Loss 0.2742 (0.3139)  Prec@1 96.875 (96.368)  Prec@5 100.000 (99.781)
Epoch: [7][180/422]  Time 1.87 (1.91)  Loss 0.3496 (0.3134)  Prec@1 96.875 (96.396)  Prec@5 99.219 (99.771)
Epoch: [7][190/422]  Time 1.91 (1.91)  Loss 0.2627 (0.3116)  Prec@1 99.219 (96.450)  Prec@5 100.000 (99.779)
Epoch: [7][200/422]  Time 1.88 (1.91)  Loss 0.4423 (0.3136)  Prec@1 93.750 (96.412)  Prec@5 99.219 (99.771)
Epoch: [7][210/422]  Time 1.89 (1.91)  Loss 0.3742 (0.3140)  Prec@1 96.094 (96.394)  Prec@5 100.000 (99.774)
Epoch: [7][220/422]  Time 2.04 (1.91)  Loss 0.2478 (0.3134)  Prec@1 99.219 (96.426)  Prec@5 100.000 (99.767)
Epoch: [7][230/422]  Time 1.88 (1.91)  Loss 0.3450 (0.3129)  Prec@1 93.750 (96.439)  Prec@5 100.000 (99.767)
Epoch: [7][240/422]  Time 1.92 (1.91)  Loss 0.3647 (0.3133)  Prec@1 95.312 (96.454)  Prec@5 99.219 (99.767)
Epoch: [7][250/422]  Time 1.88 (1.91)  Loss 0.2756 (0.3121)  Prec@1 98.438 (96.489)  Prec@5 99.219 (99.770)
Epoch: [7][260/422]  Time 1.90 (1.91)  Loss 0.2369 (0.3116)  Prec@1 98.438 (96.519)  Prec@5 100.000 (99.764)
Epoch: [7][270/422]  Time 1.88 (1.91)  Loss 0.3504 (0.3114)  Prec@1 96.094 (96.535)  Prec@5 99.219 (99.755)
Epoch: [7][280/422]  Time 1.89 (1.91)  Loss 0.2564 (0.3113)  Prec@1 98.438 (96.530)  Prec@5 100.000 (99.755)
Epoch: [7][290/422]  Time 1.90 (1.91)  Loss 0.3136 (0.3111)  Prec@1 96.875 (96.537)  Prec@5 100.000 (99.758)
Epoch: [7][300/422]  Time 1.95 (1.91)  Loss 0.2602 (0.3114)  Prec@1 98.438 (96.538)  Prec@5 100.000 (99.756)
Epoch: [7][310/422]  Time 1.87 (1.91)  Loss 0.2960 (0.3109)  Prec@1 96.875 (96.548)  Prec@5 100.000 (99.751)
Epoch: [7][320/422]  Time 1.92 (1.91)  Loss 0.2904 (0.3113)  Prec@1 97.656 (96.532)  Prec@5 100.000 (99.749)
Epoch: [7][330/422]  Time 2.05 (1.91)  Loss 0.3221 (0.3117)  Prec@1 95.312 (96.509)  Prec@5 99.219 (99.750)
Epoch: [7][340/422]  Time 1.90 (1.91)  Loss 0.3016 (0.3114)  Prec@1 96.875 (96.524)  Prec@5 100.000 (99.755)
Epoch: [7][350/422]  Time 1.90 (1.91)  Loss 0.2522 (0.3105)  Prec@1 99.219 (96.554)  Prec@5 100.000 (99.760)
Epoch: [7][360/422]  Time 1.90 (1.91)  Loss 0.3288 (0.3106)  Prec@1 95.312 (96.561)  Prec@5 100.000 (99.751)
Epoch: [7][370/422]  Time 1.89 (1.91)  Loss 0.2883 (0.3111)  Prec@1 96.875 (96.563)  Prec@5 100.000 (99.749)
Epoch: [7][380/422]  Time 1.90 (1.91)  Loss 0.2707 (0.3108)  Prec@1 97.656 (96.559)  Prec@5 100.000 (99.752)
Epoch: [7][390/422]  Time 1.90 (1.91)  Loss 0.3164 (0.3109)  Prec@1 96.875 (96.553)  Prec@5 99.219 (99.748)
Epoch: [7][400/422]  Time 1.92 (1.91)  Loss 0.3585 (0.3112)  Prec@1 95.312 (96.557)  Prec@5 100.000 (99.743)
Epoch: [7][410/422]  Time 1.88 (1.91)  Loss 0.3374 (0.3113)  Prec@1 96.094 (96.558)  Prec@5 97.656 (99.743)
Epoch: [7][420/422]  Time 1.87 (1.91)  Loss 0.3823 (0.3110)  Prec@1 96.094 (96.580)  Prec@5 98.438 (99.740)
Test: [0/47]	Time 0.547 (0.547)	Loss 0.0279 (0.0279)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
Test: [10/47]	Time 0.092 (0.138)	Loss 0.0148 (0.0621)	Prec@1 99.219 (98.224)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.091 (0.117)	Loss 0.0545 (0.0644)	Prec@1 98.438 (98.400)	Prec@5 100.000 (100.000)
Test: [30/47]	Time 0.090 (0.109)	Loss 0.0413 (0.0525)	Prec@1 99.219 (98.614)	Prec@5 100.000 (100.000)
Test: [40/47]	Time 0.075 (0.104)	Loss 0.0536 (0.0579)	Prec@1 97.656 (98.476)	Prec@5 100.000 (100.000)
 * Prec@1 98.300 Prec@5 99.983
Epoch: [8][0/422]  Time 2.42 (2.42)  Loss 0.2675 (0.2675)  Prec@1 96.875 (96.875)  Prec@5 100.000 (100.000)
Epoch: [8][10/422]  Time 1.88 (1.94)  Loss 0.3174 (0.2878)  Prec@1 96.875 (97.017)  Prec@5 99.219 (99.787)
Epoch: [8][20/422]  Time 1.92 (1.93)  Loss 0.3115 (0.2991)  Prec@1 96.094 (96.540)  Prec@5 100.000 (99.591)
Epoch: [8][30/422]  Time 1.92 (1.92)  Loss 0.2657 (0.3040)  Prec@1 97.656 (96.547)  Prec@5 100.000 (99.647)
Epoch: [8][40/422]  Time 1.89 (1.92)  Loss 0.3001 (0.3084)  Prec@1 97.656 (96.361)  Prec@5 100.000 (99.676)
Epoch: [8][50/422]  Time 1.91 (1.92)  Loss 0.3037 (0.3130)  Prec@1 96.875 (96.216)  Prec@5 100.000 (99.617)
Epoch: [8][60/422]  Time 1.89 (1.91)  Loss 0.3536 (0.3136)  Prec@1 94.531 (96.196)  Prec@5 100.000 (99.641)
Epoch: [8][70/422]  Time 2.09 (1.92)  Loss 0.3564 (0.3147)  Prec@1 96.094 (96.182)  Prec@5 99.219 (99.648)
Epoch: [8][80/422]  Time 1.90 (1.92)  Loss 0.3031 (0.3174)  Prec@1 96.094 (96.103)  Prec@5 100.000 (99.633)
Epoch: [8][90/422]  Time 1.88 (1.92)  Loss 0.3939 (0.3172)  Prec@1 93.750 (96.154)  Prec@5 99.219 (99.639)
Epoch: [8][100/422]  Time 1.87 (1.92)  Loss 0.2750 (0.3135)  Prec@1 97.656 (96.210)  Prec@5 100.000 (99.675)
Epoch: [8][110/422]  Time 2.06 (1.92)  Loss 0.3505 (0.3139)  Prec@1 96.094 (96.256)  Prec@5 100.000 (99.669)
Epoch: [8][120/422]  Time 1.93 (1.92)  Loss 0.3346 (0.3136)  Prec@1 96.094 (96.242)  Prec@5 98.438 (99.677)
Epoch: [8][130/422]  Time 1.89 (1.92)  Loss 0.3000 (0.3124)  Prec@1 96.875 (96.344)  Prec@5 100.000 (99.684)
Epoch: [8][140/422]  Time 1.90 (1.92)  Loss 0.2508 (0.3118)  Prec@1 98.438 (96.360)  Prec@5 100.000 (99.701)
Epoch: [8][150/422]  Time 1.87 (1.92)  Loss 0.3194 (0.3110)  Prec@1 95.312 (96.383)  Prec@5 99.219 (99.700)
Epoch: [8][160/422]  Time 1.88 (1.92)  Loss 0.3260 (0.3114)  Prec@1 96.094 (96.385)  Prec@5 100.000 (99.704)
Epoch: [8][170/422]  Time 1.89 (1.92)  Loss 0.2779 (0.3103)  Prec@1 98.438 (96.400)  Prec@5 100.000 (99.703)
Epoch: [8][180/422]  Time 1.91 (1.92)  Loss 0.3240 (0.3104)  Prec@1 96.094 (96.409)  Prec@5 100.000 (99.702)
Epoch: [8][190/422]  Time 1.90 (1.92)  Loss 0.3713 (0.3107)  Prec@1 95.312 (96.425)  Prec@5 100.000 (99.697)
Epoch: [8][200/422]  Time 1.89 (1.92)  Loss 0.2915 (0.3101)  Prec@1 96.094 (96.455)  Prec@5 100.000 (99.697)
Epoch: [8][210/422]  Time 1.88 (1.92)  Loss 0.3069 (0.3088)  Prec@1 97.656 (96.516)  Prec@5 100.000 (99.700)
Epoch: [8][220/422]  Time 1.88 (1.92)  Loss 0.3937 (0.3095)  Prec@1 93.750 (96.483)  Prec@5 100.000 (99.696)
Epoch: [8][230/422]  Time 1.91 (1.92)  Loss 0.2453 (0.3081)  Prec@1 98.438 (96.550)  Prec@5 100.000 (99.709)
Epoch: [8][240/422]  Time 1.90 (1.92)  Loss 0.2578 (0.3077)  Prec@1 96.094 (96.531)  Prec@5 100.000 (99.715)
Epoch: [8][250/422]  Time 2.24 (1.93)  Loss 0.3108 (0.3079)  Prec@1 98.438 (96.517)  Prec@5 99.219 (99.714)
Epoch: [8][260/422]  Time 1.88 (1.93)  Loss 0.3266 (0.3077)  Prec@1 96.094 (96.504)  Prec@5 100.000 (99.725)
Epoch: [8][270/422]  Time 1.87 (1.93)  Loss 0.2630 (0.3074)  Prec@1 97.656 (96.523)  Prec@5 100.000 (99.729)
Epoch: [8][280/422]  Time 1.90 (1.93)  Loss 0.2597 (0.3071)  Prec@1 98.438 (96.541)  Prec@5 100.000 (99.728)
Epoch: [8][290/422]  Time 1.93 (1.93)  Loss 0.3189 (0.3069)  Prec@1 97.656 (96.564)  Prec@5 99.219 (99.721)
Epoch: [8][300/422]  Time 1.88 (1.93)  Loss 0.3748 (0.3076)  Prec@1 95.312 (96.556)  Prec@5 99.219 (99.714)
Epoch: [8][310/422]  Time 1.88 (1.93)  Loss 0.3844 (0.3072)  Prec@1 93.750 (96.569)  Prec@5 98.438 (99.716)
Epoch: [8][320/422]  Time 1.89 (1.93)  Loss 0.2829 (0.3073)  Prec@1 96.875 (96.554)  Prec@5 100.000 (99.713)
Epoch: [8][330/422]  Time 1.92 (1.93)  Loss 0.2758 (0.3060)  Prec@1 96.094 (96.587)  Prec@5 100.000 (99.721)
Epoch: [8][340/422]  Time 1.91 (1.93)  Loss 0.4195 (0.3058)  Prec@1 93.750 (96.595)  Prec@5 99.219 (99.725)
Epoch: [8][350/422]  Time 1.89 (1.92)  Loss 0.2786 (0.3058)  Prec@1 96.875 (96.601)  Prec@5 100.000 (99.728)
Epoch: [8][360/422]  Time 1.89 (1.92)  Loss 0.2986 (0.3059)  Prec@1 96.094 (96.591)  Prec@5 100.000 (99.734)
Epoch: [8][370/422]  Time 1.87 (1.92)  Loss 0.3517 (0.3056)  Prec@1 96.094 (96.608)  Prec@5 100.000 (99.735)
Epoch: [8][380/422]  Time 1.96 (1.92)  Loss 0.2763 (0.3055)  Prec@1 96.094 (96.598)  Prec@5 99.219 (99.738)
Epoch: [8][390/422]  Time 1.91 (1.92)  Loss 0.3663 (0.3057)  Prec@1 96.094 (96.587)  Prec@5 99.219 (99.738)
Epoch: [8][400/422]  Time 1.90 (1.92)  Loss 0.2700 (0.3063)  Prec@1 98.438 (96.573)  Prec@5 99.219 (99.731)
Epoch: [8][410/422]  Time 1.89 (1.92)  Loss 0.3441 (0.3061)  Prec@1 94.531 (96.578)  Prec@5 99.219 (99.734)
Epoch: [8][420/422]  Time 1.86 (1.92)  Loss 0.2880 (0.3058)  Prec@1 96.094 (96.586)  Prec@5 100.000 (99.738)
Test: [0/47]	Time 0.537 (0.537)	Loss 0.0937 (0.0937)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
Test: [10/47]	Time 0.161 (0.149)	Loss 0.0631 (0.0805)	Prec@1 97.656 (97.940)	Prec@5 100.000 (99.858)
Test: [20/47]	Time 0.091 (0.124)	Loss 0.1012 (0.0790)	Prec@1 97.656 (97.954)	Prec@5 100.000 (99.926)
Test: [30/47]	Time 0.091 (0.114)	Loss 0.0228 (0.0698)	Prec@1 99.219 (98.085)	Prec@5 100.000 (99.950)
Test: [40/47]	Time 0.074 (0.108)	Loss 0.0768 (0.0663)	Prec@1 98.438 (98.190)	Prec@5 100.000 (99.962)
 * Prec@1 98.150 Prec@5 99.967
Epoch: [9][0/422]  Time 2.34 (2.34)  Loss 0.2594 (0.2594)  Prec@1 97.656 (97.656)  Prec@5 100.000 (100.000)
Epoch: [9][10/422]  Time 1.90 (1.95)  Loss 0.2450 (0.2837)  Prec@1 99.219 (97.514)  Prec@5 100.000 (99.858)
Epoch: [9][20/422]  Time 1.91 (1.94)  Loss 0.2995 (0.2903)  Prec@1 96.094 (97.024)  Prec@5 100.000 (99.591)
Epoch: [9][30/422]  Time 1.91 (1.94)  Loss 0.2969 (0.2881)  Prec@1 97.656 (97.127)  Prec@5 99.219 (99.672)
Epoch: [9][40/422]  Time 1.89 (1.93)  Loss 0.2949 (0.2958)  Prec@1 96.094 (96.723)  Prec@5 100.000 (99.695)
Epoch: [9][50/422]  Time 1.91 (1.92)  Loss 0.2736 (0.2959)  Prec@1 98.438 (96.783)  Prec@5 100.000 (99.709)
Epoch: [9][60/422]  Time 2.10 (1.92)  Loss 0.3446 (0.2972)  Prec@1 95.312 (96.837)  Prec@5 99.219 (99.705)
Epoch: [9][70/422]  Time 1.90 (1.92)  Loss 0.2754 (0.2962)  Prec@1 97.656 (96.886)  Prec@5 100.000 (99.703)
Epoch: [9][80/422]  Time 1.88 (1.92)  Loss 0.3370 (0.2987)  Prec@1 96.875 (96.836)  Prec@5 99.219 (99.691)
Epoch: [9][90/422]  Time 1.88 (1.92)  Loss 0.2876 (0.2994)  Prec@1 96.875 (96.763)  Prec@5 100.000 (99.700)
Epoch: [9][100/422]  Time 1.88 (1.92)  Loss 0.2177 (0.2960)  Prec@1 98.438 (96.867)  Prec@5 100.000 (99.722)
Epoch: [9][110/422]  Time 1.91 (1.92)  Loss 0.2438 (0.2977)  Prec@1 100.000 (96.875)  Prec@5 100.000 (99.718)
Epoch: [9][120/422]  Time 1.93 (1.92)  Loss 0.2826 (0.2955)  Prec@1 98.438 (96.985)  Prec@5 100.000 (99.729)
Epoch: [9][130/422]  Time 1.87 (1.92)  Loss 0.2566 (0.2968)  Prec@1 99.219 (96.947)  Prec@5 100.000 (99.732)
Epoch: [9][140/422]  Time 1.91 (1.92)  Loss 0.3407 (0.2983)  Prec@1 95.312 (96.897)  Prec@5 99.219 (99.723)
Epoch: [9][150/422]  Time 1.87 (1.92)  Loss 0.2829 (0.2979)  Prec@1 97.656 (96.885)  Prec@5 100.000 (99.736)
Epoch: [9][160/422]  Time 1.87 (1.92)  Loss 0.3361 (0.2976)  Prec@1 96.094 (96.909)  Prec@5 100.000 (99.748)
Epoch: [9][170/422]  Time 2.09 (1.92)  Loss 0.2449 (0.2983)  Prec@1 97.656 (96.898)  Prec@5 100.000 (99.744)
Epoch: [9][180/422]  Time 1.88 (1.92)  Loss 0.2373 (0.2981)  Prec@1 99.219 (96.910)  Prec@5 100.000 (99.737)
Epoch: [9][190/422]  Time 1.89 (1.92)  Loss 0.3253 (0.2971)  Prec@1 96.094 (96.932)  Prec@5 100.000 (99.746)
Epoch: [9][200/422]  Time 1.90 (1.92)  Loss 0.2390 (0.2982)  Prec@1 100.000 (96.910)  Prec@5 100.000 (99.728)
Epoch: [9][210/422]  Time 1.87 (1.91)  Loss 0.3608 (0.2979)  Prec@1 94.531 (96.901)  Prec@5 100.000 (99.737)
Epoch: [9][220/422]  Time 1.91 (1.91)  Loss 0.2928 (0.2980)  Prec@1 96.875 (96.900)  Prec@5 99.219 (99.735)
Epoch: [9][230/422]  Time 1.92 (1.92)  Loss 0.4093 (0.2995)  Prec@1 94.531 (96.851)  Prec@5 98.438 (99.713)
Epoch: [9][240/422]  Time 1.89 (1.92)  Loss 0.2805 (0.3002)  Prec@1 96.875 (96.836)  Prec@5 100.000 (99.705)
Epoch: [9][250/422]  Time 1.89 (1.92)  Loss 0.3657 (0.2999)  Prec@1 94.531 (96.825)  Prec@5 99.219 (99.707)
Epoch: [9][260/422]  Time 1.89 (1.92)  Loss 0.2950 (0.3004)  Prec@1 97.656 (96.818)  Prec@5 100.000 (99.710)
Epoch: [9][270/422]  Time 1.89 (1.92)  Loss 0.2122 (0.3000)  Prec@1 99.219 (96.832)  Prec@5 100.000 (99.717)
Epoch: [9][280/422]  Time 1.92 (1.92)  Loss 0.2606 (0.2998)  Prec@1 98.438 (96.842)  Prec@5 100.000 (99.728)
Epoch: [9][290/422]  Time 1.92 (1.92)  Loss 0.3773 (0.3003)  Prec@1 94.531 (96.816)  Prec@5 100.000 (99.723)
Epoch: [9][300/422]  Time 1.87 (1.92)  Loss 0.3976 (0.3005)  Prec@1 94.531 (96.810)  Prec@5 98.438 (99.717)
Epoch: [9][310/422]  Time 1.89 (1.92)  Loss 0.2472 (0.2998)  Prec@1 97.656 (96.842)  Prec@5 100.000 (99.724)
Epoch: [9][320/422]  Time 1.90 (1.92)  Loss 0.3259 (0.2993)  Prec@1 96.875 (96.870)  Prec@5 99.219 (99.723)
Epoch: [9][330/422]  Time 1.92 (1.92)  Loss 0.2420 (0.2983)  Prec@1 98.438 (96.908)  Prec@5 100.000 (99.726)
Epoch: [9][340/422]  Time 1.90 (1.92)  Loss 0.3343 (0.2984)  Prec@1 94.531 (96.898)  Prec@5 100.000 (99.718)
Epoch: [9][350/422]  Time 1.88 (1.92)  Loss 0.2753 (0.2983)  Prec@1 96.875 (96.899)  Prec@5 100.000 (99.724)
Epoch: [9][360/422]  Time 1.89 (1.92)  Loss 0.3678 (0.2981)  Prec@1 94.531 (96.910)  Prec@5 99.219 (99.725)
Epoch: [9][370/422]  Time 1.89 (1.91)  Loss 0.2452 (0.2974)  Prec@1 97.656 (96.936)  Prec@5 100.000 (99.726)
Epoch: [9][380/422]  Time 1.96 (1.92)  Loss 0.2785 (0.2981)  Prec@1 97.656 (96.908)  Prec@5 100.000 (99.717)
Epoch: [9][390/422]  Time 1.92 (1.92)  Loss 0.2307 (0.2979)  Prec@1 99.219 (96.909)  Prec@5 100.000 (99.718)
Epoch: [9][400/422]  Time 1.91 (1.92)  Loss 0.1970 (0.2975)  Prec@1 100.000 (96.924)  Prec@5 100.000 (99.721)
Epoch: [9][410/422]  Time 1.89 (1.92)  Loss 0.2913 (0.2974)  Prec@1 100.000 (96.924)  Prec@5 100.000 (99.721)
Epoch: [9][420/422]  Time 1.86 (1.91)  Loss 0.2746 (0.2972)  Prec@1 97.656 (96.918)  Prec@5 100.000 (99.722)
Test: [0/47]	Time 0.545 (0.545)	Loss 0.0240 (0.0240)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
Test: [10/47]	Time 0.095 (0.139)	Loss 0.1987 (0.0660)	Prec@1 96.094 (98.295)	Prec@5 100.000 (100.000)
Test: [20/47]	Time 0.093 (0.117)	Loss 0.1500 (0.0682)	Prec@1 97.656 (98.251)	Prec@5 100.000 (100.000)
Test: [30/47]	Time 0.092 (0.110)	Loss 0.0171 (0.0635)	Prec@1 99.219 (98.261)	Prec@5 100.000 (99.950)
Test: [40/47]	Time 0.070 (0.105)	Loss 0.0220 (0.0639)	Prec@1 98.438 (98.190)	Prec@5 100.000 (99.943)
 * Prec@1 98.117 Prec@5 99.950
Training done
Test: [0/79]	Time 0.375 (0.375)	Loss 0.0046 (0.0046)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
Test: [10/79]	Time 0.091 (0.125)	Loss 0.1001 (0.0759)	Prec@1 97.656 (97.798)	Prec@5 100.000 (99.929)
Test: [20/79]	Time 0.091 (0.111)	Loss 0.0755 (0.0863)	Prec@1 97.656 (97.582)	Prec@5 100.000 (99.963)
Test: [30/79]	Time 0.090 (0.106)	Loss 0.1050 (0.0850)	Prec@1 96.094 (97.681)	Prec@5 100.000 (99.975)
Test: [40/79]	Time 0.093 (0.103)	Loss 0.0105 (0.0803)	Prec@1 100.000 (97.713)	Prec@5 100.000 (99.981)
Test: [50/79]	Time 0.096 (0.102)	Loss 0.0446 (0.0706)	Prec@1 99.219 (97.993)	Prec@5 100.000 (99.985)
Test: [60/79]	Time 0.092 (0.100)	Loss 0.0054 (0.0624)	Prec@1 100.000 (98.194)	Prec@5 100.000 (99.987)
Test: [70/79]	Time 0.076 (0.100)	Loss 0.0938 (0.0562)	Prec@1 97.656 (98.371)	Prec@5 100.000 (99.989)
 * Prec@1 98.410 Prec@5 99.990
Initializing GSENN wrapper.
Computing train data stats...
**** Performing black-box lipschitz estimation over subset of dataset ****
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1330
Function value obtained: -0.0074
Current minimum: -0.0074
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1296
Function value obtained: -0.0185
Current minimum: -0.0185
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1300
Function value obtained: -0.0108
Current minimum: -0.0185
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1297
Function value obtained: -0.0074
Current minimum: -0.0185
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1286
Function value obtained: -0.0154
Current minimum: -0.0185
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1301
Function value obtained: -0.0033
Current minimum: -0.0185
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1311
Function value obtained: -0.0198
Current minimum: -0.0198
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0089
Current minimum: -0.0198
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1296
Function value obtained: -0.0103
Current minimum: -0.0198
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 10.2137
Function value obtained: -0.0248
Current minimum: -0.0248
0.024810785722208916 0.13244860707737516
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1315
Function value obtained: -0.0060
Current minimum: -0.0060
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1302
Function value obtained: -0.0069
Current minimum: -0.0069
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1292
Function value obtained: -0.0166
Current minimum: -0.0166
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1299
Function value obtained: -0.0055
Current minimum: -0.0166
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1291
Function value obtained: -0.0130
Current minimum: -0.0166
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1304
Function value obtained: -0.0116
Current minimum: -0.0166
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1303
Function value obtained: -0.0119
Current minimum: -0.0166
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1306
Function value obtained: -0.0105
Current minimum: -0.0166
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1298
Function value obtained: -0.0110
Current minimum: -0.0166
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.0236
Function value obtained: -0.0018
Current minimum: -0.0166
0.016581639074399475 0.1301618605566266
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1299
Function value obtained: -0.0167
Current minimum: -0.0167
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1301
Function value obtained: -0.0231
Current minimum: -0.0231
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1292
Function value obtained: -0.0222
Current minimum: -0.0231
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1291
Function value obtained: -0.0140
Current minimum: -0.0231
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1283
Function value obtained: -0.0193
Current minimum: -0.0231
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1293
Function value obtained: -0.0242
Current minimum: -0.0242
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1301
Function value obtained: -0.0130
Current minimum: -0.0242
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1291
Function value obtained: -0.0114
Current minimum: -0.0242
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1286
Function value obtained: -0.0172
Current minimum: -0.0242
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 8.9986
Function value obtained: -0.0228
Current minimum: -0.0242
0.02417369438131711 0.13536902768589643
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1303
Function value obtained: -0.0188
Current minimum: -0.0188
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0268
Current minimum: -0.0268
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1301
Function value obtained: -0.0265
Current minimum: -0.0268
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1291
Function value obtained: -0.0225
Current minimum: -0.0268
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1294
Function value obtained: -0.0223
Current minimum: -0.0268
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0345
Current minimum: -0.0345
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1308
Function value obtained: -0.0309
Current minimum: -0.0345
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1306
Function value obtained: -0.0171
Current minimum: -0.0345
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1302
Function value obtained: -0.0383
Current minimum: -0.0383
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.0221
Function value obtained: -0.0166
Current minimum: -0.0383
0.038329379157379335 0.13570217803045972
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1301
Function value obtained: -0.0064
Current minimum: -0.0064
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1304
Function value obtained: -0.0121
Current minimum: -0.0121
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1300
Function value obtained: -0.0074
Current minimum: -0.0121
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1300
Function value obtained: -0.0031
Current minimum: -0.0121
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1300
Function value obtained: -0.0045
Current minimum: -0.0121
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1293
Function value obtained: -0.0057
Current minimum: -0.0121
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1309
Function value obtained: -0.0056
Current minimum: -0.0121
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1304
Function value obtained: -0.0109
Current minimum: -0.0121
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1313
Function value obtained: -0.0037
Current minimum: -0.0121
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.0446
Function value obtained: -0.0067
Current minimum: -0.0121
0.012055188348626074 0.13314504454805212
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1301
Function value obtained: -0.0051
Current minimum: -0.0051
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1291
Function value obtained: -0.0040
Current minimum: -0.0051
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1302
Function value obtained: -0.0043
Current minimum: -0.0051
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1304
Function value obtained: -0.0033
Current minimum: -0.0051
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1303
Function value obtained: -0.0042
Current minimum: -0.0051
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1304
Function value obtained: -0.0040
Current minimum: -0.0051
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1303
Function value obtained: -0.0081
Current minimum: -0.0081
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1304
Function value obtained: -0.0051
Current minimum: -0.0081
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1312
Function value obtained: -0.0048
Current minimum: -0.0081
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.2528
Function value obtained: -0.0044
Current minimum: -0.0081
0.008139405052867804 0.13229104059976501
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1315
Function value obtained: -0.0044
Current minimum: -0.0044
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1306
Function value obtained: -0.0040
Current minimum: -0.0044
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0039
Current minimum: -0.0044
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1316
Function value obtained: -0.0044
Current minimum: -0.0044
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1302
Function value obtained: -0.0051
Current minimum: -0.0051
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1305
Function value obtained: -0.0047
Current minimum: -0.0051
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1305
Function value obtained: -0.0016
Current minimum: -0.0051
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1313
Function value obtained: -0.0055
Current minimum: -0.0055
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1316
Function value obtained: -0.0052
Current minimum: -0.0055
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.1308
Function value obtained: -0.0030
Current minimum: -0.0055
0.00548695058204113 0.13513544160474758
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1339
Function value obtained: -0.0265
Current minimum: -0.0265
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1292
Function value obtained: -0.0263
Current minimum: -0.0265
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1293
Function value obtained: -0.0179
Current minimum: -0.0265
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1298
Function value obtained: -0.0212
Current minimum: -0.0265
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1314
Function value obtained: -0.0163
Current minimum: -0.0265
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1301
Function value obtained: -0.0248
Current minimum: -0.0265
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1300
Function value obtained: -0.0078
Current minimum: -0.0265
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1305
Function value obtained: -0.0249
Current minimum: -0.0265
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1302
Function value obtained: -0.0340
Current minimum: -0.0340
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 8.9479
Function value obtained: -0.0383
Current minimum: -0.0383
0.038338611996123144 0.13509714117698451
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1313
Function value obtained: -0.0013
Current minimum: -0.0013
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1301
Function value obtained: -0.0008
Current minimum: -0.0013
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1302
Function value obtained: -0.0016
Current minimum: -0.0016
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1294
Function value obtained: -0.0013
Current minimum: -0.0016
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1293
Function value obtained: -0.0018
Current minimum: -0.0018
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1302
Function value obtained: -0.0011
Current minimum: -0.0018
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1305
Function value obtained: -0.0016
Current minimum: -0.0018
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1319
Function value obtained: -0.0013
Current minimum: -0.0018
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1304
Function value obtained: -0.0014
Current minimum: -0.0018
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 8.9312
Function value obtained: -0.0009
Current minimum: -0.0018
0.001766414353921089 0.13686203140298847
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1300
Function value obtained: -0.0241
Current minimum: -0.0241
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1302
Function value obtained: -0.0213
Current minimum: -0.0241
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1309
Function value obtained: -0.0227
Current minimum: -0.0241
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1303
Function value obtained: -0.0253
Current minimum: -0.0253
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1303
Function value obtained: -0.0218
Current minimum: -0.0253
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1312
Function value obtained: -0.0243
Current minimum: -0.0253
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1294
Function value obtained: -0.0256
Current minimum: -0.0256
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1303
Function value obtained: -0.0236
Current minimum: -0.0256
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1306
Function value obtained: -0.0249
Current minimum: -0.0256
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 8.9237
Function value obtained: -0.0220
Current minimum: -0.0256
0.02558471572892365 0.1350593541367276
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1308
Function value obtained: -0.0262
Current minimum: -0.0262
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1304
Function value obtained: -0.0616
Current minimum: -0.0616
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0234
Current minimum: -0.0616
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1305
Function value obtained: -0.0299
Current minimum: -0.0616
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1302
Function value obtained: -0.0265
Current minimum: -0.0616
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1305
Function value obtained: -0.0282
Current minimum: -0.0616
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1308
Function value obtained: -0.0820
Current minimum: -0.0820
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1293
Function value obtained: -0.0382
Current minimum: -0.0820
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1289
Function value obtained: -0.0276
Current minimum: -0.0820
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 8.9081
Function value obtained: -0.0175
Current minimum: -0.0820
0.0820319722104223 0.13303576009712784
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1297
Function value obtained: -0.0210
Current minimum: -0.0210
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1309
Function value obtained: -0.0254
Current minimum: -0.0254
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1301
Function value obtained: -0.0208
Current minimum: -0.0254
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0388
Current minimum: -0.0388
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1319
Function value obtained: -0.0419
Current minimum: -0.0419
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1310
Function value obtained: -0.0367
Current minimum: -0.0419
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1305
Function value obtained: -0.0250
Current minimum: -0.0419
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1306
Function value obtained: -0.0161
Current minimum: -0.0419
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1300
Function value obtained: -0.0272
Current minimum: -0.0419
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 8.9769
Function value obtained: -0.0234
Current minimum: -0.0419
0.04189477930243668 0.13784497013806196
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1304
Function value obtained: -0.0054
Current minimum: -0.0054
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1301
Function value obtained: -0.0068
Current minimum: -0.0068
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1295
Function value obtained: -0.0099
Current minimum: -0.0099
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1285
Function value obtained: -0.0045
Current minimum: -0.0099
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1297
Function value obtained: -0.0083
Current minimum: -0.0099
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1298
Function value obtained: -0.0089
Current minimum: -0.0099
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1292
Function value obtained: -0.0100
Current minimum: -0.0100
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1289
Function value obtained: -0.0190
Current minimum: -0.0190
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1295
Function value obtained: -0.0112
Current minimum: -0.0190
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.1775
Function value obtained: -0.0076
Current minimum: -0.0190
0.01904192328292288 0.13432534723984577
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1293
Function value obtained: -0.0157
Current minimum: -0.0157
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1293
Function value obtained: -0.0292
Current minimum: -0.0292
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1291
Function value obtained: -0.0091
Current minimum: -0.0292
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1289
Function value obtained: -0.0190
Current minimum: -0.0292
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1300
Function value obtained: -0.0202
Current minimum: -0.0292
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1288
Function value obtained: -0.0148
Current minimum: -0.0292
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1284
Function value obtained: -0.0102
Current minimum: -0.0292
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1296
Function value obtained: -0.0138
Current minimum: -0.0292
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1295
Function value obtained: -0.0241
Current minimum: -0.0292
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.0996
Function value obtained: -0.0288
Current minimum: -0.0292
0.029206357737950668 0.13504681565197033
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1301
Function value obtained: -0.0139
Current minimum: -0.0139
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1294
Function value obtained: -0.0155
Current minimum: -0.0155
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1292
Function value obtained: -0.0082
Current minimum: -0.0155
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1301
Function value obtained: -0.0163
Current minimum: -0.0163
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1303
Function value obtained: -0.0119
Current minimum: -0.0163
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1299
Function value obtained: -0.0152
Current minimum: -0.0163
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1313
Function value obtained: -0.0157
Current minimum: -0.0163
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1302
Function value obtained: -0.0109
Current minimum: -0.0163
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1302
Function value obtained: -0.0114
Current minimum: -0.0163
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.1785
Function value obtained: -0.0113
Current minimum: -0.0163
0.016288882580417125 0.13769629768671157
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1312
Function value obtained: -0.0041
Current minimum: -0.0041
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1306
Function value obtained: -0.0054
Current minimum: -0.0054
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1302
Function value obtained: -0.0054
Current minimum: -0.0054
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0069
Current minimum: -0.0069
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1306
Function value obtained: -0.0052
Current minimum: -0.0069
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1306
Function value obtained: -0.0059
Current minimum: -0.0069
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1304
Function value obtained: -0.0054
Current minimum: -0.0069
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1311
Function value obtained: -0.0082
Current minimum: -0.0082
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1306
Function value obtained: -0.0035
Current minimum: -0.0082
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.2040
Function value obtained: -0.0039
Current minimum: -0.0082
0.008191759359653775 0.13467417237136595
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1315
Function value obtained: -0.0096
Current minimum: -0.0096
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1303
Function value obtained: -0.0036
Current minimum: -0.0096
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1287
Function value obtained: -0.0037
Current minimum: -0.0096
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1286
Function value obtained: -0.0071
Current minimum: -0.0096
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1295
Function value obtained: -0.0105
Current minimum: -0.0105
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1303
Function value obtained: -0.0040
Current minimum: -0.0105
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1303
Function value obtained: -0.0024
Current minimum: -0.0105
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1303
Function value obtained: -0.0132
Current minimum: -0.0132
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1293
Function value obtained: -0.0029
Current minimum: -0.0132
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 8.8931
Function value obtained: -0.0042
Current minimum: -0.0132
0.013163858801769653 0.14159561580969982
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1308
Function value obtained: -0.0128
Current minimum: -0.0128
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1304
Function value obtained: -0.0095
Current minimum: -0.0128
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1300
Function value obtained: -0.0161
Current minimum: -0.0161
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1294
Function value obtained: -0.0100
Current minimum: -0.0161
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1291
Function value obtained: -0.0161
Current minimum: -0.0161
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1306
Function value obtained: -0.0088
Current minimum: -0.0161
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1309
Function value obtained: -0.0094
Current minimum: -0.0161
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1312
Function value obtained: -0.0163
Current minimum: -0.0163
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1296
Function value obtained: -0.0066
Current minimum: -0.0163
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 9.0564
Function value obtained: -0.0084
Current minimum: -0.0163
0.01633788490602388 0.1334036782734125
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1304
Function value obtained: -0.0394
Current minimum: -0.0394
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1308
Function value obtained: -0.0127
Current minimum: -0.0394
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0234
Current minimum: -0.0394
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1308
Function value obtained: -0.0222
Current minimum: -0.0394
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1294
Function value obtained: -0.0164
Current minimum: -0.0394
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1301
Function value obtained: -0.0317
Current minimum: -0.0394
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1309
Function value obtained: -0.0296
Current minimum: -0.0394
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1310
Function value obtained: -0.0394
Current minimum: -0.0394
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1318
Function value obtained: -0.0545
Current minimum: -0.0545
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 8.8679
Function value obtained: -0.0322
Current minimum: -0.0545
0.05445561087979644 0.13435017589579681
Running BlackBox Minimization with Bayesian Optimization
Iteration No: 1 started. Evaluating function at random point.
Iteration No: 1 ended. Evaluation done at random point.
Time taken: 0.1308
Function value obtained: -0.0052
Current minimum: -0.0052
Iteration No: 2 started. Evaluating function at random point.
Iteration No: 2 ended. Evaluation done at random point.
Time taken: 0.1298
Function value obtained: -0.0040
Current minimum: -0.0052
Iteration No: 3 started. Evaluating function at random point.
Iteration No: 3 ended. Evaluation done at random point.
Time taken: 0.1305
Function value obtained: -0.0042
Current minimum: -0.0052
Iteration No: 4 started. Evaluating function at random point.
Iteration No: 4 ended. Evaluation done at random point.
Time taken: 0.1290
Function value obtained: -0.0083
Current minimum: -0.0083
Iteration No: 5 started. Evaluating function at random point.
Iteration No: 5 ended. Evaluation done at random point.
Time taken: 0.1298
Function value obtained: -0.0112
Current minimum: -0.0112
Iteration No: 6 started. Evaluating function at random point.
Iteration No: 6 ended. Evaluation done at random point.
Time taken: 0.1309
Function value obtained: -0.0025
Current minimum: -0.0112
Iteration No: 7 started. Evaluating function at random point.
Iteration No: 7 ended. Evaluation done at random point.
Time taken: 0.1320
Function value obtained: -0.0068
Current minimum: -0.0112
Iteration No: 8 started. Evaluating function at random point.
Iteration No: 8 ended. Evaluation done at random point.
Time taken: 0.1307
Function value obtained: -0.0038
Current minimum: -0.0112
Iteration No: 9 started. Evaluating function at random point.
Iteration No: 9 ended. Evaluation done at random point.
Time taken: 0.1297
Function value obtained: -0.0072
Current minimum: -0.0112
Iteration No: 10 started. Evaluating function at random point.
Iteration No: 10 ended. Evaluation done at random point.
Time taken: 8.9491
Function value obtained: -0.0047
Current minimum: -0.0112
0.011213431509565115 0.13957458548379034
Missed points: 0/20
> /home/lgpu0014/FACT/SENN/scripts/main_mnist.py(384)main()
-> Stability_dict = {'lips': lips}
(Pdb) 
/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.
  warnings.warn(message, FutureWarning)
/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.
  warnings.warn(message, FutureWarning)
/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "scripts/main_mnist.py", line 404, in <module>
    main()
  File "scripts/main_mnist.py", line 384, in main
    Stability_dict = {'lips': lips}
  File "scripts/main_mnist.py", line 384, in main
    Stability_dict = {'lips': lips}
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/bdb.py", line 51, in trace_dispatch
    return self.dispatch_line(frame)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/bdb.py", line 70, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
srun: error: r30n6: task 0: Exited with exit code 1
srun: Job 4386953 step creation temporarily disabled, retrying
srun: Step created for job 4386953

Parameters:
	BATCH_SIZE=128
	CONCEPT_DIM=1
	CUDA=True
	DATASET=pathology
	DATASETS=['heart', 'ionosphere', 'breast-cancer', 'wine', 'heart', 'glass', 'diabetes', 'yeast', 'leukemia', 'abalone']
	DEBUG=False
	DROPOUT=0.1
	EMBEDDING=pathology
	EPOCHS=10
	H_SPARSITY=0.0001
	H_TYPE=cnn
	LIP_CALLS=10
	LIP_EPS=0.01
	LIP_POINTS=100
	LISA=1
	LOAD_MODEL=False
	LOG_PATH=log
	LR=0.001
	MODEL_PATH=models
	NCLASSES=2
	NCONCEPTS=10
	NOBIAS=False
	NUM_GPUS=1
	NUM_WORKERS=4
	OBJECTIVE=cross_entropy
	OPT=adam
	OPTIM=gp
	POSITIVE_THETA=False
	PRINT_FREQ=10
	RESULTS_PATH=out
	SEED=2018
	SUMMARY_PATH=results/summary.csv
	TEST=False
	THETA_ARCH=simple
	THETA_DIM=-1
	THETA_REG_LAMBDA=0.01
	THETA_REG_TYPE=grad3
	TRAIN=True
	WEIGHT_DECAY=0.001
Model path out lisa_output/models/mnist/grad3_Hcnn_Thsimple_Cpts10_Reg1e-02_Sp0.0001_LR0.001
Traceback (most recent call last):
  File "scripts/main_mnist.py", line 404, in <module>
    main()
  File "scripts/main_mnist.py", line 257, in main
    trainer.train(train_loader, valid_loader, epochs = args.epochs, save_path = model_path)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/trainers.py", line 180, in train
    self.train_epoch(epoch, train_loader)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/trainers.py", line 248, in train_epoch
    outputs, loss, loss_dict = self.train_batch(inputs, targets)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/trainers.py", line 575, in train_batch
    pred = self.model(inputs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/models.py", line 221, in forward
    h_x, x_tilde = self.conceptizer(x)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/conceptizers.py", line 102, in forward
    encoded = self.encode(x)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/conceptizers.py", line 202, in encode
    p       = F.relu(F.max_pool2d(self.conv1(x), 2))
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 301, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #2 'weight'
srun: error: r31n3: task 0: Exited with exit code 1

Parameters:
	BATCH_SIZE=128
	CONCEPT_DIM=1
	CUDA=True
	DATASET=pathology
	DATASETS=['heart', 'ionosphere', 'breast-cancer', 'wine', 'heart', 'glass', 'diabetes', 'yeast', 'leukemia', 'abalone']
	DEBUG=False
	DROPOUT=0.1
	EMBEDDING=pathology
	EPOCHS=10
	H_SPARSITY=0.0001
	H_TYPE=cnn
	LIP_CALLS=10
	LIP_EPS=0.01
	LIP_POINTS=100
	LISA=1
	LOAD_MODEL=False
	LOG_PATH=log
	LR=0.001
	MODEL_PATH=models
	NCLASSES=2
	NCONCEPTS=10
	NOBIAS=False
	NUM_GPUS=1
	NUM_WORKERS=4
	OBJECTIVE=cross_entropy
	OPT=adam
	OPTIM=gp
	POSITIVE_THETA=False
	PRINT_FREQ=10
	RESULTS_PATH=out
	SEED=2018
	SUMMARY_PATH=results/summary.csv
	TEST=False
	THETA_ARCH=simple
	THETA_DIM=-1
	THETA_REG_LAMBDA=0.01
	THETA_REG_TYPE=grad3
	TRAIN=True
	WEIGHT_DECAY=0.001
Model path out lisa_output/models/mnist/grad3_Hcnn_Thsimple_Cpts10_Reg1e-02_Sp0.0001_LR0.001
Traceback (most recent call last):
  File "scripts/main_mnist.py", line 404, in <module>
    main()
  File "scripts/main_mnist.py", line 257, in main
    trainer.train(train_loader, valid_loader, epochs = args.epochs, save_path = model_path)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/trainers.py", line 180, in train
    self.train_epoch(epoch, train_loader)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/trainers.py", line 248, in train_epoch
    outputs, loss, loss_dict = self.train_batch(inputs, targets)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/trainers.py", line 575, in train_batch
    pred = self.model(inputs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/models.py", line 221, in forward
    h_x, x_tilde = self.conceptizer(x)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/conceptizers.py", line 102, in forward
    encoded = self.encode(x)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/conceptizers.py", line 202, in encode
    p       = F.relu(F.max_pool2d(self.conv1(x), 2))
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 301, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #2 'weight'
srun: error: r31n3: task 0: Exited with exit code 1
srun: Job 4386986 step creation temporarily disabled, retrying
srun: Step created for job 4386986

Parameters:
	BATCH_SIZE=128
	CONCEPT_DIM=1
	CUDA=True
	DATASET=pathology
	DATASETS=['heart', 'ionosphere', 'breast-cancer', 'wine', 'heart', 'glass', 'diabetes', 'yeast', 'leukemia', 'abalone']
	DEBUG=False
	DROPOUT=0.1
	EMBEDDING=pathology
	EPOCHS=10
	H_SPARSITY=0.0001
	H_TYPE=cnn
	LIP_CALLS=10
	LIP_EPS=0.01
	LIP_POINTS=100
	LISA=1
	LOAD_MODEL=False
	LOG_PATH=log
	LR=0.001
	MODEL_PATH=models
	NCLASSES=2
	NCONCEPTS=10
	NOBIAS=False
	NUM_GPUS=1
	NUM_WORKERS=4
	OBJECTIVE=cross_entropy
	OPT=adam
	OPTIM=gp
	POSITIVE_THETA=False
	PRINT_FREQ=10
	RESULTS_PATH=out
	SEED=2018
	SUMMARY_PATH=results/summary.csv
	TEST=False
	THETA_ARCH=simple
	THETA_DIM=-1
	THETA_REG_LAMBDA=0.01
	THETA_REG_TYPE=grad3
	TRAIN=True
	WEIGHT_DECAY=0.001
Model path out lisa_output/models/mnist/grad3_Hcnn_Thsimple_Cpts10_Reg1e-02_Sp0.0001_LR0.001
Traceback (most recent call last):
  File "scripts/main_mnist.py", line 404, in <module>
    main()
  File "scripts/main_mnist.py", line 257, in main
    trainer.train(train_loader, valid_loader, epochs = args.epochs, save_path = model_path)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/trainers.py", line 180, in train
    self.train_epoch(epoch, train_loader)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/trainers.py", line 248, in train_epoch
    outputs, loss, loss_dict = self.train_batch(inputs, targets)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/trainers.py", line 575, in train_batch
    pred = self.model(inputs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/models.py", line 221, in forward
    h_x, x_tilde = self.conceptizer(x)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/conceptizers.py", line 102, in forward
    encoded = self.encode(x)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/conceptizers.py", line 202, in encode
    p       = F.relu(F.max_pool2d(self.conv1(x), 2))
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 301, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #2 'weight'
srun: error: r31n3: task 0: Exited with exit code 1
srun: Job 4386990 step creation temporarily disabled, retrying
srun: Step created for job 4386990

Parameters:
	BATCH_SIZE=128
	CONCEPT_DIM=1
	CUDA=True
	DATASET=pathology
	DATASETS=['heart', 'ionosphere', 'breast-cancer', 'wine', 'heart', 'glass', 'diabetes', 'yeast', 'leukemia', 'abalone']
	DEBUG=False
	DROPOUT=0.1
	EMBEDDING=pathology
	EPOCHS=10
	H_SPARSITY=0.0001
	H_TYPE=cnn
	LIP_CALLS=10
	LIP_EPS=0.01
	LIP_POINTS=100
	LISA=1
	LOAD_MODEL=False
	LOG_PATH=log
	LR=0.001
	MODEL_PATH=models
	NCLASSES=2
	NCONCEPTS=10
	NOBIAS=False
	NUM_GPUS=1
	NUM_WORKERS=4
	OBJECTIVE=cross_entropy
	OPT=adam
	OPTIM=gp
	POSITIVE_THETA=False
	PRINT_FREQ=10
	RESULTS_PATH=out
	SEED=2018
	SUMMARY_PATH=results/summary.csv
	TEST=False
	THETA_ARCH=simple
	THETA_DIM=-1
	THETA_REG_LAMBDA=0.01
	THETA_REG_TYPE=grad3
	TRAIN=True
	WEIGHT_DECAY=0.001
Model path out lisa_output/models/mnist/grad3_Hcnn_Thsimple_Cpts10_Reg1e-02_Sp0.0001_LR0.001
Traceback (most recent call last):
  File "scripts/main_mnist.py", line 404, in <module>
    main()
  File "scripts/main_mnist.py", line 257, in main
    trainer.train(train_loader, valid_loader, epochs = args.epochs, save_path = model_path)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/trainers.py", line 180, in train
    self.train_epoch(epoch, train_loader)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/trainers.py", line 248, in train_epoch
    outputs, loss, loss_dict = self.train_batch(inputs, targets)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/trainers.py", line 575, in train_batch
    pred = self.model(inputs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/models.py", line 221, in forward
    h_x, x_tilde = self.conceptizer(x)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/conceptizers.py", line 102, in forward
    encoded = self.encode(x)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/SENN/conceptizers.py", line 202, in encode
    p       = F.relu(F.max_pool2d(self.conv1(x), 2))
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/lgpu0014/.conda/envs/FACT/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 301, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #2 'weight'
srun: error: r31n3: task 0: Exited with exit code 1
